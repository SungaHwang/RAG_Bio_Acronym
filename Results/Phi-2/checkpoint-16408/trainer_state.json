{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 16408,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 3.484361410140991,
      "learning_rate": 0.00019878108239882984,
      "loss": 1.9319,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0457797050476074,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.6378,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.635796308517456,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.5588,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3779823780059814,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.5315,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6995463371276855,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.5284,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.048935651779175,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.5219,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1135590076446533,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.5097,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9821562767028809,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.496,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5738649368286133,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.5173,
      "step": 900
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.705208420753479,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.4383,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8629282712936401,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.4576,
      "step": 1100
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.347022771835327,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.4223,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2486326694488525,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.4575,
      "step": 1300
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.872275948524475,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.4332,
      "step": 1400
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8485629558563232,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.3928,
      "step": 1500
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.8853163719177246,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.4175,
      "step": 1600
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.008941411972046,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.3434,
      "step": 1700
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0026137828826904,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.4059,
      "step": 1800
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1112632751464844,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.3665,
      "step": 1900
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7014119625091553,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.3553,
      "step": 2000
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.392628192901611,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.3766,
      "step": 2100
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5480291843414307,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.3678,
      "step": 2200
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.449117422103882,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.3721,
      "step": 2300
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9523513317108154,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.3202,
      "step": 2400
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9506157636642456,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.288,
      "step": 2500
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.7251322269439697,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.2798,
      "step": 2600
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8945508003234863,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.2924,
      "step": 2700
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.035941481590271,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.3273,
      "step": 2800
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.847678780555725,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.3071,
      "step": 2900
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.191852331161499,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.2879,
      "step": 3000
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1710433959960938,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.3113,
      "step": 3100
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5907171964645386,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.2678,
      "step": 3200
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5638283491134644,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.26,
      "step": 3300
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.5153162479400635,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.2354,
      "step": 3400
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.77167546749115,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.2238,
      "step": 3500
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3062009811401367,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.2809,
      "step": 3600
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4757835865020752,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.2726,
      "step": 3700
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4843568801879883,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.2413,
      "step": 3800
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2319934368133545,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.2024,
      "step": 3900
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0602240562438965,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.2353,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8405888080596924,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.2709,
      "step": 4100
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.8929110765457153,
      "learning_rate": 0.00014880546075085325,
      "loss": 1.1357,
      "step": 4200
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.9730678796768188,
      "learning_rate": 0.0001475865431496831,
      "loss": 1.1413,
      "step": 4300
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.9588896036148071,
      "learning_rate": 0.00014636762554851292,
      "loss": 1.1424,
      "step": 4400
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0927420854568481,
      "learning_rate": 0.00014514870794734276,
      "loss": 1.114,
      "step": 4500
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.5113472938537598,
      "learning_rate": 0.0001439297903461726,
      "loss": 1.1224,
      "step": 4600
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.1203640699386597,
      "learning_rate": 0.00014271087274500245,
      "loss": 1.1666,
      "step": 4700
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.521341323852539,
      "learning_rate": 0.0001414919551438323,
      "loss": 1.125,
      "step": 4800
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.3722046613693237,
      "learning_rate": 0.00014027303754266213,
      "loss": 1.1413,
      "step": 4900
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.5758758783340454,
      "learning_rate": 0.00013905411994149196,
      "loss": 1.1851,
      "step": 5000
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0611172914505005,
      "learning_rate": 0.00013783520234032182,
      "loss": 1.1662,
      "step": 5100
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.671275794506073,
      "learning_rate": 0.00013661628473915166,
      "loss": 1.0987,
      "step": 5200
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5800660848617554,
      "learning_rate": 0.00013539736713798147,
      "loss": 1.1455,
      "step": 5300
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.7952613830566406,
      "learning_rate": 0.0001341784495368113,
      "loss": 1.158,
      "step": 5400
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1728980541229248,
      "learning_rate": 0.00013295953193564114,
      "loss": 1.1548,
      "step": 5500
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.7400469779968262,
      "learning_rate": 0.000131740614334471,
      "loss": 1.1346,
      "step": 5600
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1286542415618896,
      "learning_rate": 0.00013052169673330083,
      "loss": 1.0978,
      "step": 5700
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.4188013076782227,
      "learning_rate": 0.00012930277913213067,
      "loss": 1.1235,
      "step": 5800
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1993359327316284,
      "learning_rate": 0.0001280838615309605,
      "loss": 1.1413,
      "step": 5900
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.2596431970596313,
      "learning_rate": 0.00012686494392979037,
      "loss": 1.1444,
      "step": 6000
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.4566805362701416,
      "learning_rate": 0.0001256460263286202,
      "loss": 1.1476,
      "step": 6100
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9165610074996948,
      "learning_rate": 0.00012442710872745004,
      "loss": 1.1563,
      "step": 6200
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.973562479019165,
      "learning_rate": 0.00012320819112627987,
      "loss": 1.1006,
      "step": 6300
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.741936981678009,
      "learning_rate": 0.00012198927352510972,
      "loss": 1.0918,
      "step": 6400
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.310558795928955,
      "learning_rate": 0.00012077035592393954,
      "loss": 1.1184,
      "step": 6500
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.357725739479065,
      "learning_rate": 0.00011955143832276938,
      "loss": 1.1084,
      "step": 6600
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4875301122665405,
      "learning_rate": 0.00011833252072159921,
      "loss": 1.1738,
      "step": 6700
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.3289341926574707,
      "learning_rate": 0.00011711360312042908,
      "loss": 1.1089,
      "step": 6800
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.7103193998336792,
      "learning_rate": 0.00011589468551925891,
      "loss": 1.1464,
      "step": 6900
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.7259217500686646,
      "learning_rate": 0.00011467576791808873,
      "loss": 1.121,
      "step": 7000
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.125850796699524,
      "learning_rate": 0.00011345685031691857,
      "loss": 1.0901,
      "step": 7100
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0225716829299927,
      "learning_rate": 0.00011223793271574843,
      "loss": 1.0609,
      "step": 7200
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.0592002868652344,
      "learning_rate": 0.00011101901511457827,
      "loss": 1.1165,
      "step": 7300
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.6458686590194702,
      "learning_rate": 0.0001098000975134081,
      "loss": 1.1336,
      "step": 7400
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.166580080986023,
      "learning_rate": 0.00010858117991223794,
      "loss": 1.0954,
      "step": 7500
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.989369809627533,
      "learning_rate": 0.00010736226231106778,
      "loss": 1.1035,
      "step": 7600
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.6953531503677368,
      "learning_rate": 0.00010614334470989762,
      "loss": 1.0941,
      "step": 7700
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.2572306394577026,
      "learning_rate": 0.00010492442710872745,
      "loss": 1.1085,
      "step": 7800
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.8878912925720215,
      "learning_rate": 0.00010370550950755729,
      "loss": 1.0855,
      "step": 7900
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.1591646671295166,
      "learning_rate": 0.00010248659190638714,
      "loss": 1.1145,
      "step": 8000
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.9509309530258179,
      "learning_rate": 0.00010126767430521697,
      "loss": 1.1666,
      "step": 8100
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.4709807634353638,
      "learning_rate": 0.00010004875670404681,
      "loss": 1.1182,
      "step": 8200
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.9468269348144531,
      "learning_rate": 9.882983910287666e-05,
      "loss": 1.0459,
      "step": 8300
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.9754343628883362,
      "learning_rate": 9.761092150170649e-05,
      "loss": 1.0492,
      "step": 8400
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.1869688034057617,
      "learning_rate": 9.639200390053633e-05,
      "loss": 1.0333,
      "step": 8500
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.9003540873527527,
      "learning_rate": 9.517308629936616e-05,
      "loss": 1.036,
      "step": 8600
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.0174107551574707,
      "learning_rate": 9.395416869819601e-05,
      "loss": 1.0553,
      "step": 8700
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.1848220825195312,
      "learning_rate": 9.273525109702585e-05,
      "loss": 1.0135,
      "step": 8800
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.7672326564788818,
      "learning_rate": 9.151633349585568e-05,
      "loss": 1.0328,
      "step": 8900
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.2371559143066406,
      "learning_rate": 9.029741589468552e-05,
      "loss": 1.0307,
      "step": 9000
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.109681487083435,
      "learning_rate": 8.907849829351537e-05,
      "loss": 1.0433,
      "step": 9100
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.250469446182251,
      "learning_rate": 8.78595806923452e-05,
      "loss": 1.0251,
      "step": 9200
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.9629210233688354,
      "learning_rate": 8.664066309117505e-05,
      "loss": 1.0276,
      "step": 9300
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.8514182567596436,
      "learning_rate": 8.542174549000487e-05,
      "loss": 1.0359,
      "step": 9400
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.2116423845291138,
      "learning_rate": 8.420282788883472e-05,
      "loss": 1.0321,
      "step": 9500
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.0278189182281494,
      "learning_rate": 8.298391028766456e-05,
      "loss": 1.068,
      "step": 9600
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.1142243146896362,
      "learning_rate": 8.17649926864944e-05,
      "loss": 1.0546,
      "step": 9700
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.7896809577941895,
      "learning_rate": 8.054607508532424e-05,
      "loss": 1.0354,
      "step": 9800
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.3029948472976685,
      "learning_rate": 7.932715748415408e-05,
      "loss": 1.0303,
      "step": 9900
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.7196595668792725,
      "learning_rate": 7.810823988298391e-05,
      "loss": 0.9991,
      "step": 10000
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.0008153915405273,
      "learning_rate": 7.688932228181376e-05,
      "loss": 1.0471,
      "step": 10100
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.860645055770874,
      "learning_rate": 7.56704046806436e-05,
      "loss": 1.0665,
      "step": 10200
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.7142459154129028,
      "learning_rate": 7.445148707947343e-05,
      "loss": 1.033,
      "step": 10300
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.163076639175415,
      "learning_rate": 7.323256947830327e-05,
      "loss": 1.0046,
      "step": 10400
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.4873069524765015,
      "learning_rate": 7.201365187713311e-05,
      "loss": 1.0411,
      "step": 10500
    },
    {
      "epoch": 2.58,
      "grad_norm": 1.1475721597671509,
      "learning_rate": 7.079473427596295e-05,
      "loss": 1.0395,
      "step": 10600
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.7016546130180359,
      "learning_rate": 6.957581667479278e-05,
      "loss": 1.0282,
      "step": 10700
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.3517277240753174,
      "learning_rate": 6.835689907362263e-05,
      "loss": 1.0396,
      "step": 10800
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.7466099858283997,
      "learning_rate": 6.713798147245245e-05,
      "loss": 1.0615,
      "step": 10900
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.8785151839256287,
      "learning_rate": 6.59190638712823e-05,
      "loss": 1.03,
      "step": 11000
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.3070393800735474,
      "learning_rate": 6.470014627011214e-05,
      "loss": 1.0316,
      "step": 11100
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.1018317937850952,
      "learning_rate": 6.348122866894199e-05,
      "loss": 1.0193,
      "step": 11200
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.9081933498382568,
      "learning_rate": 6.226231106777182e-05,
      "loss": 1.0696,
      "step": 11300
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.1507854461669922,
      "learning_rate": 6.104339346660166e-05,
      "loss": 1.0142,
      "step": 11400
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.055543065071106,
      "learning_rate": 5.9824475865431493e-05,
      "loss": 1.0432,
      "step": 11500
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.4974255561828613,
      "learning_rate": 5.860555826426134e-05,
      "loss": 1.0141,
      "step": 11600
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.0811214447021484,
      "learning_rate": 5.738664066309117e-05,
      "loss": 1.0205,
      "step": 11700
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.9110915064811707,
      "learning_rate": 5.616772306192102e-05,
      "loss": 1.0423,
      "step": 11800
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.1482924222946167,
      "learning_rate": 5.4948805460750855e-05,
      "loss": 1.0189,
      "step": 11900
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.9129830598831177,
      "learning_rate": 5.3729887859580697e-05,
      "loss": 1.0516,
      "step": 12000
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.1929593086242676,
      "learning_rate": 5.251097025841053e-05,
      "loss": 1.0161,
      "step": 12100
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.9995872974395752,
      "learning_rate": 5.1292052657240374e-05,
      "loss": 0.994,
      "step": 12200
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.158286213874817,
      "learning_rate": 5.007313505607021e-05,
      "loss": 1.0307,
      "step": 12300
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.7697435021400452,
      "learning_rate": 4.885421745490005e-05,
      "loss": 0.9822,
      "step": 12400
    },
    {
      "epoch": 3.05,
      "grad_norm": 1.2155909538269043,
      "learning_rate": 4.763529985372989e-05,
      "loss": 0.9516,
      "step": 12500
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.765363872051239,
      "learning_rate": 4.641638225255973e-05,
      "loss": 0.9615,
      "step": 12600
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.900201678276062,
      "learning_rate": 4.519746465138957e-05,
      "loss": 0.9654,
      "step": 12700
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.7109655141830444,
      "learning_rate": 4.397854705021941e-05,
      "loss": 0.9631,
      "step": 12800
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.3521143198013306,
      "learning_rate": 4.275962944904925e-05,
      "loss": 0.9671,
      "step": 12900
    },
    {
      "epoch": 3.17,
      "grad_norm": 1.6062980890274048,
      "learning_rate": 4.154071184787909e-05,
      "loss": 0.9809,
      "step": 13000
    },
    {
      "epoch": 3.19,
      "grad_norm": 1.4839154481887817,
      "learning_rate": 4.0321794246708925e-05,
      "loss": 0.97,
      "step": 13100
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.9914780855178833,
      "learning_rate": 3.910287664553876e-05,
      "loss": 0.9677,
      "step": 13200
    },
    {
      "epoch": 3.24,
      "grad_norm": 1.3105732202529907,
      "learning_rate": 3.78839590443686e-05,
      "loss": 0.998,
      "step": 13300
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.9300282001495361,
      "learning_rate": 3.666504144319844e-05,
      "loss": 0.959,
      "step": 13400
    },
    {
      "epoch": 3.29,
      "grad_norm": 1.0427709817886353,
      "learning_rate": 3.544612384202828e-05,
      "loss": 0.9686,
      "step": 13500
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.199497103691101,
      "learning_rate": 3.4227206240858114e-05,
      "loss": 0.9664,
      "step": 13600
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.8056521415710449,
      "learning_rate": 3.3008288639687956e-05,
      "loss": 0.9974,
      "step": 13700
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.8520573377609253,
      "learning_rate": 3.17893710385178e-05,
      "loss": 0.9473,
      "step": 13800
    },
    {
      "epoch": 3.39,
      "grad_norm": 1.2778924703598022,
      "learning_rate": 3.0570453437347634e-05,
      "loss": 0.9843,
      "step": 13900
    },
    {
      "epoch": 3.41,
      "grad_norm": 1.0120283365249634,
      "learning_rate": 2.9351535836177476e-05,
      "loss": 0.9707,
      "step": 14000
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.8365510702133179,
      "learning_rate": 2.8132618235007314e-05,
      "loss": 0.9917,
      "step": 14100
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.2462637424468994,
      "learning_rate": 2.6913700633837153e-05,
      "loss": 0.9718,
      "step": 14200
    },
    {
      "epoch": 3.49,
      "grad_norm": 1.103032112121582,
      "learning_rate": 2.569478303266699e-05,
      "loss": 0.9962,
      "step": 14300
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.7893771529197693,
      "learning_rate": 2.4475865431496833e-05,
      "loss": 0.9943,
      "step": 14400
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.299138069152832,
      "learning_rate": 2.325694783032667e-05,
      "loss": 0.9594,
      "step": 14500
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.1746299266815186,
      "learning_rate": 2.2038030229156507e-05,
      "loss": 0.9673,
      "step": 14600
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.9284636974334717,
      "learning_rate": 2.081911262798635e-05,
      "loss": 0.9746,
      "step": 14700
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.8916721940040588,
      "learning_rate": 1.9600195026816188e-05,
      "loss": 0.9507,
      "step": 14800
    },
    {
      "epoch": 3.63,
      "grad_norm": 1.2799315452575684,
      "learning_rate": 1.8381277425646026e-05,
      "loss": 0.9695,
      "step": 14900
    },
    {
      "epoch": 3.66,
      "grad_norm": 1.154692530632019,
      "learning_rate": 1.7162359824475865e-05,
      "loss": 1.0071,
      "step": 15000
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.5565760135650635,
      "learning_rate": 1.5943442223305704e-05,
      "loss": 0.9708,
      "step": 15100
    },
    {
      "epoch": 3.71,
      "grad_norm": 1.154639720916748,
      "learning_rate": 1.4724524622135544e-05,
      "loss": 0.9842,
      "step": 15200
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.9539711475372314,
      "learning_rate": 1.3505607020965382e-05,
      "loss": 0.9741,
      "step": 15300
    },
    {
      "epoch": 3.75,
      "grad_norm": 1.2377290725708008,
      "learning_rate": 1.2286689419795223e-05,
      "loss": 0.9721,
      "step": 15400
    },
    {
      "epoch": 3.78,
      "grad_norm": 1.0306867361068726,
      "learning_rate": 1.1067771818625061e-05,
      "loss": 0.9545,
      "step": 15500
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.0836284160614014,
      "learning_rate": 9.8488542174549e-06,
      "loss": 0.9594,
      "step": 15600
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.9751712083816528,
      "learning_rate": 8.62993661628474e-06,
      "loss": 0.9927,
      "step": 15700
    },
    {
      "epoch": 3.85,
      "grad_norm": 1.2864528894424438,
      "learning_rate": 7.411019015114579e-06,
      "loss": 0.971,
      "step": 15800
    },
    {
      "epoch": 3.88,
      "grad_norm": 1.210811972618103,
      "learning_rate": 6.1921014139444175e-06,
      "loss": 0.9729,
      "step": 15900
    },
    {
      "epoch": 3.9,
      "grad_norm": 1.2549428939819336,
      "learning_rate": 4.973183812774257e-06,
      "loss": 0.982,
      "step": 16000
    },
    {
      "epoch": 3.92,
      "grad_norm": 1.0675208568572998,
      "learning_rate": 3.754266211604096e-06,
      "loss": 0.9711,
      "step": 16100
    },
    {
      "epoch": 3.95,
      "grad_norm": 1.0054795742034912,
      "learning_rate": 2.535348610433935e-06,
      "loss": 0.9818,
      "step": 16200
    },
    {
      "epoch": 3.97,
      "grad_norm": 1.3494453430175781,
      "learning_rate": 1.3164310092637738e-06,
      "loss": 0.9683,
      "step": 16300
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.2785065174102783,
      "learning_rate": 9.751340809361287e-08,
      "loss": 0.9828,
      "step": 16400
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 1.3557753603072e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
