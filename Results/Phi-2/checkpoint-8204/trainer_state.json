{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8204,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 3.484361410140991,
      "learning_rate": 0.00019878108239882984,
      "loss": 1.9319,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0457797050476074,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.6378,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.635796308517456,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.5588,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3779823780059814,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.5315,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6995463371276855,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.5284,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.048935651779175,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.5219,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1135590076446533,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.5097,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9821562767028809,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.496,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5738649368286133,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.5173,
      "step": 900
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.705208420753479,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.4383,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8629282712936401,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.4576,
      "step": 1100
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.347022771835327,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.4223,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2486326694488525,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.4575,
      "step": 1300
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.872275948524475,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.4332,
      "step": 1400
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8485629558563232,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.3928,
      "step": 1500
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.8853163719177246,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.4175,
      "step": 1600
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.008941411972046,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.3434,
      "step": 1700
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0026137828826904,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.4059,
      "step": 1800
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1112632751464844,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.3665,
      "step": 1900
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7014119625091553,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.3553,
      "step": 2000
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.392628192901611,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.3766,
      "step": 2100
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5480291843414307,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.3678,
      "step": 2200
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.449117422103882,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.3721,
      "step": 2300
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9523513317108154,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.3202,
      "step": 2400
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9506157636642456,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.288,
      "step": 2500
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.7251322269439697,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.2798,
      "step": 2600
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8945508003234863,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.2924,
      "step": 2700
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.035941481590271,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.3273,
      "step": 2800
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.847678780555725,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.3071,
      "step": 2900
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.191852331161499,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.2879,
      "step": 3000
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1710433959960938,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.3113,
      "step": 3100
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5907171964645386,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.2678,
      "step": 3200
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5638283491134644,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.26,
      "step": 3300
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.5153162479400635,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.2354,
      "step": 3400
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.77167546749115,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.2238,
      "step": 3500
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3062009811401367,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.2809,
      "step": 3600
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4757835865020752,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.2726,
      "step": 3700
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4843568801879883,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.2413,
      "step": 3800
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2319934368133545,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.2024,
      "step": 3900
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0602240562438965,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.2353,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8405888080596924,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.2709,
      "step": 4100
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.8929110765457153,
      "learning_rate": 0.00014880546075085325,
      "loss": 1.1357,
      "step": 4200
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.9730678796768188,
      "learning_rate": 0.0001475865431496831,
      "loss": 1.1413,
      "step": 4300
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.9588896036148071,
      "learning_rate": 0.00014636762554851292,
      "loss": 1.1424,
      "step": 4400
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0927420854568481,
      "learning_rate": 0.00014514870794734276,
      "loss": 1.114,
      "step": 4500
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.5113472938537598,
      "learning_rate": 0.0001439297903461726,
      "loss": 1.1224,
      "step": 4600
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.1203640699386597,
      "learning_rate": 0.00014271087274500245,
      "loss": 1.1666,
      "step": 4700
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.521341323852539,
      "learning_rate": 0.0001414919551438323,
      "loss": 1.125,
      "step": 4800
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.3722046613693237,
      "learning_rate": 0.00014027303754266213,
      "loss": 1.1413,
      "step": 4900
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.5758758783340454,
      "learning_rate": 0.00013905411994149196,
      "loss": 1.1851,
      "step": 5000
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0611172914505005,
      "learning_rate": 0.00013783520234032182,
      "loss": 1.1662,
      "step": 5100
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.671275794506073,
      "learning_rate": 0.00013661628473915166,
      "loss": 1.0987,
      "step": 5200
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5800660848617554,
      "learning_rate": 0.00013539736713798147,
      "loss": 1.1455,
      "step": 5300
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.7952613830566406,
      "learning_rate": 0.0001341784495368113,
      "loss": 1.158,
      "step": 5400
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1728980541229248,
      "learning_rate": 0.00013295953193564114,
      "loss": 1.1548,
      "step": 5500
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.7400469779968262,
      "learning_rate": 0.000131740614334471,
      "loss": 1.1346,
      "step": 5600
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1286542415618896,
      "learning_rate": 0.00013052169673330083,
      "loss": 1.0978,
      "step": 5700
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.4188013076782227,
      "learning_rate": 0.00012930277913213067,
      "loss": 1.1235,
      "step": 5800
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1993359327316284,
      "learning_rate": 0.0001280838615309605,
      "loss": 1.1413,
      "step": 5900
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.2596431970596313,
      "learning_rate": 0.00012686494392979037,
      "loss": 1.1444,
      "step": 6000
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.4566805362701416,
      "learning_rate": 0.0001256460263286202,
      "loss": 1.1476,
      "step": 6100
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9165610074996948,
      "learning_rate": 0.00012442710872745004,
      "loss": 1.1563,
      "step": 6200
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.973562479019165,
      "learning_rate": 0.00012320819112627987,
      "loss": 1.1006,
      "step": 6300
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.741936981678009,
      "learning_rate": 0.00012198927352510972,
      "loss": 1.0918,
      "step": 6400
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.310558795928955,
      "learning_rate": 0.00012077035592393954,
      "loss": 1.1184,
      "step": 6500
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.357725739479065,
      "learning_rate": 0.00011955143832276938,
      "loss": 1.1084,
      "step": 6600
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4875301122665405,
      "learning_rate": 0.00011833252072159921,
      "loss": 1.1738,
      "step": 6700
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.3289341926574707,
      "learning_rate": 0.00011711360312042908,
      "loss": 1.1089,
      "step": 6800
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.7103193998336792,
      "learning_rate": 0.00011589468551925891,
      "loss": 1.1464,
      "step": 6900
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.7259217500686646,
      "learning_rate": 0.00011467576791808873,
      "loss": 1.121,
      "step": 7000
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.125850796699524,
      "learning_rate": 0.00011345685031691857,
      "loss": 1.0901,
      "step": 7100
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0225716829299927,
      "learning_rate": 0.00011223793271574843,
      "loss": 1.0609,
      "step": 7200
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.0592002868652344,
      "learning_rate": 0.00011101901511457827,
      "loss": 1.1165,
      "step": 7300
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.6458686590194702,
      "learning_rate": 0.0001098000975134081,
      "loss": 1.1336,
      "step": 7400
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.166580080986023,
      "learning_rate": 0.00010858117991223794,
      "loss": 1.0954,
      "step": 7500
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.989369809627533,
      "learning_rate": 0.00010736226231106778,
      "loss": 1.1035,
      "step": 7600
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.6953531503677368,
      "learning_rate": 0.00010614334470989762,
      "loss": 1.0941,
      "step": 7700
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.2572306394577026,
      "learning_rate": 0.00010492442710872745,
      "loss": 1.1085,
      "step": 7800
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.8878912925720215,
      "learning_rate": 0.00010370550950755729,
      "loss": 1.0855,
      "step": 7900
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.1591646671295166,
      "learning_rate": 0.00010248659190638714,
      "loss": 1.1145,
      "step": 8000
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.9509309530258179,
      "learning_rate": 0.00010126767430521697,
      "loss": 1.1666,
      "step": 8100
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.4709807634353638,
      "learning_rate": 0.00010004875670404681,
      "loss": 1.1182,
      "step": 8200
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 6778747906560000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
