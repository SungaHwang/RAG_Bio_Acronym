{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4102,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 3.484361410140991,
      "learning_rate": 0.00019878108239882984,
      "loss": 1.9319,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0457797050476074,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.6378,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.635796308517456,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.5588,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3779823780059814,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.5315,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6995463371276855,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.5284,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.048935651779175,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.5219,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1135590076446533,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.5097,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9821562767028809,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.496,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5738649368286133,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.5173,
      "step": 900
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.705208420753479,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.4383,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8629282712936401,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.4576,
      "step": 1100
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.347022771835327,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.4223,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2486326694488525,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.4575,
      "step": 1300
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.872275948524475,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.4332,
      "step": 1400
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8485629558563232,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.3928,
      "step": 1500
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.8853163719177246,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.4175,
      "step": 1600
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.008941411972046,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.3434,
      "step": 1700
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0026137828826904,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.4059,
      "step": 1800
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1112632751464844,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.3665,
      "step": 1900
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7014119625091553,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.3553,
      "step": 2000
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.392628192901611,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.3766,
      "step": 2100
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5480291843414307,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.3678,
      "step": 2200
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.449117422103882,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.3721,
      "step": 2300
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9523513317108154,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.3202,
      "step": 2400
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9506157636642456,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.288,
      "step": 2500
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.7251322269439697,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.2798,
      "step": 2600
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8945508003234863,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.2924,
      "step": 2700
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.035941481590271,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.3273,
      "step": 2800
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.847678780555725,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.3071,
      "step": 2900
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.191852331161499,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.2879,
      "step": 3000
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1710433959960938,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.3113,
      "step": 3100
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5907171964645386,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.2678,
      "step": 3200
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5638283491134644,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.26,
      "step": 3300
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.5153162479400635,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.2354,
      "step": 3400
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.77167546749115,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.2238,
      "step": 3500
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3062009811401367,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.2809,
      "step": 3600
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4757835865020752,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.2726,
      "step": 3700
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4843568801879883,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.2413,
      "step": 3800
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2319934368133545,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.2024,
      "step": 3900
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0602240562438965,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.2353,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8405888080596924,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.2709,
      "step": 4100
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 3390147323136000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
