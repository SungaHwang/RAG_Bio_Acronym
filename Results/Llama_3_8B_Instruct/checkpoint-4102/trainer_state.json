{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4102,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 17.73218536376953,
      "learning_rate": 0.00019878108239882984,
      "loss": 1.7616,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 18.07570457458496,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.637,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.526622772216797,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.5481,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 19.315202713012695,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.5888,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 12.252758979797363,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.5614,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 37.18833541870117,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.5704,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.415708541870117,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.5969,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.569807052612305,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.5134,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 10.115227699279785,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.5529,
      "step": 900
    },
    {
      "epoch": 0.24,
      "grad_norm": 16.96780776977539,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.4751,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 17.234973907470703,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.4875,
      "step": 1100
    },
    {
      "epoch": 0.29,
      "grad_norm": 24.946889877319336,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.4963,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.808664798736572,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.5129,
      "step": 1300
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.918356895446777,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.4879,
      "step": 1400
    },
    {
      "epoch": 0.37,
      "grad_norm": 45.21942901611328,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.4515,
      "step": 1500
    },
    {
      "epoch": 0.39,
      "grad_norm": 12.708837509155273,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.443,
      "step": 1600
    },
    {
      "epoch": 0.41,
      "grad_norm": 12.334681510925293,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.4129,
      "step": 1700
    },
    {
      "epoch": 0.44,
      "grad_norm": 13.711291313171387,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.4465,
      "step": 1800
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.211142539978027,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.4076,
      "step": 1900
    },
    {
      "epoch": 0.49,
      "grad_norm": 10.92481517791748,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.4196,
      "step": 2000
    },
    {
      "epoch": 0.51,
      "grad_norm": 25.522842407226562,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.4351,
      "step": 2100
    },
    {
      "epoch": 0.54,
      "grad_norm": 22.61247444152832,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.4046,
      "step": 2200
    },
    {
      "epoch": 0.56,
      "grad_norm": 10.208495140075684,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.4153,
      "step": 2300
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.89745044708252,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.3854,
      "step": 2400
    },
    {
      "epoch": 0.61,
      "grad_norm": 9.183588027954102,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.3339,
      "step": 2500
    },
    {
      "epoch": 0.63,
      "grad_norm": 19.407323837280273,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.3325,
      "step": 2600
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.816115379333496,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.3173,
      "step": 2700
    },
    {
      "epoch": 0.68,
      "grad_norm": 15.548957824707031,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.3908,
      "step": 2800
    },
    {
      "epoch": 0.71,
      "grad_norm": 16.916770935058594,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.3332,
      "step": 2900
    },
    {
      "epoch": 0.73,
      "grad_norm": 8.815616607666016,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.3474,
      "step": 3000
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.77564525604248,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.3692,
      "step": 3100
    },
    {
      "epoch": 0.78,
      "grad_norm": 11.44706916809082,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.3299,
      "step": 3200
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.522964954376221,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.3099,
      "step": 3300
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.385866165161133,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.2421,
      "step": 3400
    },
    {
      "epoch": 0.85,
      "grad_norm": 16.478435516357422,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.2957,
      "step": 3500
    },
    {
      "epoch": 0.88,
      "grad_norm": 12.62771987915039,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.3254,
      "step": 3600
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.302328109741211,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.3085,
      "step": 3700
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.931312084197998,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.2864,
      "step": 3800
    },
    {
      "epoch": 0.95,
      "grad_norm": 18.68117904663086,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.2593,
      "step": 3900
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.169618606567383,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.2734,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.077672004699707,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.3123,
      "step": 4100
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 9354644403732480.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
