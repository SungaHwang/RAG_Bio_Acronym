{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 12306,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 17.73218536376953,
      "learning_rate": 0.00019878108239882984,
      "loss": 1.7616,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 18.07570457458496,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.637,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.526622772216797,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.5481,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 19.315202713012695,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.5888,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 12.252758979797363,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.5614,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 37.18833541870117,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.5704,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.415708541870117,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.5969,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.569807052612305,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.5134,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 10.115227699279785,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.5529,
      "step": 900
    },
    {
      "epoch": 0.24,
      "grad_norm": 16.96780776977539,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.4751,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 17.234973907470703,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.4875,
      "step": 1100
    },
    {
      "epoch": 0.29,
      "grad_norm": 24.946889877319336,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.4963,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.808664798736572,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.5129,
      "step": 1300
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.918356895446777,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.4879,
      "step": 1400
    },
    {
      "epoch": 0.37,
      "grad_norm": 45.21942901611328,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.4515,
      "step": 1500
    },
    {
      "epoch": 0.39,
      "grad_norm": 12.708837509155273,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.443,
      "step": 1600
    },
    {
      "epoch": 0.41,
      "grad_norm": 12.334681510925293,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.4129,
      "step": 1700
    },
    {
      "epoch": 0.44,
      "grad_norm": 13.711291313171387,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.4465,
      "step": 1800
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.211142539978027,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.4076,
      "step": 1900
    },
    {
      "epoch": 0.49,
      "grad_norm": 10.92481517791748,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.4196,
      "step": 2000
    },
    {
      "epoch": 0.51,
      "grad_norm": 25.522842407226562,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.4351,
      "step": 2100
    },
    {
      "epoch": 0.54,
      "grad_norm": 22.61247444152832,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.4046,
      "step": 2200
    },
    {
      "epoch": 0.56,
      "grad_norm": 10.208495140075684,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.4153,
      "step": 2300
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.89745044708252,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.3854,
      "step": 2400
    },
    {
      "epoch": 0.61,
      "grad_norm": 9.183588027954102,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.3339,
      "step": 2500
    },
    {
      "epoch": 0.63,
      "grad_norm": 19.407323837280273,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.3325,
      "step": 2600
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.816115379333496,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.3173,
      "step": 2700
    },
    {
      "epoch": 0.68,
      "grad_norm": 15.548957824707031,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.3908,
      "step": 2800
    },
    {
      "epoch": 0.71,
      "grad_norm": 16.916770935058594,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.3332,
      "step": 2900
    },
    {
      "epoch": 0.73,
      "grad_norm": 8.815616607666016,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.3474,
      "step": 3000
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.77564525604248,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.3692,
      "step": 3100
    },
    {
      "epoch": 0.78,
      "grad_norm": 11.44706916809082,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.3299,
      "step": 3200
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.522964954376221,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.3099,
      "step": 3300
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.385866165161133,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.2421,
      "step": 3400
    },
    {
      "epoch": 0.85,
      "grad_norm": 16.478435516357422,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.2957,
      "step": 3500
    },
    {
      "epoch": 0.88,
      "grad_norm": 12.62771987915039,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.3254,
      "step": 3600
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.302328109741211,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.3085,
      "step": 3700
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.931312084197998,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.2864,
      "step": 3800
    },
    {
      "epoch": 0.95,
      "grad_norm": 18.68117904663086,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.2593,
      "step": 3900
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.169618606567383,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.2734,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.077672004699707,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.3123,
      "step": 4100
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.987156867980957,
      "learning_rate": 0.00014880546075085325,
      "loss": 1.1411,
      "step": 4200
    },
    {
      "epoch": 1.05,
      "grad_norm": 5.449370384216309,
      "learning_rate": 0.0001475865431496831,
      "loss": 1.1528,
      "step": 4300
    },
    {
      "epoch": 1.07,
      "grad_norm": 5.242981433868408,
      "learning_rate": 0.00014636762554851292,
      "loss": 1.1707,
      "step": 4400
    },
    {
      "epoch": 1.1,
      "grad_norm": 4.875826835632324,
      "learning_rate": 0.00014514870794734276,
      "loss": 1.1522,
      "step": 4500
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.854842185974121,
      "learning_rate": 0.0001439297903461726,
      "loss": 1.1565,
      "step": 4600
    },
    {
      "epoch": 1.15,
      "grad_norm": 4.513777256011963,
      "learning_rate": 0.00014271087274500245,
      "loss": 1.1752,
      "step": 4700
    },
    {
      "epoch": 1.17,
      "grad_norm": 4.545768737792969,
      "learning_rate": 0.0001414919551438323,
      "loss": 1.1445,
      "step": 4800
    },
    {
      "epoch": 1.19,
      "grad_norm": 4.841604232788086,
      "learning_rate": 0.00014027303754266213,
      "loss": 1.1641,
      "step": 4900
    },
    {
      "epoch": 1.22,
      "grad_norm": 28.02142333984375,
      "learning_rate": 0.00013905411994149196,
      "loss": 1.1876,
      "step": 5000
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.714389324188232,
      "learning_rate": 0.00013783520234032182,
      "loss": 1.1829,
      "step": 5100
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.532966375350952,
      "learning_rate": 0.00013661628473915166,
      "loss": 1.1393,
      "step": 5200
    },
    {
      "epoch": 1.29,
      "grad_norm": 9.468000411987305,
      "learning_rate": 0.00013539736713798147,
      "loss": 1.1764,
      "step": 5300
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.4401273727417,
      "learning_rate": 0.0001341784495368113,
      "loss": 1.1586,
      "step": 5400
    },
    {
      "epoch": 1.34,
      "grad_norm": 4.329448223114014,
      "learning_rate": 0.00013295953193564114,
      "loss": 1.1848,
      "step": 5500
    },
    {
      "epoch": 1.37,
      "grad_norm": 5.715098857879639,
      "learning_rate": 0.000131740614334471,
      "loss": 1.1702,
      "step": 5600
    },
    {
      "epoch": 1.39,
      "grad_norm": 4.313548564910889,
      "learning_rate": 0.00013052169673330083,
      "loss": 1.1554,
      "step": 5700
    },
    {
      "epoch": 1.41,
      "grad_norm": 5.009328365325928,
      "learning_rate": 0.00012930277913213067,
      "loss": 1.1652,
      "step": 5800
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.64432954788208,
      "learning_rate": 0.0001280838615309605,
      "loss": 1.1783,
      "step": 5900
    },
    {
      "epoch": 1.46,
      "grad_norm": 4.431118965148926,
      "learning_rate": 0.00012686494392979037,
      "loss": 1.1674,
      "step": 6000
    },
    {
      "epoch": 1.49,
      "grad_norm": 6.377641201019287,
      "learning_rate": 0.0001256460263286202,
      "loss": 1.1583,
      "step": 6100
    },
    {
      "epoch": 1.51,
      "grad_norm": 5.596806526184082,
      "learning_rate": 0.00012442710872745004,
      "loss": 1.1784,
      "step": 6200
    },
    {
      "epoch": 1.54,
      "grad_norm": 5.714468002319336,
      "learning_rate": 0.00012320819112627987,
      "loss": 1.1517,
      "step": 6300
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.7216851711273193,
      "learning_rate": 0.00012198927352510972,
      "loss": 1.1198,
      "step": 6400
    },
    {
      "epoch": 1.58,
      "grad_norm": 11.906745910644531,
      "learning_rate": 0.00012077035592393954,
      "loss": 1.1454,
      "step": 6500
    },
    {
      "epoch": 1.61,
      "grad_norm": 10.697071075439453,
      "learning_rate": 0.00011955143832276938,
      "loss": 1.144,
      "step": 6600
    },
    {
      "epoch": 1.63,
      "grad_norm": 4.355551719665527,
      "learning_rate": 0.00011833252072159921,
      "loss": 1.1759,
      "step": 6700
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.2338740825653076,
      "learning_rate": 0.00011711360312042908,
      "loss": 1.1292,
      "step": 6800
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.260983943939209,
      "learning_rate": 0.00011589468551925891,
      "loss": 1.1712,
      "step": 6900
    },
    {
      "epoch": 1.71,
      "grad_norm": 5.692660331726074,
      "learning_rate": 0.00011467576791808873,
      "loss": 1.1185,
      "step": 7000
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.8543691635131836,
      "learning_rate": 0.00011345685031691857,
      "loss": 1.1173,
      "step": 7100
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.22641134262085,
      "learning_rate": 0.00011223793271574843,
      "loss": 1.0958,
      "step": 7200
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.465758323669434,
      "learning_rate": 0.00011101901511457827,
      "loss": 1.1413,
      "step": 7300
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.5343852043151855,
      "learning_rate": 0.0001098000975134081,
      "loss": 1.1657,
      "step": 7400
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.754145860671997,
      "learning_rate": 0.00010858117991223794,
      "loss": 1.1164,
      "step": 7500
    },
    {
      "epoch": 1.85,
      "grad_norm": 5.791374206542969,
      "learning_rate": 0.00010736226231106778,
      "loss": 1.11,
      "step": 7600
    },
    {
      "epoch": 1.88,
      "grad_norm": 5.2491044998168945,
      "learning_rate": 0.00010614334470989762,
      "loss": 1.1031,
      "step": 7700
    },
    {
      "epoch": 1.9,
      "grad_norm": 5.841136455535889,
      "learning_rate": 0.00010492442710872745,
      "loss": 1.1359,
      "step": 7800
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.300891876220703,
      "learning_rate": 0.00010370550950755729,
      "loss": 1.105,
      "step": 7900
    },
    {
      "epoch": 1.95,
      "grad_norm": 18.850814819335938,
      "learning_rate": 0.00010248659190638714,
      "loss": 1.1236,
      "step": 8000
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.53237771987915,
      "learning_rate": 0.00010126767430521697,
      "loss": 1.1693,
      "step": 8100
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.499574661254883,
      "learning_rate": 0.00010004875670404681,
      "loss": 1.1266,
      "step": 8200
    },
    {
      "epoch": 2.02,
      "grad_norm": 6.0906782150268555,
      "learning_rate": 9.882983910287666e-05,
      "loss": 1.0224,
      "step": 8300
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.697134256362915,
      "learning_rate": 9.761092150170649e-05,
      "loss": 1.029,
      "step": 8400
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.3268625736236572,
      "learning_rate": 9.639200390053633e-05,
      "loss": 1.0596,
      "step": 8500
    },
    {
      "epoch": 2.1,
      "grad_norm": 4.394504547119141,
      "learning_rate": 9.517308629936616e-05,
      "loss": 1.0377,
      "step": 8600
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.571538209915161,
      "learning_rate": 9.395416869819601e-05,
      "loss": 1.0421,
      "step": 8700
    },
    {
      "epoch": 2.15,
      "grad_norm": 4.720691204071045,
      "learning_rate": 9.273525109702585e-05,
      "loss": 1.0092,
      "step": 8800
    },
    {
      "epoch": 2.17,
      "grad_norm": 4.672593593597412,
      "learning_rate": 9.151633349585568e-05,
      "loss": 1.0317,
      "step": 8900
    },
    {
      "epoch": 2.19,
      "grad_norm": 4.0551676750183105,
      "learning_rate": 9.029741589468552e-05,
      "loss": 1.0187,
      "step": 9000
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.331057548522949,
      "learning_rate": 8.907849829351537e-05,
      "loss": 1.0409,
      "step": 9100
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.8041813373565674,
      "learning_rate": 8.78595806923452e-05,
      "loss": 1.0235,
      "step": 9200
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.5837888717651367,
      "learning_rate": 8.664066309117505e-05,
      "loss": 1.0376,
      "step": 9300
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.2584755420684814,
      "learning_rate": 8.542174549000487e-05,
      "loss": 1.0276,
      "step": 9400
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.4044830799102783,
      "learning_rate": 8.420282788883472e-05,
      "loss": 0.9919,
      "step": 9500
    },
    {
      "epoch": 2.34,
      "grad_norm": 9.874598503112793,
      "learning_rate": 8.298391028766456e-05,
      "loss": 1.0578,
      "step": 9600
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.9973435401916504,
      "learning_rate": 8.17649926864944e-05,
      "loss": 1.0496,
      "step": 9700
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.978276014328003,
      "learning_rate": 8.054607508532424e-05,
      "loss": 1.0284,
      "step": 9800
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.8748230934143066,
      "learning_rate": 7.932715748415408e-05,
      "loss": 1.0186,
      "step": 9900
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.9541988372802734,
      "learning_rate": 7.810823988298391e-05,
      "loss": 1.0148,
      "step": 10000
    },
    {
      "epoch": 2.46,
      "grad_norm": 6.879817962646484,
      "learning_rate": 7.688932228181376e-05,
      "loss": 1.0386,
      "step": 10100
    },
    {
      "epoch": 2.49,
      "grad_norm": 5.0935163497924805,
      "learning_rate": 7.56704046806436e-05,
      "loss": 1.062,
      "step": 10200
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.174520492553711,
      "learning_rate": 7.445148707947343e-05,
      "loss": 1.0352,
      "step": 10300
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.287414312362671,
      "learning_rate": 7.323256947830327e-05,
      "loss": 1.0109,
      "step": 10400
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.772029161453247,
      "learning_rate": 7.201365187713311e-05,
      "loss": 1.0317,
      "step": 10500
    },
    {
      "epoch": 2.58,
      "grad_norm": 4.923951148986816,
      "learning_rate": 7.079473427596295e-05,
      "loss": 1.0245,
      "step": 10600
    },
    {
      "epoch": 2.61,
      "grad_norm": 4.5318145751953125,
      "learning_rate": 6.957581667479278e-05,
      "loss": 1.0294,
      "step": 10700
    },
    {
      "epoch": 2.63,
      "grad_norm": 4.455578327178955,
      "learning_rate": 6.835689907362263e-05,
      "loss": 1.0319,
      "step": 10800
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.300058603286743,
      "learning_rate": 6.713798147245245e-05,
      "loss": 1.034,
      "step": 10900
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.6204030513763428,
      "learning_rate": 6.59190638712823e-05,
      "loss": 1.0316,
      "step": 11000
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.5943262577056885,
      "learning_rate": 6.470014627011214e-05,
      "loss": 1.0202,
      "step": 11100
    },
    {
      "epoch": 2.73,
      "grad_norm": 3.2638843059539795,
      "learning_rate": 6.348122866894199e-05,
      "loss": 1.021,
      "step": 11200
    },
    {
      "epoch": 2.75,
      "grad_norm": 4.499646186828613,
      "learning_rate": 6.226231106777182e-05,
      "loss": 1.0603,
      "step": 11300
    },
    {
      "epoch": 2.78,
      "grad_norm": 5.890535354614258,
      "learning_rate": 6.104339346660166e-05,
      "loss": 1.0047,
      "step": 11400
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.8720669746398926,
      "learning_rate": 5.9824475865431493e-05,
      "loss": 1.0312,
      "step": 11500
    },
    {
      "epoch": 2.83,
      "grad_norm": 5.01943302154541,
      "learning_rate": 5.860555826426134e-05,
      "loss": 1.01,
      "step": 11600
    },
    {
      "epoch": 2.85,
      "grad_norm": 3.8360447883605957,
      "learning_rate": 5.738664066309117e-05,
      "loss": 0.9808,
      "step": 11700
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.308363199234009,
      "learning_rate": 5.616772306192102e-05,
      "loss": 1.0151,
      "step": 11800
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.1738152503967285,
      "learning_rate": 5.4948805460750855e-05,
      "loss": 1.0177,
      "step": 11900
    },
    {
      "epoch": 2.93,
      "grad_norm": 4.674156665802002,
      "learning_rate": 5.3729887859580697e-05,
      "loss": 1.0118,
      "step": 12000
    },
    {
      "epoch": 2.95,
      "grad_norm": 3.4583823680877686,
      "learning_rate": 5.251097025841053e-05,
      "loss": 0.9965,
      "step": 12100
    },
    {
      "epoch": 2.97,
      "grad_norm": 4.7200026512146,
      "learning_rate": 5.1292052657240374e-05,
      "loss": 0.9779,
      "step": 12200
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.56264591217041,
      "learning_rate": 5.007313505607021e-05,
      "loss": 1.0237,
      "step": 12300
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 2.806252949380301e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
