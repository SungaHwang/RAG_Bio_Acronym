{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8204,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 17.73218536376953,
      "learning_rate": 0.00019878108239882984,
      "loss": 1.7616,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 18.07570457458496,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.637,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.526622772216797,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.5481,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 19.315202713012695,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.5888,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 12.252758979797363,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.5614,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 37.18833541870117,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.5704,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.415708541870117,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.5969,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.569807052612305,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.5134,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 10.115227699279785,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.5529,
      "step": 900
    },
    {
      "epoch": 0.24,
      "grad_norm": 16.96780776977539,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.4751,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 17.234973907470703,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.4875,
      "step": 1100
    },
    {
      "epoch": 0.29,
      "grad_norm": 24.946889877319336,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.4963,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.808664798736572,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.5129,
      "step": 1300
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.918356895446777,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.4879,
      "step": 1400
    },
    {
      "epoch": 0.37,
      "grad_norm": 45.21942901611328,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.4515,
      "step": 1500
    },
    {
      "epoch": 0.39,
      "grad_norm": 12.708837509155273,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.443,
      "step": 1600
    },
    {
      "epoch": 0.41,
      "grad_norm": 12.334681510925293,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.4129,
      "step": 1700
    },
    {
      "epoch": 0.44,
      "grad_norm": 13.711291313171387,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.4465,
      "step": 1800
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.211142539978027,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.4076,
      "step": 1900
    },
    {
      "epoch": 0.49,
      "grad_norm": 10.92481517791748,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.4196,
      "step": 2000
    },
    {
      "epoch": 0.51,
      "grad_norm": 25.522842407226562,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.4351,
      "step": 2100
    },
    {
      "epoch": 0.54,
      "grad_norm": 22.61247444152832,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.4046,
      "step": 2200
    },
    {
      "epoch": 0.56,
      "grad_norm": 10.208495140075684,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.4153,
      "step": 2300
    },
    {
      "epoch": 0.59,
      "grad_norm": 9.89745044708252,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.3854,
      "step": 2400
    },
    {
      "epoch": 0.61,
      "grad_norm": 9.183588027954102,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.3339,
      "step": 2500
    },
    {
      "epoch": 0.63,
      "grad_norm": 19.407323837280273,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.3325,
      "step": 2600
    },
    {
      "epoch": 0.66,
      "grad_norm": 10.816115379333496,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.3173,
      "step": 2700
    },
    {
      "epoch": 0.68,
      "grad_norm": 15.548957824707031,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.3908,
      "step": 2800
    },
    {
      "epoch": 0.71,
      "grad_norm": 16.916770935058594,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.3332,
      "step": 2900
    },
    {
      "epoch": 0.73,
      "grad_norm": 8.815616607666016,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.3474,
      "step": 3000
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.77564525604248,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.3692,
      "step": 3100
    },
    {
      "epoch": 0.78,
      "grad_norm": 11.44706916809082,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.3299,
      "step": 3200
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.522964954376221,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.3099,
      "step": 3300
    },
    {
      "epoch": 0.83,
      "grad_norm": 8.385866165161133,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.2421,
      "step": 3400
    },
    {
      "epoch": 0.85,
      "grad_norm": 16.478435516357422,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.2957,
      "step": 3500
    },
    {
      "epoch": 0.88,
      "grad_norm": 12.62771987915039,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.3254,
      "step": 3600
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.302328109741211,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.3085,
      "step": 3700
    },
    {
      "epoch": 0.93,
      "grad_norm": 7.931312084197998,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.2864,
      "step": 3800
    },
    {
      "epoch": 0.95,
      "grad_norm": 18.68117904663086,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.2593,
      "step": 3900
    },
    {
      "epoch": 0.98,
      "grad_norm": 6.169618606567383,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.2734,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.077672004699707,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.3123,
      "step": 4100
    },
    {
      "epoch": 1.02,
      "grad_norm": 6.987156867980957,
      "learning_rate": 0.00014880546075085325,
      "loss": 1.1411,
      "step": 4200
    },
    {
      "epoch": 1.05,
      "grad_norm": 5.449370384216309,
      "learning_rate": 0.0001475865431496831,
      "loss": 1.1528,
      "step": 4300
    },
    {
      "epoch": 1.07,
      "grad_norm": 5.242981433868408,
      "learning_rate": 0.00014636762554851292,
      "loss": 1.1707,
      "step": 4400
    },
    {
      "epoch": 1.1,
      "grad_norm": 4.875826835632324,
      "learning_rate": 0.00014514870794734276,
      "loss": 1.1522,
      "step": 4500
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.854842185974121,
      "learning_rate": 0.0001439297903461726,
      "loss": 1.1565,
      "step": 4600
    },
    {
      "epoch": 1.15,
      "grad_norm": 4.513777256011963,
      "learning_rate": 0.00014271087274500245,
      "loss": 1.1752,
      "step": 4700
    },
    {
      "epoch": 1.17,
      "grad_norm": 4.545768737792969,
      "learning_rate": 0.0001414919551438323,
      "loss": 1.1445,
      "step": 4800
    },
    {
      "epoch": 1.19,
      "grad_norm": 4.841604232788086,
      "learning_rate": 0.00014027303754266213,
      "loss": 1.1641,
      "step": 4900
    },
    {
      "epoch": 1.22,
      "grad_norm": 28.02142333984375,
      "learning_rate": 0.00013905411994149196,
      "loss": 1.1876,
      "step": 5000
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.714389324188232,
      "learning_rate": 0.00013783520234032182,
      "loss": 1.1829,
      "step": 5100
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.532966375350952,
      "learning_rate": 0.00013661628473915166,
      "loss": 1.1393,
      "step": 5200
    },
    {
      "epoch": 1.29,
      "grad_norm": 9.468000411987305,
      "learning_rate": 0.00013539736713798147,
      "loss": 1.1764,
      "step": 5300
    },
    {
      "epoch": 1.32,
      "grad_norm": 9.4401273727417,
      "learning_rate": 0.0001341784495368113,
      "loss": 1.1586,
      "step": 5400
    },
    {
      "epoch": 1.34,
      "grad_norm": 4.329448223114014,
      "learning_rate": 0.00013295953193564114,
      "loss": 1.1848,
      "step": 5500
    },
    {
      "epoch": 1.37,
      "grad_norm": 5.715098857879639,
      "learning_rate": 0.000131740614334471,
      "loss": 1.1702,
      "step": 5600
    },
    {
      "epoch": 1.39,
      "grad_norm": 4.313548564910889,
      "learning_rate": 0.00013052169673330083,
      "loss": 1.1554,
      "step": 5700
    },
    {
      "epoch": 1.41,
      "grad_norm": 5.009328365325928,
      "learning_rate": 0.00012930277913213067,
      "loss": 1.1652,
      "step": 5800
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.64432954788208,
      "learning_rate": 0.0001280838615309605,
      "loss": 1.1783,
      "step": 5900
    },
    {
      "epoch": 1.46,
      "grad_norm": 4.431118965148926,
      "learning_rate": 0.00012686494392979037,
      "loss": 1.1674,
      "step": 6000
    },
    {
      "epoch": 1.49,
      "grad_norm": 6.377641201019287,
      "learning_rate": 0.0001256460263286202,
      "loss": 1.1583,
      "step": 6100
    },
    {
      "epoch": 1.51,
      "grad_norm": 5.596806526184082,
      "learning_rate": 0.00012442710872745004,
      "loss": 1.1784,
      "step": 6200
    },
    {
      "epoch": 1.54,
      "grad_norm": 5.714468002319336,
      "learning_rate": 0.00012320819112627987,
      "loss": 1.1517,
      "step": 6300
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.7216851711273193,
      "learning_rate": 0.00012198927352510972,
      "loss": 1.1198,
      "step": 6400
    },
    {
      "epoch": 1.58,
      "grad_norm": 11.906745910644531,
      "learning_rate": 0.00012077035592393954,
      "loss": 1.1454,
      "step": 6500
    },
    {
      "epoch": 1.61,
      "grad_norm": 10.697071075439453,
      "learning_rate": 0.00011955143832276938,
      "loss": 1.144,
      "step": 6600
    },
    {
      "epoch": 1.63,
      "grad_norm": 4.355551719665527,
      "learning_rate": 0.00011833252072159921,
      "loss": 1.1759,
      "step": 6700
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.2338740825653076,
      "learning_rate": 0.00011711360312042908,
      "loss": 1.1292,
      "step": 6800
    },
    {
      "epoch": 1.68,
      "grad_norm": 7.260983943939209,
      "learning_rate": 0.00011589468551925891,
      "loss": 1.1712,
      "step": 6900
    },
    {
      "epoch": 1.71,
      "grad_norm": 5.692660331726074,
      "learning_rate": 0.00011467576791808873,
      "loss": 1.1185,
      "step": 7000
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.8543691635131836,
      "learning_rate": 0.00011345685031691857,
      "loss": 1.1173,
      "step": 7100
    },
    {
      "epoch": 1.76,
      "grad_norm": 6.22641134262085,
      "learning_rate": 0.00011223793271574843,
      "loss": 1.0958,
      "step": 7200
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.465758323669434,
      "learning_rate": 0.00011101901511457827,
      "loss": 1.1413,
      "step": 7300
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.5343852043151855,
      "learning_rate": 0.0001098000975134081,
      "loss": 1.1657,
      "step": 7400
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.754145860671997,
      "learning_rate": 0.00010858117991223794,
      "loss": 1.1164,
      "step": 7500
    },
    {
      "epoch": 1.85,
      "grad_norm": 5.791374206542969,
      "learning_rate": 0.00010736226231106778,
      "loss": 1.11,
      "step": 7600
    },
    {
      "epoch": 1.88,
      "grad_norm": 5.2491044998168945,
      "learning_rate": 0.00010614334470989762,
      "loss": 1.1031,
      "step": 7700
    },
    {
      "epoch": 1.9,
      "grad_norm": 5.841136455535889,
      "learning_rate": 0.00010492442710872745,
      "loss": 1.1359,
      "step": 7800
    },
    {
      "epoch": 1.93,
      "grad_norm": 10.300891876220703,
      "learning_rate": 0.00010370550950755729,
      "loss": 1.105,
      "step": 7900
    },
    {
      "epoch": 1.95,
      "grad_norm": 18.850814819335938,
      "learning_rate": 0.00010248659190638714,
      "loss": 1.1236,
      "step": 8000
    },
    {
      "epoch": 1.97,
      "grad_norm": 4.53237771987915,
      "learning_rate": 0.00010126767430521697,
      "loss": 1.1693,
      "step": 8100
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.499574661254883,
      "learning_rate": 0.00010004875670404681,
      "loss": 1.1266,
      "step": 8200
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 1.870344753185587e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
