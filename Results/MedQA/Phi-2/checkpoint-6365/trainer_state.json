{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 6365,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 0.2844811975955963,
      "learning_rate": 0.00010471204188481676,
      "loss": 1.6541,
      "step": 100
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.25125688314437866,
      "learning_rate": 0.00019999895137366743,
      "loss": 1.3287,
      "step": 200
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1858229786157608,
      "learning_rate": 0.00019984622768244757,
      "loss": 1.2897,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1980711668729782,
      "learning_rate": 0.00019943503738051928,
      "loss": 1.2563,
      "step": 400
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18266813457012177,
      "learning_rate": 0.00019876644489431278,
      "loss": 1.2652,
      "step": 500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.18491242825984955,
      "learning_rate": 0.00019784218097358052,
      "loss": 1.2501,
      "step": 600
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.19981060922145844,
      "learning_rate": 0.0001966646382110978,
      "loss": 1.2319,
      "step": 700
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1758306473493576,
      "learning_rate": 0.00019523686484908522,
      "loss": 1.2169,
      "step": 800
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.17708583176136017,
      "learning_rate": 0.0001935625568883863,
      "loss": 1.2289,
      "step": 900
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.17865070700645447,
      "learning_rate": 0.00019164604852082707,
      "loss": 1.2176,
      "step": 1000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.17212225496768951,
      "learning_rate": 0.00018949230090952463,
      "loss": 1.2237,
      "step": 1100
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1903826743364334,
      "learning_rate": 0.0001871068893461884,
      "loss": 1.2196,
      "step": 1200
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.16538618505001068,
      "learning_rate": 0.00018449598881865943,
      "loss": 1.1873,
      "step": 1300
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.1642477661371231,
      "learning_rate": 0.00018166635802604856,
      "loss": 1.1623,
      "step": 1400
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.1724044382572174,
      "learning_rate": 0.00017862532188285174,
      "loss": 1.1592,
      "step": 1500
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.16514278948307037,
      "learning_rate": 0.00017538075255733428,
      "loss": 1.1607,
      "step": 1600
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.16334109008312225,
      "learning_rate": 0.00017194104909326821,
      "loss": 1.1692,
      "step": 1700
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.17453216016292572,
      "learning_rate": 0.00016831511566777502,
      "loss": 1.155,
      "step": 1800
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.1875295788049698,
      "learning_rate": 0.00016451233854155675,
      "loss": 1.1685,
      "step": 1900
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.171899676322937,
      "learning_rate": 0.0001605425617611829,
      "loss": 1.1399,
      "step": 2000
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.17617136240005493,
      "learning_rate": 0.00015641606167633143,
      "loss": 1.1474,
      "step": 2100
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.18353264033794403,
      "learning_rate": 0.0001521435203379498,
      "loss": 1.1416,
      "step": 2200
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.18012943863868713,
      "learning_rate": 0.0001477359978461989,
      "loss": 1.1645,
      "step": 2300
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.17715230584144592,
      "learning_rate": 0.00014320490371976053,
      "loss": 1.1509,
      "step": 2400
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.18468010425567627,
      "learning_rate": 0.00013856196736062465,
      "loss": 1.1395,
      "step": 2500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.1595374047756195,
      "learning_rate": 0.00013381920769081103,
      "loss": 1.1288,
      "step": 2600
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.1755250245332718,
      "learning_rate": 0.000128988902039626,
      "loss": 1.0846,
      "step": 2700
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.19259013235569,
      "learning_rate": 0.0001240835543619944,
      "loss": 1.1017,
      "step": 2800
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.18124377727508545,
      "learning_rate": 0.00011911586287013725,
      "loss": 1.0957,
      "step": 2900
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.17817743122577667,
      "learning_rate": 0.00011409868716238636,
      "loss": 1.0836,
      "step": 3000
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.17777478694915771,
      "learning_rate": 0.00010904501493422723,
      "loss": 1.0839,
      "step": 3100
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.18359878659248352,
      "learning_rate": 0.00010396792835774347,
      "loss": 1.087,
      "step": 3200
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.1703389286994934,
      "learning_rate": 9.88805702164949e-05,
      "loss": 1.08,
      "step": 3300
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.18015269935131073,
      "learning_rate": 9.379610988349398e-05,
      "loss": 1.0798,
      "step": 3400
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.16116322576999664,
      "learning_rate": 8.872770923035114e-05,
      "loss": 1.0861,
      "step": 3500
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.17823782563209534,
      "learning_rate": 8.368848855583918e-05,
      "loss": 1.0854,
      "step": 3600
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.1788487434387207,
      "learning_rate": 7.869149262207472e-05,
      "loss": 1.0782,
      "step": 3700
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.1947079300880432,
      "learning_rate": 7.374965688623726e-05,
      "loss": 1.0896,
      "step": 3800
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.23577934503555298,
      "learning_rate": 6.887577401524036e-05,
      "loss": 1.0511,
      "step": 3900
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.2364896684885025,
      "learning_rate": 6.408246077003633e-05,
      "loss": 1.0461,
      "step": 4000
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.24968989193439484,
      "learning_rate": 5.938212534527916e-05,
      "loss": 1.031,
      "step": 4100
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.24221834540367126,
      "learning_rate": 5.478693524889209e-05,
      "loss": 1.0456,
      "step": 4200
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.25041431188583374,
      "learning_rate": 5.030878580468793e-05,
      "loss": 1.0339,
      "step": 4300
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.25713977217674255,
      "learning_rate": 4.59592693595781e-05,
      "loss": 1.033,
      "step": 4400
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.22535823285579681,
      "learning_rate": 4.174964527508161e-05,
      "loss": 1.0382,
      "step": 4500
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.23687955737113953,
      "learning_rate": 3.7690810780815776e-05,
      "loss": 1.0304,
      "step": 4600
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.2646500766277313,
      "learning_rate": 3.379327276541834e-05,
      "loss": 1.0361,
      "step": 4700
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.24461719393730164,
      "learning_rate": 3.0067120577924624e-05,
      "loss": 1.0287,
      "step": 4800
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.24575097858905792,
      "learning_rate": 2.652199991000712e-05,
      "loss": 1.0165,
      "step": 4900
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.2704198360443115,
      "learning_rate": 2.3167087826687238e-05,
      "loss": 1.0443,
      "step": 5000
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.21815961599349976,
      "learning_rate": 2.0011069010156092e-05,
      "loss": 1.0171,
      "step": 5100
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.22965389490127563,
      "learning_rate": 1.70621132782002e-05,
      "loss": 1.0055,
      "step": 5200
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.21531689167022705,
      "learning_rate": 1.43278544354296e-05,
      "loss": 1.006,
      "step": 5300
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.21996274590492249,
      "learning_rate": 1.1815370512054192e-05,
      "loss": 1.0181,
      "step": 5400
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.22154979407787323,
      "learning_rate": 9.531165441364299e-06,
      "loss": 0.995,
      "step": 5500
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.2442532628774643,
      "learning_rate": 7.4811522233448894e-06,
      "loss": 1.0137,
      "step": 5600
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.23518690466880798,
      "learning_rate": 5.670637618007502e-06,
      "loss": 1.0084,
      "step": 5700
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.23020270466804504,
      "learning_rate": 4.104308408063329e-06,
      "loss": 0.998,
      "step": 5800
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.23069313168525696,
      "learning_rate": 2.7862192664984686e-06,
      "loss": 1.0073,
      "step": 5900
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.22858023643493652,
      "learning_rate": 1.7197822604579694e-06,
      "loss": 0.9903,
      "step": 6000
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.22899983823299408,
      "learning_rate": 9.077580186093504e-07,
      "loss": 1.006,
      "step": 6100
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.2196677029132843,
      "learning_rate": 3.5224858485027877e-07,
      "loss": 1.0119,
      "step": 6200
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.21830548346042633,
      "learning_rate": 5.4691976859455595e-08,
      "loss": 0.9962,
      "step": 6300
    }
  ],
  "logging_steps": 100,
  "max_steps": 6365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 2.1912712892700672e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
