{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 5092,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 0.6959501504898071,
      "learning_rate": 0.00019607227022780835,
      "loss": 1.256,
      "step": 100
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.720913290977478,
      "learning_rate": 0.00019214454045561667,
      "loss": 1.195,
      "step": 200
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6791186928749084,
      "learning_rate": 0.000188216810683425,
      "loss": 1.1702,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7613677978515625,
      "learning_rate": 0.0001842890809112333,
      "loss": 1.1438,
      "step": 400
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7731598019599915,
      "learning_rate": 0.00018036135113904165,
      "loss": 1.1668,
      "step": 500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7766410708427429,
      "learning_rate": 0.00017643362136684996,
      "loss": 1.1526,
      "step": 600
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8210713863372803,
      "learning_rate": 0.00017250589159465828,
      "loss": 1.1381,
      "step": 700
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7438023090362549,
      "learning_rate": 0.00016857816182246662,
      "loss": 1.1209,
      "step": 800
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.775532066822052,
      "learning_rate": 0.00016465043205027494,
      "loss": 1.1414,
      "step": 900
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.755506694316864,
      "learning_rate": 0.00016072270227808329,
      "loss": 1.129,
      "step": 1000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7482151389122009,
      "learning_rate": 0.0001567949725058916,
      "loss": 1.1353,
      "step": 1100
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8239672183990479,
      "learning_rate": 0.00015286724273369992,
      "loss": 1.1336,
      "step": 1200
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6004689931869507,
      "learning_rate": 0.00014893951296150826,
      "loss": 1.0768,
      "step": 1300
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8705707788467407,
      "learning_rate": 0.00014501178318931658,
      "loss": 0.9609,
      "step": 1400
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.694466233253479,
      "learning_rate": 0.00014108405341712492,
      "loss": 0.9669,
      "step": 1500
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.729660153388977,
      "learning_rate": 0.0001371563236449332,
      "loss": 0.9682,
      "step": 1600
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7605364322662354,
      "learning_rate": 0.00013322859387274156,
      "loss": 0.9756,
      "step": 1700
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6991492509841919,
      "learning_rate": 0.0001293008641005499,
      "loss": 0.9682,
      "step": 1800
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7429937124252319,
      "learning_rate": 0.00012537313432835822,
      "loss": 0.9799,
      "step": 1900
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.8781117796897888,
      "learning_rate": 0.00012144540455616653,
      "loss": 0.956,
      "step": 2000
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6884232759475708,
      "learning_rate": 0.00011751767478397486,
      "loss": 0.9654,
      "step": 2100
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7807583808898926,
      "learning_rate": 0.0001135899450117832,
      "loss": 0.9631,
      "step": 2200
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.8298517465591431,
      "learning_rate": 0.00010966221523959153,
      "loss": 0.9823,
      "step": 2300
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.8491970896720886,
      "learning_rate": 0.00010573448546739986,
      "loss": 0.9679,
      "step": 2400
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.8052304983139038,
      "learning_rate": 0.00010180675569520817,
      "loss": 0.96,
      "step": 2500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.9106615781784058,
      "learning_rate": 9.78790259230165e-05,
      "loss": 0.8529,
      "step": 2600
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.9054208993911743,
      "learning_rate": 9.395129615082483e-05,
      "loss": 0.7385,
      "step": 2700
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.9281930327415466,
      "learning_rate": 9.002356637863315e-05,
      "loss": 0.7418,
      "step": 2800
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.9220802187919617,
      "learning_rate": 8.609583660644148e-05,
      "loss": 0.7374,
      "step": 2900
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.0016671419143677,
      "learning_rate": 8.21681068342498e-05,
      "loss": 0.7366,
      "step": 3000
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.9155464768409729,
      "learning_rate": 7.824037706205814e-05,
      "loss": 0.7429,
      "step": 3100
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.8692630529403687,
      "learning_rate": 7.431264728986647e-05,
      "loss": 0.7408,
      "step": 3200
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.8461183309555054,
      "learning_rate": 7.038491751767479e-05,
      "loss": 0.7392,
      "step": 3300
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.9914370775222778,
      "learning_rate": 6.645718774548312e-05,
      "loss": 0.7378,
      "step": 3400
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.8399602174758911,
      "learning_rate": 6.252945797329144e-05,
      "loss": 0.7468,
      "step": 3500
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.8739191889762878,
      "learning_rate": 5.860172820109977e-05,
      "loss": 0.7383,
      "step": 3600
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.8270878195762634,
      "learning_rate": 5.467399842890809e-05,
      "loss": 0.7392,
      "step": 3700
    },
    {
      "epoch": 2.99,
      "grad_norm": 1.0601989030838013,
      "learning_rate": 5.074626865671642e-05,
      "loss": 0.7456,
      "step": 3800
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.4674897193908691,
      "learning_rate": 4.681853888452475e-05,
      "loss": 0.5844,
      "step": 3900
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.2247552871704102,
      "learning_rate": 4.289080911233307e-05,
      "loss": 0.5196,
      "step": 4000
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.2171964645385742,
      "learning_rate": 3.8963079340141403e-05,
      "loss": 0.5157,
      "step": 4100
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.464445948600769,
      "learning_rate": 3.503534956794973e-05,
      "loss": 0.528,
      "step": 4200
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.3431334495544434,
      "learning_rate": 3.110761979575805e-05,
      "loss": 0.5125,
      "step": 4300
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.287269115447998,
      "learning_rate": 2.7179890023566377e-05,
      "loss": 0.5052,
      "step": 4400
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.3998991250991821,
      "learning_rate": 2.3252160251374708e-05,
      "loss": 0.517,
      "step": 4500
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.5032458305358887,
      "learning_rate": 1.9324430479183035e-05,
      "loss": 0.5111,
      "step": 4600
    },
    {
      "epoch": 3.69,
      "grad_norm": 1.3615639209747314,
      "learning_rate": 1.539670070699136e-05,
      "loss": 0.5116,
      "step": 4700
    },
    {
      "epoch": 3.77,
      "grad_norm": 1.28766667842865,
      "learning_rate": 1.1468970934799687e-05,
      "loss": 0.5085,
      "step": 4800
    },
    {
      "epoch": 3.85,
      "grad_norm": 1.492654800415039,
      "learning_rate": 7.541241162608014e-06,
      "loss": 0.5074,
      "step": 4900
    },
    {
      "epoch": 3.93,
      "grad_norm": 1.5278096199035645,
      "learning_rate": 3.6135113904163394e-06,
      "loss": 0.5189,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 5092,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 4.686876536389632e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
