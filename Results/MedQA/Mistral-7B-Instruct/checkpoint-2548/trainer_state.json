{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 2548,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16,
      "grad_norm": 0.9232600331306458,
      "learning_rate": 0.00019215070643642074,
      "loss": 1.04,
      "step": 100
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9510466456413269,
      "learning_rate": 0.00018430141287284146,
      "loss": 0.9768,
      "step": 200
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9479876160621643,
      "learning_rate": 0.0001764521193092622,
      "loss": 0.9806,
      "step": 300
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9236558675765991,
      "learning_rate": 0.0001686028257456829,
      "loss": 0.9564,
      "step": 400
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8719210028648376,
      "learning_rate": 0.00016075353218210364,
      "loss": 0.962,
      "step": 500
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9606930017471313,
      "learning_rate": 0.00015290423861852434,
      "loss": 0.9612,
      "step": 600
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.7101446986198425,
      "learning_rate": 0.00014505494505494506,
      "loss": 0.8397,
      "step": 700
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.734800398349762,
      "learning_rate": 0.0001372056514913658,
      "loss": 0.783,
      "step": 800
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.7657638192176819,
      "learning_rate": 0.00012935635792778652,
      "loss": 0.7896,
      "step": 900
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7637599110603333,
      "learning_rate": 0.00012150706436420723,
      "loss": 0.7877,
      "step": 1000
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7399865984916687,
      "learning_rate": 0.00011365777080062794,
      "loss": 0.7861,
      "step": 1100
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7618964910507202,
      "learning_rate": 0.00010580847723704868,
      "loss": 0.7979,
      "step": 1200
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.0159019231796265,
      "learning_rate": 9.79591836734694e-05,
      "loss": 0.746,
      "step": 1300
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.3066840171813965,
      "learning_rate": 9.010989010989012e-05,
      "loss": 0.562,
      "step": 1400
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.1279789209365845,
      "learning_rate": 8.226059654631083e-05,
      "loss": 0.5653,
      "step": 1500
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.2171123027801514,
      "learning_rate": 7.441130298273156e-05,
      "loss": 0.5666,
      "step": 1600
    },
    {
      "epoch": 2.67,
      "grad_norm": 1.0877729654312134,
      "learning_rate": 6.656200941915228e-05,
      "loss": 0.5693,
      "step": 1700
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.1045609712600708,
      "learning_rate": 5.8712715855572997e-05,
      "loss": 0.5713,
      "step": 1800
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.2938413619995117,
      "learning_rate": 5.086342229199372e-05,
      "loss": 0.5664,
      "step": 1900
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.607444405555725,
      "learning_rate": 4.301412872841444e-05,
      "loss": 0.3897,
      "step": 2000
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.5265319347381592,
      "learning_rate": 3.516483516483517e-05,
      "loss": 0.3686,
      "step": 2100
    },
    {
      "epoch": 3.45,
      "grad_norm": 1.601913332939148,
      "learning_rate": 2.731554160125589e-05,
      "loss": 0.3604,
      "step": 2200
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.4091261625289917,
      "learning_rate": 1.946624803767661e-05,
      "loss": 0.3618,
      "step": 2300
    },
    {
      "epoch": 3.77,
      "grad_norm": 1.4593627452850342,
      "learning_rate": 1.1616954474097332e-05,
      "loss": 0.3594,
      "step": 2400
    },
    {
      "epoch": 3.92,
      "grad_norm": 1.588781476020813,
      "learning_rate": 3.767660910518053e-06,
      "loss": 0.3604,
      "step": 2500
    }
  ],
  "logging_steps": 100,
  "max_steps": 2548,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 5.2699854005334835e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
