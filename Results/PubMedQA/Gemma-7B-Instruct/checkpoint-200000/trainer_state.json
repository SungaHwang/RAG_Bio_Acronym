{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 2.4646289348602295,
      "learning_rate": 0.0001999999210431752,
      "loss": 1.9027,
      "step": 100
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.9353413581848145,
      "learning_rate": 0.00019999968417282543,
      "loss": 1.7616,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.399960994720459,
      "learning_rate": 0.00019999928938932473,
      "loss": 1.7111,
      "step": 300
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.996699094772339,
      "learning_rate": 0.0001999987366932966,
      "loss": 1.6986,
      "step": 400
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5676631927490234,
      "learning_rate": 0.0001999980260856137,
      "loss": 1.7024,
      "step": 500
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.7441439628601074,
      "learning_rate": 0.00019999715756739833,
      "loss": 1.6863,
      "step": 600
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.4471466541290283,
      "learning_rate": 0.00019999613114002186,
      "loss": 1.7191,
      "step": 700
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.681846857070923,
      "learning_rate": 0.00019999494680510518,
      "loss": 1.6885,
      "step": 800
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.772782802581787,
      "learning_rate": 0.0001999936045645186,
      "loss": 1.6871,
      "step": 900
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.5385632514953613,
      "learning_rate": 0.00019999210442038162,
      "loss": 1.6805,
      "step": 1000
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.596430778503418,
      "learning_rate": 0.0001999904463750632,
      "loss": 1.6898,
      "step": 1100
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3756628036499023,
      "learning_rate": 0.00019998863043118163,
      "loss": 1.6814,
      "step": 1200
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.2058486938476562,
      "learning_rate": 0.00019998665659160452,
      "loss": 1.7157,
      "step": 1300
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.9771857261657715,
      "learning_rate": 0.00019998452485944887,
      "loss": 1.6864,
      "step": 1400
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.3066372871398926,
      "learning_rate": 0.0001999822352380809,
      "loss": 1.7127,
      "step": 1500
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.364581823348999,
      "learning_rate": 0.0001999797877311163,
      "loss": 1.7244,
      "step": 1600
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4145572185516357,
      "learning_rate": 0.00019997718234242,
      "loss": 1.7178,
      "step": 1700
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.8330068588256836,
      "learning_rate": 0.00019997441907610624,
      "loss": 1.7014,
      "step": 1800
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.549238920211792,
      "learning_rate": 0.00019997149793653861,
      "loss": 1.704,
      "step": 1900
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.4594833850860596,
      "learning_rate": 0.00019996841892833,
      "loss": 1.7193,
      "step": 2000
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.0242390632629395,
      "learning_rate": 0.00019996518205634258,
      "loss": 1.7206,
      "step": 2100
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.368825674057007,
      "learning_rate": 0.00019996178732568782,
      "loss": 1.7221,
      "step": 2200
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.429276704788208,
      "learning_rate": 0.00019995823474172644,
      "loss": 1.708,
      "step": 2300
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.989872932434082,
      "learning_rate": 0.00019995452431006844,
      "loss": 1.7198,
      "step": 2400
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.8670952320098877,
      "learning_rate": 0.00019995065603657316,
      "loss": 1.7177,
      "step": 2500
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.3113789558410645,
      "learning_rate": 0.0001999466299273491,
      "loss": 1.724,
      "step": 2600
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.028704881668091,
      "learning_rate": 0.000199942445988754,
      "loss": 1.7232,
      "step": 2700
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.8329029083251953,
      "learning_rate": 0.00019993810422739495,
      "loss": 1.6935,
      "step": 2800
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.9371461868286133,
      "learning_rate": 0.0001999336046501281,
      "loss": 1.6976,
      "step": 2900
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.910581588745117,
      "learning_rate": 0.00019992894726405893,
      "loss": 1.7191,
      "step": 3000
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.527749538421631,
      "learning_rate": 0.0001999241320765421,
      "loss": 1.7225,
      "step": 3100
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.4215738773345947,
      "learning_rate": 0.00019991915909518143,
      "loss": 1.7082,
      "step": 3200
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.092978000640869,
      "learning_rate": 0.00019991402832782997,
      "loss": 1.7367,
      "step": 3300
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.9647247791290283,
      "learning_rate": 0.0001999087397825899,
      "loss": 1.7292,
      "step": 3400
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.9415109157562256,
      "learning_rate": 0.0001999032934678125,
      "loss": 1.709,
      "step": 3500
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.9324426651000977,
      "learning_rate": 0.00019989768939209824,
      "loss": 1.7053,
      "step": 3600
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.028543472290039,
      "learning_rate": 0.00019989192756429683,
      "loss": 1.7427,
      "step": 3700
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.7304532527923584,
      "learning_rate": 0.00019988600799350685,
      "loss": 1.7204,
      "step": 3800
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.8390755653381348,
      "learning_rate": 0.0001998799306890762,
      "loss": 1.7418,
      "step": 3900
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.713179588317871,
      "learning_rate": 0.00019987369566060176,
      "loss": 1.713,
      "step": 4000
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.8767614364624023,
      "learning_rate": 0.00019986730291792946,
      "loss": 1.7145,
      "step": 4100
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.253901481628418,
      "learning_rate": 0.00019986075247115432,
      "loss": 1.7518,
      "step": 4200
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.570359468460083,
      "learning_rate": 0.0001998540443306204,
      "loss": 1.7026,
      "step": 4300
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.2918505668640137,
      "learning_rate": 0.0001998471785069208,
      "loss": 1.7072,
      "step": 4400
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.800170660018921,
      "learning_rate": 0.00019984015501089752,
      "loss": 1.7607,
      "step": 4500
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.6801931858062744,
      "learning_rate": 0.00019983297385364166,
      "loss": 1.7005,
      "step": 4600
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.090244293212891,
      "learning_rate": 0.00019982563504649327,
      "loss": 1.7275,
      "step": 4700
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.955674648284912,
      "learning_rate": 0.00019981813860104128,
      "loss": 1.716,
      "step": 4800
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.577115058898926,
      "learning_rate": 0.00019981048452912364,
      "loss": 1.7389,
      "step": 4900
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.1103482246398926,
      "learning_rate": 0.00019980267284282717,
      "loss": 1.7204,
      "step": 5000
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.878068685531616,
      "learning_rate": 0.00019979470355448756,
      "loss": 1.7072,
      "step": 5100
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.1484386920928955,
      "learning_rate": 0.00019978657667668942,
      "loss": 1.7175,
      "step": 5200
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.756289482116699,
      "learning_rate": 0.00019977829222226623,
      "loss": 1.7121,
      "step": 5300
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.799133777618408,
      "learning_rate": 0.00019976985020430022,
      "loss": 1.7056,
      "step": 5400
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.1361985206604004,
      "learning_rate": 0.00019976125063612252,
      "loss": 1.7379,
      "step": 5500
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.348189115524292,
      "learning_rate": 0.00019975249353131305,
      "loss": 1.7011,
      "step": 5600
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.4772064685821533,
      "learning_rate": 0.0001997435789037004,
      "loss": 1.7196,
      "step": 5700
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.0800728797912598,
      "learning_rate": 0.00019973450676736204,
      "loss": 1.7442,
      "step": 5800
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.58211350440979,
      "learning_rate": 0.00019972527713662408,
      "loss": 1.7454,
      "step": 5900
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.8608205318450928,
      "learning_rate": 0.0001997158900260614,
      "loss": 1.7394,
      "step": 6000
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.0571181774139404,
      "learning_rate": 0.00019970634545049751,
      "loss": 1.7346,
      "step": 6100
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.019630193710327,
      "learning_rate": 0.0001996966434250046,
      "loss": 1.7574,
      "step": 6200
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.262937068939209,
      "learning_rate": 0.0001996867839649035,
      "loss": 1.7365,
      "step": 6300
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.0153841972351074,
      "learning_rate": 0.00019967676708576362,
      "loss": 1.7439,
      "step": 6400
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.899113178253174,
      "learning_rate": 0.00019966659280340297,
      "loss": 1.7247,
      "step": 6500
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.930922508239746,
      "learning_rate": 0.00019965626113388824,
      "loss": 1.7131,
      "step": 6600
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.148608922958374,
      "learning_rate": 0.0001996457720935344,
      "loss": 1.7535,
      "step": 6700
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.1402857303619385,
      "learning_rate": 0.00019963512569890512,
      "loss": 1.7388,
      "step": 6800
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.4450058937072754,
      "learning_rate": 0.00019962432196681258,
      "loss": 1.7121,
      "step": 6900
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.678384780883789,
      "learning_rate": 0.00019961336091431727,
      "loss": 1.7099,
      "step": 7000
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.1707119941711426,
      "learning_rate": 0.00019960224255872818,
      "loss": 1.7227,
      "step": 7100
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.343381404876709,
      "learning_rate": 0.00019959096691760282,
      "loss": 1.7242,
      "step": 7200
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.964857816696167,
      "learning_rate": 0.00019957953400874683,
      "loss": 1.7443,
      "step": 7300
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.047729969024658,
      "learning_rate": 0.00019956794385021442,
      "loss": 1.7486,
      "step": 7400
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.831636667251587,
      "learning_rate": 0.00019955619646030802,
      "loss": 1.7346,
      "step": 7500
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.2290375232696533,
      "learning_rate": 0.00019954429185757832,
      "loss": 1.7445,
      "step": 7600
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.747034788131714,
      "learning_rate": 0.00019953223006082435,
      "loss": 1.7375,
      "step": 7700
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.902557373046875,
      "learning_rate": 0.00019952001108909336,
      "loss": 1.7387,
      "step": 7800
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.7088422775268555,
      "learning_rate": 0.0001995076349616807,
      "loss": 1.7447,
      "step": 7900
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.0328433513641357,
      "learning_rate": 0.00019949510169813003,
      "loss": 1.7208,
      "step": 8000
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.9899566173553467,
      "learning_rate": 0.00019948241131823304,
      "loss": 1.7398,
      "step": 8100
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.7697649002075195,
      "learning_rate": 0.0001994695638420296,
      "loss": 1.7146,
      "step": 8200
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.678133964538574,
      "learning_rate": 0.00019945655928980762,
      "loss": 1.7205,
      "step": 8300
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.040067434310913,
      "learning_rate": 0.00019944339768210306,
      "loss": 1.7535,
      "step": 8400
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.2442705631256104,
      "learning_rate": 0.0001994300790396999,
      "loss": 1.7218,
      "step": 8500
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.5851221084594727,
      "learning_rate": 0.0001994166033836301,
      "loss": 1.7274,
      "step": 8600
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.366919755935669,
      "learning_rate": 0.00019940297073517353,
      "loss": 1.7356,
      "step": 8700
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.159445285797119,
      "learning_rate": 0.00019938918111585805,
      "loss": 1.748,
      "step": 8800
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.653900384902954,
      "learning_rate": 0.0001993752345474593,
      "loss": 1.7161,
      "step": 8900
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.785148859024048,
      "learning_rate": 0.00019936113105200085,
      "loss": 1.7337,
      "step": 9000
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.2125070095062256,
      "learning_rate": 0.00019934687065175405,
      "loss": 1.7477,
      "step": 9100
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.6362364292144775,
      "learning_rate": 0.000199332453369238,
      "loss": 1.7375,
      "step": 9200
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.954834461212158,
      "learning_rate": 0.00019931787922721953,
      "loss": 1.7436,
      "step": 9300
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.7478229999542236,
      "learning_rate": 0.00019930314824871326,
      "loss": 1.7178,
      "step": 9400
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.474243402481079,
      "learning_rate": 0.00019928826045698136,
      "loss": 1.7235,
      "step": 9500
    },
    {
      "epoch": 0.19,
      "grad_norm": 5.6015825271606445,
      "learning_rate": 0.00019927321587553376,
      "loss": 1.7422,
      "step": 9600
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.6645076274871826,
      "learning_rate": 0.00019925801452812781,
      "loss": 1.733,
      "step": 9700
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.90571665763855,
      "learning_rate": 0.0001992426564387686,
      "loss": 1.7605,
      "step": 9800
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.8741486072540283,
      "learning_rate": 0.0001992271416317086,
      "loss": 1.7383,
      "step": 9900
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.0798447132110596,
      "learning_rate": 0.0001992114701314478,
      "loss": 1.7658,
      "step": 10000
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.3739285469055176,
      "learning_rate": 0.00019919564196273367,
      "loss": 1.7466,
      "step": 10100
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.552452802658081,
      "learning_rate": 0.00019917965715056103,
      "loss": 1.7157,
      "step": 10200
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.4568352699279785,
      "learning_rate": 0.00019916351572017208,
      "loss": 1.7375,
      "step": 10300
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.1541764736175537,
      "learning_rate": 0.00019914721769705634,
      "loss": 1.7321,
      "step": 10400
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.0024569034576416,
      "learning_rate": 0.00019913076310695068,
      "loss": 1.7637,
      "step": 10500
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.024834156036377,
      "learning_rate": 0.00019911415197583905,
      "loss": 1.7188,
      "step": 10600
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.519399404525757,
      "learning_rate": 0.0001990973843299527,
      "loss": 1.7449,
      "step": 10700
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.03316593170166,
      "learning_rate": 0.00019908046019577008,
      "loss": 1.722,
      "step": 10800
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.872342109680176,
      "learning_rate": 0.0001990633796000167,
      "loss": 1.714,
      "step": 10900
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.0984888076782227,
      "learning_rate": 0.00019904614256966512,
      "loss": 1.7328,
      "step": 11000
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.513847827911377,
      "learning_rate": 0.000199028749131935,
      "loss": 1.713,
      "step": 11100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.6060714721679688,
      "learning_rate": 0.00019901119931429296,
      "loss": 1.7184,
      "step": 11200
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.891066074371338,
      "learning_rate": 0.00019899349314445248,
      "loss": 1.7624,
      "step": 11300
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.0960335731506348,
      "learning_rate": 0.0001989756306503741,
      "loss": 1.7302,
      "step": 11400
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.8282384872436523,
      "learning_rate": 0.0001989576118602651,
      "loss": 1.7409,
      "step": 11500
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.26326060295105,
      "learning_rate": 0.00019893943680257962,
      "loss": 1.7357,
      "step": 11600
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.459340810775757,
      "learning_rate": 0.00019892110550601857,
      "loss": 1.7337,
      "step": 11700
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.298975944519043,
      "learning_rate": 0.00019890261799952955,
      "loss": 1.7423,
      "step": 11800
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.650036096572876,
      "learning_rate": 0.00019888397431230685,
      "loss": 1.7435,
      "step": 11900
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.0919840335845947,
      "learning_rate": 0.0001988651744737914,
      "loss": 1.765,
      "step": 12000
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.8755602836608887,
      "learning_rate": 0.00019884621851367075,
      "loss": 1.7541,
      "step": 12100
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.26377534866333,
      "learning_rate": 0.00019882710646187886,
      "loss": 1.7548,
      "step": 12200
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.82086181640625,
      "learning_rate": 0.00019880783834859636,
      "loss": 1.7276,
      "step": 12300
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.2228972911834717,
      "learning_rate": 0.00019878841420425023,
      "loss": 1.7464,
      "step": 12400
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.192080020904541,
      "learning_rate": 0.00019876883405951377,
      "loss": 1.7426,
      "step": 12500
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.2335169315338135,
      "learning_rate": 0.00019874909794530675,
      "loss": 1.746,
      "step": 12600
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.985968828201294,
      "learning_rate": 0.0001987292058927952,
      "loss": 1.7473,
      "step": 12700
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.1728532314300537,
      "learning_rate": 0.00019870915793339137,
      "loss": 1.7322,
      "step": 12800
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.656313180923462,
      "learning_rate": 0.00019868895409875368,
      "loss": 1.7451,
      "step": 12900
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.398716926574707,
      "learning_rate": 0.0001986685944207868,
      "loss": 1.7624,
      "step": 13000
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.053755283355713,
      "learning_rate": 0.00019864807893164144,
      "loss": 1.7571,
      "step": 13100
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8202126026153564,
      "learning_rate": 0.00019862740766371436,
      "loss": 1.735,
      "step": 13200
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.404825448989868,
      "learning_rate": 0.00019860658064964825,
      "loss": 1.7207,
      "step": 13300
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.207882881164551,
      "learning_rate": 0.00019858559792233188,
      "loss": 1.7539,
      "step": 13400
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.7897372245788574,
      "learning_rate": 0.00019856445951489982,
      "loss": 1.7604,
      "step": 13500
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.367581367492676,
      "learning_rate": 0.0001985431654607325,
      "loss": 1.7457,
      "step": 13600
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.4439022541046143,
      "learning_rate": 0.00019852171579345612,
      "loss": 1.7568,
      "step": 13700
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.6514880657196045,
      "learning_rate": 0.0001985001105469426,
      "loss": 1.7454,
      "step": 13800
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.413357734680176,
      "learning_rate": 0.00019847834975530968,
      "loss": 1.7562,
      "step": 13900
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.087985038757324,
      "learning_rate": 0.00019845643345292054,
      "loss": 1.7242,
      "step": 14000
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.6331722736358643,
      "learning_rate": 0.00019843436167438406,
      "loss": 1.7524,
      "step": 14100
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.412297248840332,
      "learning_rate": 0.0001984121344545545,
      "loss": 1.7647,
      "step": 14200
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.437518358230591,
      "learning_rate": 0.00019838975182853182,
      "loss": 1.7401,
      "step": 14300
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.3817853927612305,
      "learning_rate": 0.0001983672138316611,
      "loss": 1.7403,
      "step": 14400
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.715542793273926,
      "learning_rate": 0.00019834452049953297,
      "loss": 1.7539,
      "step": 14500
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.997493028640747,
      "learning_rate": 0.00019832167186798331,
      "loss": 1.7695,
      "step": 14600
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.9136228561401367,
      "learning_rate": 0.00019829866797309325,
      "loss": 1.732,
      "step": 14700
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.1903772354125977,
      "learning_rate": 0.00019827550885118903,
      "loss": 1.7608,
      "step": 14800
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.313688278198242,
      "learning_rate": 0.00019825219453884207,
      "loss": 1.7569,
      "step": 14900
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.207073211669922,
      "learning_rate": 0.0001982287250728689,
      "loss": 1.7276,
      "step": 15000
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.1728687286376953,
      "learning_rate": 0.00019820510049033092,
      "loss": 1.7335,
      "step": 15100
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.126944541931152,
      "learning_rate": 0.00019818132082853466,
      "loss": 1.7741,
      "step": 15200
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.2443296909332275,
      "learning_rate": 0.00019815738612503144,
      "loss": 1.7498,
      "step": 15300
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.808461904525757,
      "learning_rate": 0.0001981332964176174,
      "loss": 1.7551,
      "step": 15400
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.0887787342071533,
      "learning_rate": 0.0001981090517443334,
      "loss": 1.725,
      "step": 15500
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.6701340675354004,
      "learning_rate": 0.00019808465214346524,
      "loss": 1.7432,
      "step": 15600
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.419811248779297,
      "learning_rate": 0.00019806009765354311,
      "loss": 1.7749,
      "step": 15700
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.6704015731811523,
      "learning_rate": 0.00019803538831334198,
      "loss": 1.7515,
      "step": 15800
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.509265422821045,
      "learning_rate": 0.00019801052416188123,
      "loss": 1.7482,
      "step": 15900
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.523753643035889,
      "learning_rate": 0.0001979855052384247,
      "loss": 1.7336,
      "step": 16000
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.2771191596984863,
      "learning_rate": 0.00019796033158248075,
      "loss": 1.7461,
      "step": 16100
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.334597587585449,
      "learning_rate": 0.000197935003233802,
      "loss": 1.746,
      "step": 16200
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.918574810028076,
      "learning_rate": 0.00019790952023238537,
      "loss": 1.7604,
      "step": 16300
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.259131669998169,
      "learning_rate": 0.00019788388261847203,
      "loss": 1.7322,
      "step": 16400
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.427732467651367,
      "learning_rate": 0.00019785809043254722,
      "loss": 1.7076,
      "step": 16500
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.955034017562866,
      "learning_rate": 0.00019783214371534035,
      "loss": 1.7237,
      "step": 16600
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.166594505310059,
      "learning_rate": 0.00019780604250782478,
      "loss": 1.7312,
      "step": 16700
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.9721877574920654,
      "learning_rate": 0.00019777978685121798,
      "loss": 1.727,
      "step": 16800
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.9009790420532227,
      "learning_rate": 0.00019775337678698115,
      "loss": 1.756,
      "step": 16900
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.2459356784820557,
      "learning_rate": 0.00019772681235681936,
      "loss": 1.7286,
      "step": 17000
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.214462757110596,
      "learning_rate": 0.00019770009360268152,
      "loss": 1.7648,
      "step": 17100
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.509934663772583,
      "learning_rate": 0.00019767322056676016,
      "loss": 1.7647,
      "step": 17200
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.302037239074707,
      "learning_rate": 0.0001976461932914915,
      "loss": 1.7371,
      "step": 17300
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.597979784011841,
      "learning_rate": 0.0001976190118195553,
      "loss": 1.7566,
      "step": 17400
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.3707659244537354,
      "learning_rate": 0.00019759167619387476,
      "loss": 1.7675,
      "step": 17500
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.0875349044799805,
      "learning_rate": 0.0001975641864576166,
      "loss": 1.743,
      "step": 17600
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.624932050704956,
      "learning_rate": 0.00019753654265419087,
      "loss": 1.7469,
      "step": 17700
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.452202796936035,
      "learning_rate": 0.00019750874482725092,
      "loss": 1.719,
      "step": 17800
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.162269115447998,
      "learning_rate": 0.00019748079302069332,
      "loss": 1.7665,
      "step": 17900
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.3587772846221924,
      "learning_rate": 0.00019745268727865774,
      "loss": 1.7424,
      "step": 18000
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.7852256298065186,
      "learning_rate": 0.000197424427645527,
      "loss": 1.7317,
      "step": 18100
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.989886522293091,
      "learning_rate": 0.00019739601416592691,
      "loss": 1.754,
      "step": 18200
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.453681468963623,
      "learning_rate": 0.00019736744688472627,
      "loss": 1.766,
      "step": 18300
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.0186970233917236,
      "learning_rate": 0.00019733872584703672,
      "loss": 1.7799,
      "step": 18400
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.1270456314086914,
      "learning_rate": 0.00019730985109821266,
      "loss": 1.7667,
      "step": 18500
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.9500327110290527,
      "learning_rate": 0.00019728082268385125,
      "loss": 1.7614,
      "step": 18600
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.0915071964263916,
      "learning_rate": 0.0001972516406497924,
      "loss": 1.7804,
      "step": 18700
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.7555480003356934,
      "learning_rate": 0.00019722230504211843,
      "loss": 1.7398,
      "step": 18800
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.064276218414307,
      "learning_rate": 0.00019719281590715432,
      "loss": 1.7545,
      "step": 18900
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.2351603507995605,
      "learning_rate": 0.0001971631732914674,
      "loss": 1.7405,
      "step": 19000
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.195998430252075,
      "learning_rate": 0.00019713337724186743,
      "loss": 1.7403,
      "step": 19100
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.555772304534912,
      "learning_rate": 0.00019710342780540648,
      "loss": 1.739,
      "step": 19200
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.5542056560516357,
      "learning_rate": 0.00019707332502937874,
      "loss": 1.7653,
      "step": 19300
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.563009738922119,
      "learning_rate": 0.00019704306896132064,
      "loss": 1.7351,
      "step": 19400
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.2914960384368896,
      "learning_rate": 0.0001970126596490106,
      "loss": 1.7382,
      "step": 19500
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.2546825408935547,
      "learning_rate": 0.0001969820971404691,
      "loss": 1.756,
      "step": 19600
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.304884672164917,
      "learning_rate": 0.00019695138148395852,
      "loss": 1.7466,
      "step": 19700
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.4854722023010254,
      "learning_rate": 0.00019692051272798304,
      "loss": 1.7455,
      "step": 19800
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.025643348693848,
      "learning_rate": 0.0001968894909212887,
      "loss": 1.7598,
      "step": 19900
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.513070583343506,
      "learning_rate": 0.0001968583161128631,
      "loss": 1.757,
      "step": 20000
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.9166412353515625,
      "learning_rate": 0.00019682698835193557,
      "loss": 1.7538,
      "step": 20100
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.3605847358703613,
      "learning_rate": 0.00019679550768797693,
      "loss": 1.7497,
      "step": 20200
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.538051128387451,
      "learning_rate": 0.00019676387417069937,
      "loss": 1.7604,
      "step": 20300
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.586785078048706,
      "learning_rate": 0.0001967320878500566,
      "loss": 1.7668,
      "step": 20400
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.8308889865875244,
      "learning_rate": 0.00019670014877624353,
      "loss": 1.7514,
      "step": 20500
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.067134141921997,
      "learning_rate": 0.0001966680569996963,
      "loss": 1.7623,
      "step": 20600
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.5033087730407715,
      "learning_rate": 0.00019663581257109224,
      "loss": 1.7477,
      "step": 20700
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.11631441116333,
      "learning_rate": 0.0001966034155413497,
      "loss": 1.7407,
      "step": 20800
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.7150588035583496,
      "learning_rate": 0.000196570865961628,
      "loss": 1.7415,
      "step": 20900
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.704193592071533,
      "learning_rate": 0.0001965381638833274,
      "loss": 1.7399,
      "step": 21000
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.9286351203918457,
      "learning_rate": 0.0001965053093580889,
      "loss": 1.7443,
      "step": 21100
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.4889914989471436,
      "learning_rate": 0.00019647230243779432,
      "loss": 1.7649,
      "step": 21200
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.9208273887634277,
      "learning_rate": 0.00019643914317456603,
      "loss": 1.7595,
      "step": 21300
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.993680953979492,
      "learning_rate": 0.0001964058316207671,
      "loss": 1.7559,
      "step": 21400
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.0227386951446533,
      "learning_rate": 0.000196372367829001,
      "loss": 1.7542,
      "step": 21500
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.282289028167725,
      "learning_rate": 0.00019633875185211158,
      "loss": 1.7384,
      "step": 21600
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.685859203338623,
      "learning_rate": 0.00019630498374318314,
      "loss": 1.7463,
      "step": 21700
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.707347869873047,
      "learning_rate": 0.00019627106355554007,
      "loss": 1.7417,
      "step": 21800
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.025566101074219,
      "learning_rate": 0.000196236991342747,
      "loss": 1.7477,
      "step": 21900
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.363761901855469,
      "learning_rate": 0.0001962027671586086,
      "loss": 1.7364,
      "step": 22000
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.3857550621032715,
      "learning_rate": 0.00019616839105716954,
      "loss": 1.7674,
      "step": 22100
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.3781538009643555,
      "learning_rate": 0.00019613386309271435,
      "loss": 1.7626,
      "step": 22200
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.2067666053771973,
      "learning_rate": 0.0001960991833197674,
      "loss": 1.7605,
      "step": 22300
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.2734451293945312,
      "learning_rate": 0.0001960643517930928,
      "loss": 1.7509,
      "step": 22400
    },
    {
      "epoch": 0.45,
      "grad_norm": 4.2403106689453125,
      "learning_rate": 0.0001960293685676943,
      "loss": 1.7286,
      "step": 22500
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.4288980960845947,
      "learning_rate": 0.0001959942336988152,
      "loss": 1.7612,
      "step": 22600
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.2945449352264404,
      "learning_rate": 0.00019595894724193816,
      "loss": 1.7591,
      "step": 22700
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.5274927616119385,
      "learning_rate": 0.00019592350925278545,
      "loss": 1.7332,
      "step": 22800
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.0482892990112305,
      "learning_rate": 0.00019588791978731836,
      "loss": 1.744,
      "step": 22900
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.044027805328369,
      "learning_rate": 0.0001958521789017376,
      "loss": 1.7717,
      "step": 23000
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.1460533142089844,
      "learning_rate": 0.00019581628665248286,
      "loss": 1.7483,
      "step": 23100
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.870166301727295,
      "learning_rate": 0.00019578024309623295,
      "loss": 1.7602,
      "step": 23200
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.5669121742248535,
      "learning_rate": 0.00019574404828990552,
      "loss": 1.7728,
      "step": 23300
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.5334160327911377,
      "learning_rate": 0.00019570770229065715,
      "loss": 1.7681,
      "step": 23400
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.802670478820801,
      "learning_rate": 0.00019567120515588308,
      "loss": 1.7424,
      "step": 23500
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.295645713806152,
      "learning_rate": 0.0001956345569432173,
      "loss": 1.7534,
      "step": 23600
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.1740832328796387,
      "learning_rate": 0.0001955977577105323,
      "loss": 1.7613,
      "step": 23700
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.763461112976074,
      "learning_rate": 0.00019556080751593918,
      "loss": 1.7417,
      "step": 23800
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.686629772186279,
      "learning_rate": 0.00019552370641778727,
      "loss": 1.7287,
      "step": 23900
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.025032043457031,
      "learning_rate": 0.00019548645447466431,
      "loss": 1.7553,
      "step": 24000
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.4796159267425537,
      "learning_rate": 0.00019544905174539615,
      "loss": 1.7539,
      "step": 24100
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.530794143676758,
      "learning_rate": 0.00019541149828904687,
      "loss": 1.7372,
      "step": 24200
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.5265378952026367,
      "learning_rate": 0.00019537379416491844,
      "loss": 1.7445,
      "step": 24300
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.5650734901428223,
      "learning_rate": 0.00019533593943255086,
      "loss": 1.746,
      "step": 24400
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.856595277786255,
      "learning_rate": 0.00019529793415172192,
      "loss": 1.7651,
      "step": 24500
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.6165034770965576,
      "learning_rate": 0.0001952597783824471,
      "loss": 1.7617,
      "step": 24600
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.5041019916534424,
      "learning_rate": 0.00019522147218497963,
      "loss": 1.756,
      "step": 24700
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.958303213119507,
      "learning_rate": 0.00019518301561981014,
      "loss": 1.7463,
      "step": 24800
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.0737667083740234,
      "learning_rate": 0.0001951444087476669,
      "loss": 1.768,
      "step": 24900
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.9790377616882324,
      "learning_rate": 0.00019510565162951537,
      "loss": 1.7343,
      "step": 25000
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.958467960357666,
      "learning_rate": 0.00019506674432655835,
      "loss": 1.7912,
      "step": 25100
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.5623936653137207,
      "learning_rate": 0.00019502768690023574,
      "loss": 1.7523,
      "step": 25200
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.602240562438965,
      "learning_rate": 0.00019498847941222462,
      "loss": 1.7246,
      "step": 25300
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.6292967796325684,
      "learning_rate": 0.0001949491219244389,
      "loss": 1.7194,
      "step": 25400
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.134222507476807,
      "learning_rate": 0.00019490961449902946,
      "loss": 1.7428,
      "step": 25500
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.149425983428955,
      "learning_rate": 0.00019486995719838392,
      "loss": 1.7709,
      "step": 25600
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.319638729095459,
      "learning_rate": 0.00019483015008512654,
      "loss": 1.7605,
      "step": 25700
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.6366939544677734,
      "learning_rate": 0.00019479019322211823,
      "loss": 1.7337,
      "step": 25800
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.343344211578369,
      "learning_rate": 0.00019475008667245626,
      "loss": 1.7665,
      "step": 25900
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.4271891117095947,
      "learning_rate": 0.00019470983049947444,
      "loss": 1.7466,
      "step": 26000
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.2175018787384033,
      "learning_rate": 0.0001946694247667427,
      "loss": 1.7616,
      "step": 26100
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.575488567352295,
      "learning_rate": 0.0001946288695380672,
      "loss": 1.7498,
      "step": 26200
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.7407121658325195,
      "learning_rate": 0.00019458816487749023,
      "loss": 1.7581,
      "step": 26300
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.929365873336792,
      "learning_rate": 0.00019454731084928993,
      "loss": 1.7538,
      "step": 26400
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.8630692958831787,
      "learning_rate": 0.00019450630751798048,
      "loss": 1.7519,
      "step": 26500
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.401836395263672,
      "learning_rate": 0.00019446515494831167,
      "loss": 1.7485,
      "step": 26600
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.088844299316406,
      "learning_rate": 0.00019442385320526907,
      "loss": 1.7388,
      "step": 26700
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.0605545043945312,
      "learning_rate": 0.00019438240235407375,
      "loss": 1.7535,
      "step": 26800
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.562854528427124,
      "learning_rate": 0.00019434080246018222,
      "loss": 1.7576,
      "step": 26900
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.827294111251831,
      "learning_rate": 0.00019429905358928646,
      "loss": 1.7736,
      "step": 27000
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.353231906890869,
      "learning_rate": 0.0001942571558073136,
      "loss": 1.7438,
      "step": 27100
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.0664896965026855,
      "learning_rate": 0.00019421510918042593,
      "loss": 1.7662,
      "step": 27200
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.8803577423095703,
      "learning_rate": 0.00019417291377502087,
      "loss": 1.7442,
      "step": 27300
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.876087188720703,
      "learning_rate": 0.0001941305696577307,
      "loss": 1.7681,
      "step": 27400
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.3383264541625977,
      "learning_rate": 0.00019408807689542257,
      "loss": 1.7417,
      "step": 27500
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.477738857269287,
      "learning_rate": 0.00019404543555519833,
      "loss": 1.7463,
      "step": 27600
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.0250158309936523,
      "learning_rate": 0.00019400264570439447,
      "loss": 1.7468,
      "step": 27700
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.114380359649658,
      "learning_rate": 0.00019395970741058202,
      "loss": 1.7685,
      "step": 27800
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.100734233856201,
      "learning_rate": 0.00019391662074156644,
      "loss": 1.7449,
      "step": 27900
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.3852286338806152,
      "learning_rate": 0.00019387338576538744,
      "loss": 1.7601,
      "step": 28000
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.037266969680786,
      "learning_rate": 0.0001938300025503189,
      "loss": 1.7696,
      "step": 28100
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.172576427459717,
      "learning_rate": 0.0001937864711648689,
      "loss": 1.7825,
      "step": 28200
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.6307077407836914,
      "learning_rate": 0.00019374279167777943,
      "loss": 1.7345,
      "step": 28300
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.4119200706481934,
      "learning_rate": 0.0001936989641580263,
      "loss": 1.7514,
      "step": 28400
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.298126220703125,
      "learning_rate": 0.00019365498867481923,
      "loss": 1.7662,
      "step": 28500
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.873896837234497,
      "learning_rate": 0.0001936108652976015,
      "loss": 1.7556,
      "step": 28600
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.8185155391693115,
      "learning_rate": 0.00019356659409604989,
      "loss": 1.7528,
      "step": 28700
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.579805612564087,
      "learning_rate": 0.0001935221751400747,
      "loss": 1.7667,
      "step": 28800
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.798687934875488,
      "learning_rate": 0.00019347760849981955,
      "loss": 1.7347,
      "step": 28900
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.604384183883667,
      "learning_rate": 0.00019343289424566122,
      "loss": 1.7667,
      "step": 29000
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.4147255420684814,
      "learning_rate": 0.00019338803244820963,
      "loss": 1.7382,
      "step": 29100
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.9606337547302246,
      "learning_rate": 0.00019334302317830764,
      "loss": 1.7533,
      "step": 29200
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.9529738426208496,
      "learning_rate": 0.0001932978665070311,
      "loss": 1.7462,
      "step": 29300
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.3076891899108887,
      "learning_rate": 0.0001932525625056885,
      "loss": 1.724,
      "step": 29400
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.8933374881744385,
      "learning_rate": 0.0001932071112458211,
      "loss": 1.7645,
      "step": 29500
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.721409559249878,
      "learning_rate": 0.0001931615127992026,
      "loss": 1.7638,
      "step": 29600
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.6039576530456543,
      "learning_rate": 0.0001931157672378392,
      "loss": 1.7317,
      "step": 29700
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.042871475219727,
      "learning_rate": 0.00019306987463396934,
      "loss": 1.7595,
      "step": 29800
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.4253742694854736,
      "learning_rate": 0.00019302383506006373,
      "loss": 1.7331,
      "step": 29900
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.1099295616149902,
      "learning_rate": 0.00019297764858882514,
      "loss": 1.771,
      "step": 30000
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.3895950317382812,
      "learning_rate": 0.00019293131529318834,
      "loss": 1.7419,
      "step": 30100
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.4675071239471436,
      "learning_rate": 0.0001928848352463199,
      "loss": 1.7636,
      "step": 30200
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.7467896938323975,
      "learning_rate": 0.00019283820852161816,
      "loss": 1.7707,
      "step": 30300
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.189780235290527,
      "learning_rate": 0.00019279143519271307,
      "loss": 1.7645,
      "step": 30400
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.3328895568847656,
      "learning_rate": 0.00019274451533346615,
      "loss": 1.7812,
      "step": 30500
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.340152740478516,
      "learning_rate": 0.0001926974490179702,
      "loss": 1.7479,
      "step": 30600
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.569462776184082,
      "learning_rate": 0.00019265023632054939,
      "loss": 1.7907,
      "step": 30700
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.7009530067443848,
      "learning_rate": 0.00019260287731575902,
      "loss": 1.7518,
      "step": 30800
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.3409178256988525,
      "learning_rate": 0.0001925553720783854,
      "loss": 1.7466,
      "step": 30900
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.299492835998535,
      "learning_rate": 0.0001925077206834458,
      "loss": 1.7931,
      "step": 31000
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.788132905960083,
      "learning_rate": 0.00019245992320618828,
      "loss": 1.7702,
      "step": 31100
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.8177573680877686,
      "learning_rate": 0.00019241197972209157,
      "loss": 1.7582,
      "step": 31200
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.2547550201416016,
      "learning_rate": 0.000192363890306865,
      "loss": 1.7463,
      "step": 31300
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.7882115840911865,
      "learning_rate": 0.00019231565503644826,
      "loss": 1.7438,
      "step": 31400
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.4390223026275635,
      "learning_rate": 0.0001922672739870115,
      "loss": 1.7418,
      "step": 31500
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.9789562225341797,
      "learning_rate": 0.00019221874723495495,
      "loss": 1.7596,
      "step": 31600
    },
    {
      "epoch": 0.63,
      "grad_norm": 7.5055928230285645,
      "learning_rate": 0.000192170074856909,
      "loss": 1.7422,
      "step": 31700
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.9086267948150635,
      "learning_rate": 0.00019212125692973396,
      "loss": 1.7447,
      "step": 31800
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.412391185760498,
      "learning_rate": 0.00019207229353052,
      "loss": 1.7473,
      "step": 31900
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.4594147205352783,
      "learning_rate": 0.00019202318473658705,
      "loss": 1.7178,
      "step": 32000
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.8363935947418213,
      "learning_rate": 0.00019197393062548454,
      "loss": 1.7427,
      "step": 32100
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.3821349143981934,
      "learning_rate": 0.0001919245312749915,
      "loss": 1.7514,
      "step": 32200
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.1480841636657715,
      "learning_rate": 0.00019187498676311618,
      "loss": 1.7428,
      "step": 32300
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.3541626930236816,
      "learning_rate": 0.0001918252971680962,
      "loss": 1.7808,
      "step": 32400
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.440321683883667,
      "learning_rate": 0.00019177546256839812,
      "loss": 1.7295,
      "step": 32500
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.162626266479492,
      "learning_rate": 0.00019172548304271768,
      "loss": 1.7302,
      "step": 32600
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.4187204837799072,
      "learning_rate": 0.00019167535866997928,
      "loss": 1.7448,
      "step": 32700
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.6561672687530518,
      "learning_rate": 0.0001916250895293362,
      "loss": 1.7528,
      "step": 32800
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.137699604034424,
      "learning_rate": 0.00019157467570017026,
      "loss": 1.7493,
      "step": 32900
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.654437780380249,
      "learning_rate": 0.00019152411726209176,
      "loss": 1.74,
      "step": 33000
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.6692962646484375,
      "learning_rate": 0.00019147341429493945,
      "loss": 1.7592,
      "step": 33100
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.680016279220581,
      "learning_rate": 0.0001914225668787801,
      "loss": 1.758,
      "step": 33200
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.4344966411590576,
      "learning_rate": 0.00019137157509390885,
      "loss": 1.7296,
      "step": 33300
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.610748052597046,
      "learning_rate": 0.00019132043902084865,
      "loss": 1.7708,
      "step": 33400
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.71220064163208,
      "learning_rate": 0.0001912691587403503,
      "loss": 1.7404,
      "step": 33500
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.076992988586426,
      "learning_rate": 0.0001912177343333924,
      "loss": 1.7457,
      "step": 33600
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.411491632461548,
      "learning_rate": 0.00019116616588118107,
      "loss": 1.7374,
      "step": 33700
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.1178460121154785,
      "learning_rate": 0.00019111445346515002,
      "loss": 1.7563,
      "step": 33800
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.3841052055358887,
      "learning_rate": 0.00019106259716696012,
      "loss": 1.7434,
      "step": 33900
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.6529040336608887,
      "learning_rate": 0.00019101059706849957,
      "loss": 1.7534,
      "step": 34000
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.5951931476593018,
      "learning_rate": 0.00019095845325188367,
      "loss": 1.7568,
      "step": 34100
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.4062185287475586,
      "learning_rate": 0.00019090616579945456,
      "loss": 1.7582,
      "step": 34200
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.539888381958008,
      "learning_rate": 0.0001908537347937813,
      "loss": 1.7652,
      "step": 34300
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.154428720474243,
      "learning_rate": 0.00019080116031765958,
      "loss": 1.7413,
      "step": 34400
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.611966609954834,
      "learning_rate": 0.0001907484424541117,
      "loss": 1.7599,
      "step": 34500
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.871119976043701,
      "learning_rate": 0.00019069558128638635,
      "loss": 1.7642,
      "step": 34600
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.1800615787506104,
      "learning_rate": 0.00019064257689795856,
      "loss": 1.7409,
      "step": 34700
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.459643840789795,
      "learning_rate": 0.00019058942937252943,
      "loss": 1.7088,
      "step": 34800
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.2416436672210693,
      "learning_rate": 0.00019053613879402618,
      "loss": 1.7725,
      "step": 34900
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.7825145721435547,
      "learning_rate": 0.00019048270524660196,
      "loss": 1.7593,
      "step": 35000
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.466592788696289,
      "learning_rate": 0.0001904291288146356,
      "loss": 1.7533,
      "step": 35100
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.6172449588775635,
      "learning_rate": 0.00019037540958273156,
      "loss": 1.7853,
      "step": 35200
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.588206768035889,
      "learning_rate": 0.0001903215476357199,
      "loss": 1.7252,
      "step": 35300
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.4759232997894287,
      "learning_rate": 0.00019026754305865592,
      "loss": 1.7752,
      "step": 35400
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.8226020336151123,
      "learning_rate": 0.00019021339593682028,
      "loss": 1.7808,
      "step": 35500
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.124562978744507,
      "learning_rate": 0.00019015910635571869,
      "loss": 1.756,
      "step": 35600
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.159167766571045,
      "learning_rate": 0.00019010467440108174,
      "loss": 1.7491,
      "step": 35700
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.7804760932922363,
      "learning_rate": 0.00019005010015886496,
      "loss": 1.7307,
      "step": 35800
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.4631309509277344,
      "learning_rate": 0.00018999538371524847,
      "loss": 1.7437,
      "step": 35900
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.144638776779175,
      "learning_rate": 0.0001899405251566371,
      "loss": 1.7452,
      "step": 36000
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.616566181182861,
      "learning_rate": 0.00018988552456965997,
      "loss": 1.7488,
      "step": 36100
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.1373722553253174,
      "learning_rate": 0.00018983038204117044,
      "loss": 1.7414,
      "step": 36200
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.1791272163391113,
      "learning_rate": 0.0001897750976582462,
      "loss": 1.7192,
      "step": 36300
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.7342426776885986,
      "learning_rate": 0.00018971967150818877,
      "loss": 1.7573,
      "step": 36400
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.3841540813446045,
      "learning_rate": 0.00018966410367852362,
      "loss": 1.7318,
      "step": 36500
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.431446075439453,
      "learning_rate": 0.0001896083942569999,
      "loss": 1.7432,
      "step": 36600
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.83951735496521,
      "learning_rate": 0.00018955254333159047,
      "loss": 1.7631,
      "step": 36700
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.524763584136963,
      "learning_rate": 0.00018949655099049148,
      "loss": 1.7438,
      "step": 36800
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.7195677757263184,
      "learning_rate": 0.00018944041732212255,
      "loss": 1.754,
      "step": 36900
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.410170555114746,
      "learning_rate": 0.0001893841424151264,
      "loss": 1.7647,
      "step": 37000
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.072301387786865,
      "learning_rate": 0.00018932772635836873,
      "loss": 1.7383,
      "step": 37100
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.028282642364502,
      "learning_rate": 0.00018927116924093824,
      "loss": 1.7563,
      "step": 37200
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.8310203552246094,
      "learning_rate": 0.00018921447115214632,
      "loss": 1.7596,
      "step": 37300
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.194075345993042,
      "learning_rate": 0.00018915763218152704,
      "loss": 1.7585,
      "step": 37400
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.8398776054382324,
      "learning_rate": 0.0001891006524188368,
      "loss": 1.7616,
      "step": 37500
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.381877899169922,
      "learning_rate": 0.0001890435319540545,
      "loss": 1.7413,
      "step": 37600
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.735422134399414,
      "learning_rate": 0.0001889862708773811,
      "loss": 1.7571,
      "step": 37700
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.524555206298828,
      "learning_rate": 0.00018892886927923973,
      "loss": 1.7585,
      "step": 37800
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.3684558868408203,
      "learning_rate": 0.00018887132725027526,
      "loss": 1.7524,
      "step": 37900
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.266396999359131,
      "learning_rate": 0.00018881364488135448,
      "loss": 1.7193,
      "step": 38000
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.948502779006958,
      "learning_rate": 0.00018875582226356564,
      "loss": 1.7271,
      "step": 38100
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.1530137062072754,
      "learning_rate": 0.00018869785948821865,
      "loss": 1.7891,
      "step": 38200
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.3002185821533203,
      "learning_rate": 0.00018863975664684457,
      "loss": 1.7581,
      "step": 38300
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.9252610206604,
      "learning_rate": 0.00018858151383119575,
      "loss": 1.7209,
      "step": 38400
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.625770092010498,
      "learning_rate": 0.00018852313113324552,
      "loss": 1.806,
      "step": 38500
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.264780282974243,
      "learning_rate": 0.00018846460864518818,
      "loss": 1.7579,
      "step": 38600
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.9445927143096924,
      "learning_rate": 0.00018840594645943865,
      "loss": 1.7419,
      "step": 38700
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.2971763610839844,
      "learning_rate": 0.0001883471446686326,
      "loss": 1.7424,
      "step": 38800
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.3174843788146973,
      "learning_rate": 0.00018828820336562604,
      "loss": 1.7418,
      "step": 38900
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.4609479904174805,
      "learning_rate": 0.00018822912264349534,
      "loss": 1.7789,
      "step": 39000
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.8222646713256836,
      "learning_rate": 0.00018816990259553701,
      "loss": 1.7674,
      "step": 39100
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.190377235412598,
      "learning_rate": 0.00018811054331526768,
      "loss": 1.7139,
      "step": 39200
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.4387218952178955,
      "learning_rate": 0.00018805104489642363,
      "loss": 1.7462,
      "step": 39300
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.560617685317993,
      "learning_rate": 0.00018799140743296105,
      "loss": 1.7527,
      "step": 39400
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.5333971977233887,
      "learning_rate": 0.00018793163101905563,
      "loss": 1.7638,
      "step": 39500
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.2055776119232178,
      "learning_rate": 0.00018787171574910247,
      "loss": 1.768,
      "step": 39600
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.792703866958618,
      "learning_rate": 0.000187811661717716,
      "loss": 1.7428,
      "step": 39700
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.032339572906494,
      "learning_rate": 0.00018775146901972968,
      "loss": 1.7491,
      "step": 39800
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.2731595039367676,
      "learning_rate": 0.00018769113775019605,
      "loss": 1.7477,
      "step": 39900
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.048443794250488,
      "learning_rate": 0.00018763066800438636,
      "loss": 1.7795,
      "step": 40000
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.1019821166992188,
      "learning_rate": 0.00018757005987779065,
      "loss": 1.7302,
      "step": 40100
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.2878224849700928,
      "learning_rate": 0.00018750931346611739,
      "loss": 1.7629,
      "step": 40200
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.229037046432495,
      "learning_rate": 0.00018744842886529343,
      "loss": 1.7427,
      "step": 40300
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.010974884033203,
      "learning_rate": 0.00018738740617146396,
      "loss": 1.729,
      "step": 40400
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.9631123542785645,
      "learning_rate": 0.00018732624548099204,
      "loss": 1.7653,
      "step": 40500
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.258147716522217,
      "learning_rate": 0.00018726494689045876,
      "loss": 1.7539,
      "step": 40600
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.555943489074707,
      "learning_rate": 0.00018720351049666305,
      "loss": 1.7488,
      "step": 40700
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.9591987133026123,
      "learning_rate": 0.00018714193639662128,
      "loss": 1.7238,
      "step": 40800
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.9661829471588135,
      "learning_rate": 0.00018708022468756738,
      "loss": 1.749,
      "step": 40900
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.191577434539795,
      "learning_rate": 0.0001870183754669526,
      "loss": 1.7576,
      "step": 41000
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.050676107406616,
      "learning_rate": 0.00018695638883244522,
      "loss": 1.7538,
      "step": 41100
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.889512538909912,
      "learning_rate": 0.00018689426488193066,
      "loss": 1.7585,
      "step": 41200
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.8551204204559326,
      "learning_rate": 0.00018683200371351108,
      "loss": 1.7313,
      "step": 41300
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.703958034515381,
      "learning_rate": 0.0001867696054255054,
      "loss": 1.7645,
      "step": 41400
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.8650360107421875,
      "learning_rate": 0.000186707070116449,
      "loss": 1.7533,
      "step": 41500
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.9680070877075195,
      "learning_rate": 0.0001866443978850937,
      "loss": 1.757,
      "step": 41600
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.6120405197143555,
      "learning_rate": 0.00018658158883040754,
      "loss": 1.734,
      "step": 41700
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.596662759780884,
      "learning_rate": 0.0001865186430515745,
      "loss": 1.762,
      "step": 41800
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.200601577758789,
      "learning_rate": 0.00018645556064799456,
      "loss": 1.7383,
      "step": 41900
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.605432033538818,
      "learning_rate": 0.00018639234171928353,
      "loss": 1.712,
      "step": 42000
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.9084115028381348,
      "learning_rate": 0.0001863289863652727,
      "loss": 1.7664,
      "step": 42100
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.5690653324127197,
      "learning_rate": 0.00018626549468600878,
      "loss": 1.7585,
      "step": 42200
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.167919635772705,
      "learning_rate": 0.0001862018667817538,
      "loss": 1.7696,
      "step": 42300
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.557610034942627,
      "learning_rate": 0.000186138102752985,
      "loss": 1.7366,
      "step": 42400
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.487790107727051,
      "learning_rate": 0.0001860742027003944,
      "loss": 1.7477,
      "step": 42500
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.4642202854156494,
      "learning_rate": 0.00018601016672488888,
      "loss": 1.7348,
      "step": 42600
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.6249139308929443,
      "learning_rate": 0.00018594599492759004,
      "loss": 1.7352,
      "step": 42700
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.404381275177002,
      "learning_rate": 0.00018588168740983388,
      "loss": 1.7519,
      "step": 42800
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.5102877616882324,
      "learning_rate": 0.0001858172442731708,
      "loss": 1.7422,
      "step": 42900
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.325041770935059,
      "learning_rate": 0.00018575266561936523,
      "loss": 1.7694,
      "step": 43000
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.8333170413970947,
      "learning_rate": 0.00018568795155039577,
      "loss": 1.7617,
      "step": 43100
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.515671491622925,
      "learning_rate": 0.00018562310216845465,
      "loss": 1.7199,
      "step": 43200
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.1751670837402344,
      "learning_rate": 0.000185558117575948,
      "loss": 1.7574,
      "step": 43300
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.092312812805176,
      "learning_rate": 0.00018549299787549533,
      "loss": 1.7588,
      "step": 43400
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.7853198051452637,
      "learning_rate": 0.0001854277431699295,
      "loss": 1.7722,
      "step": 43500
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.7604031562805176,
      "learning_rate": 0.0001853623535622967,
      "loss": 1.7458,
      "step": 43600
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.2123866081237793,
      "learning_rate": 0.0001852968291558559,
      "loss": 1.7553,
      "step": 43700
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.2610552310943604,
      "learning_rate": 0.0001852311700540792,
      "loss": 1.7356,
      "step": 43800
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.715672254562378,
      "learning_rate": 0.00018516537636065121,
      "loss": 1.7717,
      "step": 43900
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.8624322414398193,
      "learning_rate": 0.00018509944817946922,
      "loss": 1.7543,
      "step": 44000
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.050374984741211,
      "learning_rate": 0.00018503338561464273,
      "loss": 1.7288,
      "step": 44100
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.6381025314331055,
      "learning_rate": 0.00018496718877049367,
      "loss": 1.7368,
      "step": 44200
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.1887543201446533,
      "learning_rate": 0.00018490085775155576,
      "loss": 1.7386,
      "step": 44300
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.780428647994995,
      "learning_rate": 0.00018483439266257486,
      "loss": 1.74,
      "step": 44400
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.453185558319092,
      "learning_rate": 0.00018476779360850832,
      "loss": 1.7418,
      "step": 44500
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.79974627494812,
      "learning_rate": 0.0001847010606945252,
      "loss": 1.7534,
      "step": 44600
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.4890761375427246,
      "learning_rate": 0.00018463419402600585,
      "loss": 1.7558,
      "step": 44700
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.281158924102783,
      "learning_rate": 0.0001845671937085419,
      "loss": 1.7233,
      "step": 44800
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.35075306892395,
      "learning_rate": 0.00018450005984793592,
      "loss": 1.7148,
      "step": 44900
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.076877117156982,
      "learning_rate": 0.00018443279255020152,
      "loss": 1.7503,
      "step": 45000
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.14723801612854,
      "learning_rate": 0.0001843653919215629,
      "loss": 1.718,
      "step": 45100
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.55853533744812,
      "learning_rate": 0.00018429785806845487,
      "loss": 1.7373,
      "step": 45200
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.763977527618408,
      "learning_rate": 0.0001842301910975226,
      "loss": 1.7519,
      "step": 45300
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.994763135910034,
      "learning_rate": 0.00018416239111562147,
      "loss": 1.7592,
      "step": 45400
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.177142381668091,
      "learning_rate": 0.00018409445822981693,
      "loss": 1.7524,
      "step": 45500
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.790626287460327,
      "learning_rate": 0.00018402639254738422,
      "loss": 1.7373,
      "step": 45600
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.666255474090576,
      "learning_rate": 0.0001839581941758084,
      "loss": 1.7599,
      "step": 45700
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.1528069972991943,
      "learning_rate": 0.00018388986322278398,
      "loss": 1.7174,
      "step": 45800
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.279341459274292,
      "learning_rate": 0.00018382139979621488,
      "loss": 1.7293,
      "step": 45900
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.0014069080352783,
      "learning_rate": 0.0001837528040042142,
      "loss": 1.7527,
      "step": 46000
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.382859230041504,
      "learning_rate": 0.000183684075955104,
      "loss": 1.7577,
      "step": 46100
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.2991201877593994,
      "learning_rate": 0.0001836152157574153,
      "loss": 1.7483,
      "step": 46200
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.537078857421875,
      "learning_rate": 0.0001835462235198878,
      "loss": 1.7669,
      "step": 46300
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.4127795696258545,
      "learning_rate": 0.00018347709935146958,
      "loss": 1.7428,
      "step": 46400
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.817934036254883,
      "learning_rate": 0.00018340784336131713,
      "loss": 1.753,
      "step": 46500
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.514540910720825,
      "learning_rate": 0.00018333845565879516,
      "loss": 1.7505,
      "step": 46600
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.2575173377990723,
      "learning_rate": 0.00018326893635347633,
      "loss": 1.7377,
      "step": 46700
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.183427095413208,
      "learning_rate": 0.00018319928555514108,
      "loss": 1.7379,
      "step": 46800
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.392587661743164,
      "learning_rate": 0.00018312950337377753,
      "loss": 1.7122,
      "step": 46900
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.4291446208953857,
      "learning_rate": 0.00018305958991958127,
      "loss": 1.7495,
      "step": 47000
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.5380496978759766,
      "learning_rate": 0.00018298954530295524,
      "loss": 1.7257,
      "step": 47100
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.203106164932251,
      "learning_rate": 0.00018291936963450934,
      "loss": 1.7275,
      "step": 47200
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.6780612468719482,
      "learning_rate": 0.00018284906302506063,
      "loss": 1.751,
      "step": 47300
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.111503601074219,
      "learning_rate": 0.00018277862558563278,
      "loss": 1.7502,
      "step": 47400
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.291719436645508,
      "learning_rate": 0.00018270805742745617,
      "loss": 1.7744,
      "step": 47500
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.396247863769531,
      "learning_rate": 0.00018263735866196756,
      "loss": 1.7801,
      "step": 47600
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.9427483081817627,
      "learning_rate": 0.0001825665294008099,
      "loss": 1.7459,
      "step": 47700
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.550389051437378,
      "learning_rate": 0.0001824955697558323,
      "loss": 1.7437,
      "step": 47800
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.3723394870758057,
      "learning_rate": 0.00018242447983908967,
      "loss": 1.7361,
      "step": 47900
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.25911808013916,
      "learning_rate": 0.00018235325976284275,
      "loss": 1.7614,
      "step": 48000
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.202785015106201,
      "learning_rate": 0.00018228190963955775,
      "loss": 1.7397,
      "step": 48100
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.913839340209961,
      "learning_rate": 0.00018221042958190627,
      "loss": 1.7483,
      "step": 48200
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.8235678672790527,
      "learning_rate": 0.000182138819702765,
      "loss": 1.7417,
      "step": 48300
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.2136855125427246,
      "learning_rate": 0.00018206708011521582,
      "loss": 1.7287,
      "step": 48400
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.8642947673797607,
      "learning_rate": 0.00018199521093254523,
      "loss": 1.7333,
      "step": 48500
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.5876071453094482,
      "learning_rate": 0.00018192321226824455,
      "loss": 1.7523,
      "step": 48600
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.6350557804107666,
      "learning_rate": 0.0001818510842360095,
      "loss": 1.7404,
      "step": 48700
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.134884357452393,
      "learning_rate": 0.00018177882694974006,
      "loss": 1.74,
      "step": 48800
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.272284984588623,
      "learning_rate": 0.00018170644052354035,
      "loss": 1.7587,
      "step": 48900
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.72230863571167,
      "learning_rate": 0.00018163392507171842,
      "loss": 1.7576,
      "step": 49000
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.4124207496643066,
      "learning_rate": 0.00018156128070878603,
      "loss": 1.7252,
      "step": 49100
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.335282564163208,
      "learning_rate": 0.00018148850754945862,
      "loss": 1.7643,
      "step": 49200
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.085452079772949,
      "learning_rate": 0.0001814156057086549,
      "loss": 1.7398,
      "step": 49300
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.9956438541412354,
      "learning_rate": 0.00018134257530149684,
      "loss": 1.7602,
      "step": 49400
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.143184185028076,
      "learning_rate": 0.0001812694164433094,
      "loss": 1.7279,
      "step": 49500
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.1089625358581543,
      "learning_rate": 0.00018119612924962045,
      "loss": 1.752,
      "step": 49600
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.09405517578125,
      "learning_rate": 0.00018112271383616038,
      "loss": 1.7472,
      "step": 49700
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.996656894683838,
      "learning_rate": 0.00018104917031886222,
      "loss": 1.7495,
      "step": 49800
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.3404014110565186,
      "learning_rate": 0.00018097549881386125,
      "loss": 1.7346,
      "step": 49900
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.845308780670166,
      "learning_rate": 0.00018090169943749476,
      "loss": 1.7494,
      "step": 50000
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.059366226196289,
      "learning_rate": 0.00018082777230630205,
      "loss": 1.7174,
      "step": 50100
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.89433217048645,
      "learning_rate": 0.0001807537175370242,
      "loss": 1.7075,
      "step": 50200
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.8404786586761475,
      "learning_rate": 0.0001806795352466038,
      "loss": 1.7381,
      "step": 50300
    },
    {
      "epoch": 1.01,
      "grad_norm": 6.843549728393555,
      "learning_rate": 0.0001806052255521847,
      "loss": 1.7137,
      "step": 50400
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.325988292694092,
      "learning_rate": 0.0001805307885711122,
      "loss": 1.7414,
      "step": 50500
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.1110458374023438,
      "learning_rate": 0.00018045622442093237,
      "loss": 1.7238,
      "step": 50600
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.658905029296875,
      "learning_rate": 0.0001803815332193922,
      "loss": 1.7045,
      "step": 50700
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.620211362838745,
      "learning_rate": 0.00018030671508443929,
      "loss": 1.7115,
      "step": 50800
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.446880578994751,
      "learning_rate": 0.00018023177013422168,
      "loss": 1.723,
      "step": 50900
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.6351158618927,
      "learning_rate": 0.00018015669848708767,
      "loss": 1.7146,
      "step": 51000
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.4574811458587646,
      "learning_rate": 0.00018008150026158567,
      "loss": 1.7145,
      "step": 51100
    },
    {
      "epoch": 1.02,
      "grad_norm": 4.1773247718811035,
      "learning_rate": 0.0001800061755764639,
      "loss": 1.7087,
      "step": 51200
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.80755352973938,
      "learning_rate": 0.00017993072455067038,
      "loss": 1.7278,
      "step": 51300
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.6726906299591064,
      "learning_rate": 0.00017985514730335252,
      "loss": 1.7199,
      "step": 51400
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.9190099239349365,
      "learning_rate": 0.0001797794439538571,
      "loss": 1.7072,
      "step": 51500
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.3807058334350586,
      "learning_rate": 0.0001797036146217301,
      "loss": 1.7102,
      "step": 51600
    },
    {
      "epoch": 1.03,
      "grad_norm": 3.3027937412261963,
      "learning_rate": 0.00017962765942671638,
      "loss": 1.7071,
      "step": 51700
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.3544962406158447,
      "learning_rate": 0.0001795515784887595,
      "loss": 1.7164,
      "step": 51800
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.973771095275879,
      "learning_rate": 0.0001794753719280017,
      "loss": 1.6983,
      "step": 51900
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.456857204437256,
      "learning_rate": 0.00017939903986478355,
      "loss": 1.694,
      "step": 52000
    },
    {
      "epoch": 1.04,
      "grad_norm": 4.105882167816162,
      "learning_rate": 0.00017932258241964375,
      "loss": 1.7113,
      "step": 52100
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.641005516052246,
      "learning_rate": 0.00017924599971331907,
      "loss": 1.7321,
      "step": 52200
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.106822967529297,
      "learning_rate": 0.00017916929186674404,
      "loss": 1.7185,
      "step": 52300
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.7903473377227783,
      "learning_rate": 0.00017909245900105084,
      "loss": 1.7379,
      "step": 52400
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.560786008834839,
      "learning_rate": 0.00017901550123756906,
      "loss": 1.7132,
      "step": 52500
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.8231048583984375,
      "learning_rate": 0.00017893841869782547,
      "loss": 1.7081,
      "step": 52600
    },
    {
      "epoch": 1.05,
      "grad_norm": 4.01493501663208,
      "learning_rate": 0.00017886121150354395,
      "loss": 1.7234,
      "step": 52700
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.2785563468933105,
      "learning_rate": 0.0001787838797766452,
      "loss": 1.7368,
      "step": 52800
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.6298604011535645,
      "learning_rate": 0.0001787064236392466,
      "loss": 1.713,
      "step": 52900
    },
    {
      "epoch": 1.06,
      "grad_norm": 4.468074798583984,
      "learning_rate": 0.00017862884321366188,
      "loss": 1.719,
      "step": 53000
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.2056546211242676,
      "learning_rate": 0.0001785511386224012,
      "loss": 1.7307,
      "step": 53100
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.2612850666046143,
      "learning_rate": 0.00017847330998817072,
      "loss": 1.7177,
      "step": 53200
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.1689460277557373,
      "learning_rate": 0.0001783953574338724,
      "loss": 1.7579,
      "step": 53300
    },
    {
      "epoch": 1.07,
      "grad_norm": 4.050646781921387,
      "learning_rate": 0.00017831728108260407,
      "loss": 1.7276,
      "step": 53400
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.8006105422973633,
      "learning_rate": 0.0001782390810576588,
      "loss": 1.7143,
      "step": 53500
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.165726661682129,
      "learning_rate": 0.00017816075748252526,
      "loss": 1.7422,
      "step": 53600
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.991821765899658,
      "learning_rate": 0.00017808231048088697,
      "loss": 1.686,
      "step": 53700
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.2589359283447266,
      "learning_rate": 0.0001780037401766225,
      "loss": 1.7356,
      "step": 53800
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.235520839691162,
      "learning_rate": 0.00017792504669380502,
      "loss": 1.7298,
      "step": 53900
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.980748414993286,
      "learning_rate": 0.00017784623015670238,
      "loss": 1.7283,
      "step": 54000
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.1414923667907715,
      "learning_rate": 0.00017776729068977654,
      "loss": 1.7108,
      "step": 54100
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.4485867023468018,
      "learning_rate": 0.00017768822841768379,
      "loss": 1.7507,
      "step": 54200
    },
    {
      "epoch": 1.09,
      "grad_norm": 3.7998900413513184,
      "learning_rate": 0.00017760904346527417,
      "loss": 1.7261,
      "step": 54300
    },
    {
      "epoch": 1.09,
      "grad_norm": 4.62751579284668,
      "learning_rate": 0.00017752973595759158,
      "loss": 1.7131,
      "step": 54400
    },
    {
      "epoch": 1.09,
      "grad_norm": 4.102806568145752,
      "learning_rate": 0.00017745030601987337,
      "loss": 1.7423,
      "step": 54500
    },
    {
      "epoch": 1.09,
      "grad_norm": 3.254840135574341,
      "learning_rate": 0.00017737075377755032,
      "loss": 1.7501,
      "step": 54600
    },
    {
      "epoch": 1.09,
      "grad_norm": 3.5665323734283447,
      "learning_rate": 0.0001772910793562462,
      "loss": 1.7083,
      "step": 54700
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.130322217941284,
      "learning_rate": 0.00017721128288177782,
      "loss": 1.7385,
      "step": 54800
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.382674217224121,
      "learning_rate": 0.0001771313644801547,
      "loss": 1.7318,
      "step": 54900
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.839895725250244,
      "learning_rate": 0.00017705132427757895,
      "loss": 1.7241,
      "step": 55000
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.467639207839966,
      "learning_rate": 0.00017697116240044492,
      "loss": 1.726,
      "step": 55100
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.473512887954712,
      "learning_rate": 0.00017689087897533915,
      "loss": 1.7352,
      "step": 55200
    },
    {
      "epoch": 1.11,
      "grad_norm": 3.7400095462799072,
      "learning_rate": 0.00017681047412904018,
      "loss": 1.7168,
      "step": 55300
    },
    {
      "epoch": 1.11,
      "grad_norm": 3.873790740966797,
      "learning_rate": 0.0001767299479885182,
      "loss": 1.755,
      "step": 55400
    },
    {
      "epoch": 1.11,
      "grad_norm": 3.273043394088745,
      "learning_rate": 0.00017664930068093498,
      "loss": 1.716,
      "step": 55500
    },
    {
      "epoch": 1.11,
      "grad_norm": 3.1925432682037354,
      "learning_rate": 0.00017656853233364369,
      "loss": 1.7475,
      "step": 55600
    },
    {
      "epoch": 1.11,
      "grad_norm": 3.725842237472534,
      "learning_rate": 0.00017648764307418843,
      "loss": 1.7056,
      "step": 55700
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.9686906337738037,
      "learning_rate": 0.00017640663303030452,
      "loss": 1.7065,
      "step": 55800
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.764216899871826,
      "learning_rate": 0.00017632550232991783,
      "loss": 1.7277,
      "step": 55900
    },
    {
      "epoch": 1.12,
      "grad_norm": 4.225737571716309,
      "learning_rate": 0.0001762442511011448,
      "loss": 1.7479,
      "step": 56000
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.5444540977478027,
      "learning_rate": 0.00017616287947229222,
      "loss": 1.7164,
      "step": 56100
    },
    {
      "epoch": 1.12,
      "grad_norm": 4.012929439544678,
      "learning_rate": 0.00017608138757185698,
      "loss": 1.7031,
      "step": 56200
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.8790054321289062,
      "learning_rate": 0.00017599977552852595,
      "loss": 1.7492,
      "step": 56300
    },
    {
      "epoch": 1.13,
      "grad_norm": 4.266294956207275,
      "learning_rate": 0.00017591804347117567,
      "loss": 1.7288,
      "step": 56400
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.4764175415039062,
      "learning_rate": 0.0001758361915288722,
      "loss": 1.7319,
      "step": 56500
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.059023141860962,
      "learning_rate": 0.00017575421983087095,
      "loss": 1.7223,
      "step": 56600
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.320617198944092,
      "learning_rate": 0.00017567212850661638,
      "loss": 1.6988,
      "step": 56700
    },
    {
      "epoch": 1.14,
      "grad_norm": 4.34910249710083,
      "learning_rate": 0.000175589917685742,
      "loss": 1.7033,
      "step": 56800
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.732501745223999,
      "learning_rate": 0.00017550758749806974,
      "loss": 1.7347,
      "step": 56900
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.9942424297332764,
      "learning_rate": 0.00017542513807361037,
      "loss": 1.7011,
      "step": 57000
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.5440428256988525,
      "learning_rate": 0.00017534256954256273,
      "loss": 1.7046,
      "step": 57100
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.8889756202697754,
      "learning_rate": 0.0001752598820353138,
      "loss": 1.702,
      "step": 57200
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.888822317123413,
      "learning_rate": 0.00017517707568243842,
      "loss": 1.7571,
      "step": 57300
    },
    {
      "epoch": 1.15,
      "grad_norm": 4.041213035583496,
      "learning_rate": 0.00017509415061469917,
      "loss": 1.7212,
      "step": 57400
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.4339206218719482,
      "learning_rate": 0.00017501110696304596,
      "loss": 1.702,
      "step": 57500
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.8950610160827637,
      "learning_rate": 0.00017492794485861617,
      "loss": 1.7282,
      "step": 57600
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.2475180625915527,
      "learning_rate": 0.000174844664432734,
      "loss": 1.7388,
      "step": 57700
    },
    {
      "epoch": 1.16,
      "grad_norm": 4.069153785705566,
      "learning_rate": 0.0001747612658169107,
      "loss": 1.7126,
      "step": 57800
    },
    {
      "epoch": 1.16,
      "grad_norm": 4.559791088104248,
      "learning_rate": 0.00017467774914284404,
      "loss": 1.7148,
      "step": 57900
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.047304153442383,
      "learning_rate": 0.00017459411454241822,
      "loss": 1.7319,
      "step": 58000
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.351962089538574,
      "learning_rate": 0.00017451036214770373,
      "loss": 1.7403,
      "step": 58100
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.143709182739258,
      "learning_rate": 0.000174426492090957,
      "loss": 1.7143,
      "step": 58200
    },
    {
      "epoch": 1.17,
      "grad_norm": 3.4020814895629883,
      "learning_rate": 0.00017434250450462034,
      "loss": 1.738,
      "step": 58300
    },
    {
      "epoch": 1.17,
      "grad_norm": 3.4496450424194336,
      "learning_rate": 0.00017425839952132157,
      "loss": 1.7404,
      "step": 58400
    },
    {
      "epoch": 1.17,
      "grad_norm": 3.8608267307281494,
      "learning_rate": 0.00017417417727387394,
      "loss": 1.7359,
      "step": 58500
    },
    {
      "epoch": 1.17,
      "grad_norm": 3.2396814823150635,
      "learning_rate": 0.0001740898378952759,
      "loss": 1.7303,
      "step": 58600
    },
    {
      "epoch": 1.17,
      "grad_norm": 3.0841903686523438,
      "learning_rate": 0.00017400538151871083,
      "loss": 1.7235,
      "step": 58700
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.4068713188171387,
      "learning_rate": 0.00017392080827754688,
      "loss": 1.7267,
      "step": 58800
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.40071177482605,
      "learning_rate": 0.0001738361183053367,
      "loss": 1.7268,
      "step": 58900
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.704521417617798,
      "learning_rate": 0.0001737513117358174,
      "loss": 1.7137,
      "step": 59000
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.7676522731781006,
      "learning_rate": 0.00017366638870291006,
      "loss": 1.7238,
      "step": 59100
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.367976665496826,
      "learning_rate": 0.00017358134934071978,
      "loss": 1.7187,
      "step": 59200
    },
    {
      "epoch": 1.19,
      "grad_norm": 3.6169140338897705,
      "learning_rate": 0.0001734961937835353,
      "loss": 1.7184,
      "step": 59300
    },
    {
      "epoch": 1.19,
      "grad_norm": 4.074030876159668,
      "learning_rate": 0.00017341092216582887,
      "loss": 1.725,
      "step": 59400
    },
    {
      "epoch": 1.19,
      "grad_norm": 3.1258773803710938,
      "learning_rate": 0.00017332553462225602,
      "loss": 1.7352,
      "step": 59500
    },
    {
      "epoch": 1.19,
      "grad_norm": 4.720520973205566,
      "learning_rate": 0.00017324003128765534,
      "loss": 1.7157,
      "step": 59600
    },
    {
      "epoch": 1.19,
      "grad_norm": 3.913037061691284,
      "learning_rate": 0.00017315441229704822,
      "loss": 1.731,
      "step": 59700
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.120488405227661,
      "learning_rate": 0.0001730686777856388,
      "loss": 1.7081,
      "step": 59800
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.5652220249176025,
      "learning_rate": 0.00017298282788881354,
      "loss": 1.7261,
      "step": 59900
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.2139482498168945,
      "learning_rate": 0.00017289686274214118,
      "loss": 1.7402,
      "step": 60000
    },
    {
      "epoch": 1.2,
      "grad_norm": 5.687899589538574,
      "learning_rate": 0.00017281078248137233,
      "loss": 1.7232,
      "step": 60100
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.899282455444336,
      "learning_rate": 0.0001727245872424396,
      "loss": 1.7435,
      "step": 60200
    },
    {
      "epoch": 1.21,
      "grad_norm": 3.3017613887786865,
      "learning_rate": 0.00017263827716145692,
      "loss": 1.7316,
      "step": 60300
    },
    {
      "epoch": 1.21,
      "grad_norm": 3.8612136840820312,
      "learning_rate": 0.00017255185237471978,
      "loss": 1.7174,
      "step": 60400
    },
    {
      "epoch": 1.21,
      "grad_norm": 3.528876543045044,
      "learning_rate": 0.0001724653130187047,
      "loss": 1.7383,
      "step": 60500
    },
    {
      "epoch": 1.21,
      "grad_norm": 3.928339958190918,
      "learning_rate": 0.00017237865923006905,
      "loss": 1.7312,
      "step": 60600
    },
    {
      "epoch": 1.21,
      "grad_norm": 3.1144044399261475,
      "learning_rate": 0.00017229189114565107,
      "loss": 1.7024,
      "step": 60700
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.242532730102539,
      "learning_rate": 0.00017220500890246943,
      "loss": 1.7324,
      "step": 60800
    },
    {
      "epoch": 1.22,
      "grad_norm": 4.266125202178955,
      "learning_rate": 0.00017211801263772295,
      "loss": 1.7158,
      "step": 60900
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.1732802391052246,
      "learning_rate": 0.0001720309024887907,
      "loss": 1.7571,
      "step": 61000
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.6547253131866455,
      "learning_rate": 0.00017194367859323147,
      "loss": 1.6914,
      "step": 61100
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.2209808826446533,
      "learning_rate": 0.00017185634108878367,
      "loss": 1.7172,
      "step": 61200
    },
    {
      "epoch": 1.23,
      "grad_norm": 4.107367515563965,
      "learning_rate": 0.00017176889011336516,
      "loss": 1.7037,
      "step": 61300
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.6888062953948975,
      "learning_rate": 0.000171681325805073,
      "loss": 1.73,
      "step": 61400
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.8829658031463623,
      "learning_rate": 0.00017159364830218312,
      "loss": 1.733,
      "step": 61500
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.342973232269287,
      "learning_rate": 0.00017150585774315032,
      "loss": 1.7252,
      "step": 61600
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.599332094192505,
      "learning_rate": 0.00017141795426660786,
      "loss": 1.7281,
      "step": 61700
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.5834481716156006,
      "learning_rate": 0.00017132993801136727,
      "loss": 1.7208,
      "step": 61800
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.8178536891937256,
      "learning_rate": 0.00017124180911641835,
      "loss": 1.706,
      "step": 61900
    },
    {
      "epoch": 1.24,
      "grad_norm": 5.336187839508057,
      "learning_rate": 0.00017115356772092857,
      "loss": 1.7247,
      "step": 62000
    },
    {
      "epoch": 1.24,
      "grad_norm": 4.5414276123046875,
      "learning_rate": 0.0001710652139642431,
      "loss": 1.7149,
      "step": 62100
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.436131238937378,
      "learning_rate": 0.0001709767479858847,
      "loss": 1.729,
      "step": 62200
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.0591485500335693,
      "learning_rate": 0.00017088816992555313,
      "loss": 1.7328,
      "step": 62300
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.796072483062744,
      "learning_rate": 0.0001707994799231253,
      "loss": 1.7132,
      "step": 62400
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.5054192543029785,
      "learning_rate": 0.00017071067811865476,
      "loss": 1.6963,
      "step": 62500
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.4001994132995605,
      "learning_rate": 0.00017062176465237175,
      "loss": 1.733,
      "step": 62600
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.210514545440674,
      "learning_rate": 0.0001705327396646827,
      "loss": 1.7207,
      "step": 62700
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.443103790283203,
      "learning_rate": 0.0001704436032961703,
      "loss": 1.7513,
      "step": 62800
    },
    {
      "epoch": 1.26,
      "grad_norm": 4.046875476837158,
      "learning_rate": 0.000170354355687593,
      "loss": 1.6966,
      "step": 62900
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.8006932735443115,
      "learning_rate": 0.00017026499697988493,
      "loss": 1.7317,
      "step": 63000
    },
    {
      "epoch": 1.26,
      "grad_norm": 4.081901550292969,
      "learning_rate": 0.00017017552731415575,
      "loss": 1.7069,
      "step": 63100
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.9259650707244873,
      "learning_rate": 0.00017008594683169017,
      "loss": 1.7169,
      "step": 63200
    },
    {
      "epoch": 1.27,
      "grad_norm": 3.133815050125122,
      "learning_rate": 0.00016999625567394814,
      "loss": 1.7762,
      "step": 63300
    },
    {
      "epoch": 1.27,
      "grad_norm": 3.7123918533325195,
      "learning_rate": 0.0001699064539825641,
      "loss": 1.7191,
      "step": 63400
    },
    {
      "epoch": 1.27,
      "grad_norm": 3.7288360595703125,
      "learning_rate": 0.00016981654189934727,
      "loss": 1.7105,
      "step": 63500
    },
    {
      "epoch": 1.27,
      "grad_norm": 3.2778549194335938,
      "learning_rate": 0.00016972651956628107,
      "loss": 1.7145,
      "step": 63600
    },
    {
      "epoch": 1.27,
      "grad_norm": 3.702660083770752,
      "learning_rate": 0.00016963638712552307,
      "loss": 1.728,
      "step": 63700
    },
    {
      "epoch": 1.28,
      "grad_norm": 4.063478469848633,
      "learning_rate": 0.00016954614471940472,
      "loss": 1.7186,
      "step": 63800
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.815460681915283,
      "learning_rate": 0.00016945579249043102,
      "loss": 1.7074,
      "step": 63900
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.8016765117645264,
      "learning_rate": 0.0001693653305812805,
      "loss": 1.7335,
      "step": 64000
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.7532432079315186,
      "learning_rate": 0.0001692747591348049,
      "loss": 1.7065,
      "step": 64100
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.071763277053833,
      "learning_rate": 0.00016918407829402888,
      "loss": 1.7319,
      "step": 64200
    },
    {
      "epoch": 1.29,
      "grad_norm": 3.8572070598602295,
      "learning_rate": 0.00016909328820214985,
      "loss": 1.7229,
      "step": 64300
    },
    {
      "epoch": 1.29,
      "grad_norm": 3.952826499938965,
      "learning_rate": 0.00016900238900253775,
      "loss": 1.7058,
      "step": 64400
    },
    {
      "epoch": 1.29,
      "grad_norm": 3.252627372741699,
      "learning_rate": 0.00016891138083873487,
      "loss": 1.7134,
      "step": 64500
    },
    {
      "epoch": 1.29,
      "grad_norm": 3.549039125442505,
      "learning_rate": 0.00016882026385445546,
      "loss": 1.7143,
      "step": 64600
    },
    {
      "epoch": 1.29,
      "grad_norm": 3.1175613403320312,
      "learning_rate": 0.00016872903819358572,
      "loss": 1.7306,
      "step": 64700
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.2974774837493896,
      "learning_rate": 0.00016863770400018342,
      "loss": 1.7164,
      "step": 64800
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.452535152435303,
      "learning_rate": 0.00016854626141847768,
      "loss": 1.735,
      "step": 64900
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.2025372982025146,
      "learning_rate": 0.00016845471059286887,
      "loss": 1.7295,
      "step": 65000
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.938091993331909,
      "learning_rate": 0.0001683630516679282,
      "loss": 1.7229,
      "step": 65100
    },
    {
      "epoch": 1.3,
      "grad_norm": 5.560149192810059,
      "learning_rate": 0.00016827128478839767,
      "loss": 1.719,
      "step": 65200
    },
    {
      "epoch": 1.31,
      "grad_norm": 3.7657864093780518,
      "learning_rate": 0.00016817941009918962,
      "loss": 1.7086,
      "step": 65300
    },
    {
      "epoch": 1.31,
      "grad_norm": 4.127791404724121,
      "learning_rate": 0.0001680874277453868,
      "loss": 1.7457,
      "step": 65400
    },
    {
      "epoch": 1.31,
      "grad_norm": 3.5360288619995117,
      "learning_rate": 0.00016799533787224192,
      "loss": 1.7344,
      "step": 65500
    },
    {
      "epoch": 1.31,
      "grad_norm": 3.8262555599212646,
      "learning_rate": 0.0001679031406251774,
      "loss": 1.709,
      "step": 65600
    },
    {
      "epoch": 1.31,
      "grad_norm": 3.15946364402771,
      "learning_rate": 0.0001678108361497853,
      "loss": 1.738,
      "step": 65700
    },
    {
      "epoch": 1.32,
      "grad_norm": 7.470615863800049,
      "learning_rate": 0.000167718424591827,
      "loss": 1.7448,
      "step": 65800
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.6769423484802246,
      "learning_rate": 0.00016762590609723294,
      "loss": 1.7303,
      "step": 65900
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.334970474243164,
      "learning_rate": 0.00016753328081210245,
      "loss": 1.7753,
      "step": 66000
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.3025805950164795,
      "learning_rate": 0.0001674405488827035,
      "loss": 1.742,
      "step": 66100
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.7356605529785156,
      "learning_rate": 0.0001673477104554725,
      "loss": 1.7112,
      "step": 66200
    },
    {
      "epoch": 1.33,
      "grad_norm": 3.6343438625335693,
      "learning_rate": 0.000167254765677014,
      "loss": 1.7373,
      "step": 66300
    },
    {
      "epoch": 1.33,
      "grad_norm": 3.5916709899902344,
      "learning_rate": 0.00016716171469410043,
      "loss": 1.7077,
      "step": 66400
    },
    {
      "epoch": 1.33,
      "grad_norm": 3.1436121463775635,
      "learning_rate": 0.000167068557653672,
      "loss": 1.7417,
      "step": 66500
    },
    {
      "epoch": 1.33,
      "grad_norm": 3.37080454826355,
      "learning_rate": 0.00016697529470283647,
      "loss": 1.713,
      "step": 66600
    },
    {
      "epoch": 1.33,
      "grad_norm": 3.1513283252716064,
      "learning_rate": 0.0001668819259888687,
      "loss": 1.7088,
      "step": 66700
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.4533982276916504,
      "learning_rate": 0.00016678845165921065,
      "loss": 1.7268,
      "step": 66800
    },
    {
      "epoch": 1.34,
      "grad_norm": 4.096078395843506,
      "learning_rate": 0.00016669487186147107,
      "loss": 1.714,
      "step": 66900
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.778665781021118,
      "learning_rate": 0.00016660118674342517,
      "loss": 1.7344,
      "step": 67000
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.7214882373809814,
      "learning_rate": 0.0001665073964530146,
      "loss": 1.7395,
      "step": 67100
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.731616497039795,
      "learning_rate": 0.00016641350113834704,
      "loss": 1.7371,
      "step": 67200
    },
    {
      "epoch": 1.35,
      "grad_norm": 3.602813482284546,
      "learning_rate": 0.00016631950094769595,
      "loss": 1.747,
      "step": 67300
    },
    {
      "epoch": 1.35,
      "grad_norm": 3.215538263320923,
      "learning_rate": 0.00016622539602950052,
      "loss": 1.7085,
      "step": 67400
    },
    {
      "epoch": 1.35,
      "grad_norm": 3.530777931213379,
      "learning_rate": 0.00016613118653236518,
      "loss": 1.7339,
      "step": 67500
    },
    {
      "epoch": 1.35,
      "grad_norm": 4.23131799697876,
      "learning_rate": 0.0001660368726050597,
      "loss": 1.7239,
      "step": 67600
    },
    {
      "epoch": 1.35,
      "grad_norm": 3.508707284927368,
      "learning_rate": 0.00016594245439651855,
      "loss": 1.7218,
      "step": 67700
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.832519769668579,
      "learning_rate": 0.00016584793205584098,
      "loss": 1.7353,
      "step": 67800
    },
    {
      "epoch": 1.36,
      "grad_norm": 5.1355485916137695,
      "learning_rate": 0.00016575330573229076,
      "loss": 1.741,
      "step": 67900
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.548438549041748,
      "learning_rate": 0.00016565857557529566,
      "loss": 1.7107,
      "step": 68000
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.6881871223449707,
      "learning_rate": 0.00016556374173444754,
      "loss": 1.7269,
      "step": 68100
    },
    {
      "epoch": 1.36,
      "grad_norm": 3.7807488441467285,
      "learning_rate": 0.00016546880435950207,
      "loss": 1.7053,
      "step": 68200
    },
    {
      "epoch": 1.37,
      "grad_norm": 3.6559550762176514,
      "learning_rate": 0.0001653737636003782,
      "loss": 1.7111,
      "step": 68300
    },
    {
      "epoch": 1.37,
      "grad_norm": 3.747882127761841,
      "learning_rate": 0.00016527861960715837,
      "loss": 1.7328,
      "step": 68400
    },
    {
      "epoch": 1.37,
      "grad_norm": 3.2701022624969482,
      "learning_rate": 0.0001651833725300879,
      "loss": 1.7035,
      "step": 68500
    },
    {
      "epoch": 1.37,
      "grad_norm": 3.975463628768921,
      "learning_rate": 0.00016508802251957486,
      "loss": 1.7113,
      "step": 68600
    },
    {
      "epoch": 1.37,
      "grad_norm": 3.3043503761291504,
      "learning_rate": 0.00016499256972619,
      "loss": 1.7098,
      "step": 68700
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.590211868286133,
      "learning_rate": 0.0001648970143006663,
      "loss": 1.703,
      "step": 68800
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.6216697692871094,
      "learning_rate": 0.00016480135639389883,
      "loss": 1.7216,
      "step": 68900
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.495440721511841,
      "learning_rate": 0.00016470559615694446,
      "loss": 1.6918,
      "step": 69000
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.4434728622436523,
      "learning_rate": 0.00016460973374102163,
      "loss": 1.7256,
      "step": 69100
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.390911340713501,
      "learning_rate": 0.00016451376929751027,
      "loss": 1.7014,
      "step": 69200
    },
    {
      "epoch": 1.39,
      "grad_norm": 3.573951005935669,
      "learning_rate": 0.0001644177029779513,
      "loss": 1.7554,
      "step": 69300
    },
    {
      "epoch": 1.39,
      "grad_norm": 3.1262316703796387,
      "learning_rate": 0.0001643215349340465,
      "loss": 1.709,
      "step": 69400
    },
    {
      "epoch": 1.39,
      "grad_norm": 3.4953479766845703,
      "learning_rate": 0.00016422526531765846,
      "loss": 1.7216,
      "step": 69500
    },
    {
      "epoch": 1.39,
      "grad_norm": 3.2354278564453125,
      "learning_rate": 0.0001641288942808099,
      "loss": 1.7309,
      "step": 69600
    },
    {
      "epoch": 1.39,
      "grad_norm": 3.721240520477295,
      "learning_rate": 0.00016403242197568396,
      "loss": 1.7229,
      "step": 69700
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.8275465965270996,
      "learning_rate": 0.0001639358485546235,
      "loss": 1.6939,
      "step": 69800
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.6044185161590576,
      "learning_rate": 0.00016383917417013116,
      "loss": 1.74,
      "step": 69900
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.954141139984131,
      "learning_rate": 0.000163742398974869,
      "loss": 1.7015,
      "step": 70000
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.456801176071167,
      "learning_rate": 0.0001636455231216582,
      "loss": 1.7345,
      "step": 70100
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.3491640090942383,
      "learning_rate": 0.00016354854676347907,
      "loss": 1.7327,
      "step": 70200
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.5464932918548584,
      "learning_rate": 0.00016345147005347044,
      "loss": 1.7469,
      "step": 70300
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.144611358642578,
      "learning_rate": 0.0001633542931449297,
      "loss": 1.7215,
      "step": 70400
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.9559438228607178,
      "learning_rate": 0.00016325701619131246,
      "loss": 1.7136,
      "step": 70500
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.2746949195861816,
      "learning_rate": 0.00016315963934623228,
      "loss": 1.6862,
      "step": 70600
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.714566469192505,
      "learning_rate": 0.00016306216276346054,
      "loss": 1.7264,
      "step": 70700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.7576215267181396,
      "learning_rate": 0.00016296458659692602,
      "loss": 1.7073,
      "step": 70800
    },
    {
      "epoch": 1.42,
      "grad_norm": 5.203591823577881,
      "learning_rate": 0.00016286691100071482,
      "loss": 1.7493,
      "step": 70900
    },
    {
      "epoch": 1.42,
      "grad_norm": 4.052161693572998,
      "learning_rate": 0.00016276913612907007,
      "loss": 1.693,
      "step": 71000
    },
    {
      "epoch": 1.42,
      "grad_norm": 3.0390024185180664,
      "learning_rate": 0.0001626712621363916,
      "loss": 1.6946,
      "step": 71100
    },
    {
      "epoch": 1.42,
      "grad_norm": 3.349884033203125,
      "learning_rate": 0.0001625732891772358,
      "loss": 1.715,
      "step": 71200
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.3437917232513428,
      "learning_rate": 0.00016247521740631537,
      "loss": 1.7317,
      "step": 71300
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.317652940750122,
      "learning_rate": 0.00016237704697849903,
      "loss": 1.7433,
      "step": 71400
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.460008144378662,
      "learning_rate": 0.00016227877804881127,
      "loss": 1.7298,
      "step": 71500
    },
    {
      "epoch": 1.43,
      "grad_norm": 4.581823348999023,
      "learning_rate": 0.00016218041077243212,
      "loss": 1.7335,
      "step": 71600
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.4049625396728516,
      "learning_rate": 0.00016208194530469697,
      "loss": 1.6976,
      "step": 71700
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.159684181213379,
      "learning_rate": 0.00016198338180109626,
      "loss": 1.7213,
      "step": 71800
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.6705992221832275,
      "learning_rate": 0.00016188472041727515,
      "loss": 1.7189,
      "step": 71900
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.9383840560913086,
      "learning_rate": 0.00016178596130903344,
      "loss": 1.7385,
      "step": 72000
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.761204481124878,
      "learning_rate": 0.0001616871046323253,
      "loss": 1.695,
      "step": 72100
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.6975040435791016,
      "learning_rate": 0.00016158815054325887,
      "loss": 1.7292,
      "step": 72200
    },
    {
      "epoch": 1.45,
      "grad_norm": 3.296895742416382,
      "learning_rate": 0.00016148909919809615,
      "loss": 1.7023,
      "step": 72300
    },
    {
      "epoch": 1.45,
      "grad_norm": 3.191147804260254,
      "learning_rate": 0.00016138995075325277,
      "loss": 1.7028,
      "step": 72400
    },
    {
      "epoch": 1.45,
      "grad_norm": 4.131357192993164,
      "learning_rate": 0.00016129070536529766,
      "loss": 1.7385,
      "step": 72500
    },
    {
      "epoch": 1.45,
      "grad_norm": 3.71269154548645,
      "learning_rate": 0.0001611913631909528,
      "loss": 1.7086,
      "step": 72600
    },
    {
      "epoch": 1.45,
      "grad_norm": 3.3649818897247314,
      "learning_rate": 0.00016109192438709308,
      "loss": 1.7162,
      "step": 72700
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.2803828716278076,
      "learning_rate": 0.00016099238911074592,
      "loss": 1.7399,
      "step": 72800
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.161041736602783,
      "learning_rate": 0.0001608927575190911,
      "loss": 1.733,
      "step": 72900
    },
    {
      "epoch": 1.46,
      "grad_norm": 4.006885051727295,
      "learning_rate": 0.00016079302976946055,
      "loss": 1.7143,
      "step": 73000
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.1588265895843506,
      "learning_rate": 0.00016069320601933796,
      "loss": 1.7133,
      "step": 73100
    },
    {
      "epoch": 1.46,
      "grad_norm": 4.022718906402588,
      "learning_rate": 0.00016059328642635862,
      "loss": 1.7374,
      "step": 73200
    },
    {
      "epoch": 1.47,
      "grad_norm": 4.164827346801758,
      "learning_rate": 0.0001604932711483093,
      "loss": 1.693,
      "step": 73300
    },
    {
      "epoch": 1.47,
      "grad_norm": 3.158599615097046,
      "learning_rate": 0.00016039316034312769,
      "loss": 1.7234,
      "step": 73400
    },
    {
      "epoch": 1.47,
      "grad_norm": 3.8133063316345215,
      "learning_rate": 0.00016029295416890248,
      "loss": 1.7335,
      "step": 73500
    },
    {
      "epoch": 1.47,
      "grad_norm": 3.8025646209716797,
      "learning_rate": 0.00016019265278387286,
      "loss": 1.7274,
      "step": 73600
    },
    {
      "epoch": 1.47,
      "grad_norm": 4.051915645599365,
      "learning_rate": 0.0001600922563464284,
      "loss": 1.7147,
      "step": 73700
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.291876792907715,
      "learning_rate": 0.00015999176501510883,
      "loss": 1.6931,
      "step": 73800
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.3556294441223145,
      "learning_rate": 0.00015989117894860358,
      "loss": 1.6872,
      "step": 73900
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.314195394515991,
      "learning_rate": 0.0001597904983057519,
      "loss": 1.7179,
      "step": 74000
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.2207233905792236,
      "learning_rate": 0.0001596897232455422,
      "loss": 1.7175,
      "step": 74100
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.4538068771362305,
      "learning_rate": 0.00015958885392711202,
      "loss": 1.7159,
      "step": 74200
    },
    {
      "epoch": 1.49,
      "grad_norm": 3.379268169403076,
      "learning_rate": 0.00015948789050974788,
      "loss": 1.7085,
      "step": 74300
    },
    {
      "epoch": 1.49,
      "grad_norm": 3.8437578678131104,
      "learning_rate": 0.00015938683315288473,
      "loss": 1.7137,
      "step": 74400
    },
    {
      "epoch": 1.49,
      "grad_norm": 3.0241167545318604,
      "learning_rate": 0.00015928568201610595,
      "loss": 1.7255,
      "step": 74500
    },
    {
      "epoch": 1.49,
      "grad_norm": 3.8038270473480225,
      "learning_rate": 0.00015918443725914297,
      "loss": 1.7028,
      "step": 74600
    },
    {
      "epoch": 1.49,
      "grad_norm": 4.40185546875,
      "learning_rate": 0.0001590830990418751,
      "loss": 1.7056,
      "step": 74700
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.4698076248168945,
      "learning_rate": 0.0001589816675243292,
      "loss": 1.6909,
      "step": 74800
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.515606164932251,
      "learning_rate": 0.0001588801428666795,
      "loss": 1.694,
      "step": 74900
    },
    {
      "epoch": 1.5,
      "grad_norm": 4.206979274749756,
      "learning_rate": 0.00015877852522924732,
      "loss": 1.7246,
      "step": 75000
    },
    {
      "epoch": 1.5,
      "grad_norm": 4.139703750610352,
      "learning_rate": 0.00015867681477250073,
      "loss": 1.7023,
      "step": 75100
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.726470947265625,
      "learning_rate": 0.00015857501165705444,
      "loss": 1.6902,
      "step": 75200
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.9474034309387207,
      "learning_rate": 0.00015847311604366948,
      "loss": 1.7114,
      "step": 75300
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.1038827896118164,
      "learning_rate": 0.0001583711280932529,
      "loss": 1.7071,
      "step": 75400
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.359787940979004,
      "learning_rate": 0.00015826904796685762,
      "loss": 1.676,
      "step": 75500
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.5930919647216797,
      "learning_rate": 0.00015816687582568208,
      "loss": 1.703,
      "step": 75600
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.3128557205200195,
      "learning_rate": 0.00015806461183107007,
      "loss": 1.7157,
      "step": 75700
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.304732322692871,
      "learning_rate": 0.00015796225614451032,
      "loss": 1.7014,
      "step": 75800
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.9562156200408936,
      "learning_rate": 0.00015785980892763654,
      "loss": 1.7482,
      "step": 75900
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.0458950996398926,
      "learning_rate": 0.00015775727034222675,
      "loss": 1.7127,
      "step": 76000
    },
    {
      "epoch": 1.52,
      "grad_norm": 4.757762432098389,
      "learning_rate": 0.00015765464055020347,
      "loss": 1.6845,
      "step": 76100
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.4292290210723877,
      "learning_rate": 0.00015755191971363313,
      "loss": 1.6996,
      "step": 76200
    },
    {
      "epoch": 1.53,
      "grad_norm": 3.901801824569702,
      "learning_rate": 0.0001574491079947259,
      "loss": 1.708,
      "step": 76300
    },
    {
      "epoch": 1.53,
      "grad_norm": 3.7505571842193604,
      "learning_rate": 0.00015734620555583556,
      "loss": 1.6921,
      "step": 76400
    },
    {
      "epoch": 1.53,
      "grad_norm": 3.5862252712249756,
      "learning_rate": 0.0001572432125594591,
      "loss": 1.7225,
      "step": 76500
    },
    {
      "epoch": 1.53,
      "grad_norm": 4.283257007598877,
      "learning_rate": 0.00015714012916823652,
      "loss": 1.7242,
      "step": 76600
    },
    {
      "epoch": 1.53,
      "grad_norm": 3.261298656463623,
      "learning_rate": 0.00015703695554495056,
      "loss": 1.6935,
      "step": 76700
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.2090888023376465,
      "learning_rate": 0.00015693369185252646,
      "loss": 1.7094,
      "step": 76800
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.280197620391846,
      "learning_rate": 0.0001568303382540317,
      "loss": 1.7308,
      "step": 76900
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.2085280418395996,
      "learning_rate": 0.00015672689491267567,
      "loss": 1.7109,
      "step": 77000
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.0002241134643555,
      "learning_rate": 0.00015662336199180957,
      "loss": 1.7247,
      "step": 77100
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.927553653717041,
      "learning_rate": 0.000156519739654926,
      "loss": 1.7139,
      "step": 77200
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.5245678424835205,
      "learning_rate": 0.00015641602806565878,
      "loss": 1.7118,
      "step": 77300
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.314302921295166,
      "learning_rate": 0.00015631222738778265,
      "loss": 1.729,
      "step": 77400
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.899217128753662,
      "learning_rate": 0.00015620833778521307,
      "loss": 1.7141,
      "step": 77500
    },
    {
      "epoch": 1.55,
      "grad_norm": 3.0865073204040527,
      "learning_rate": 0.0001561043594220059,
      "loss": 1.7069,
      "step": 77600
    },
    {
      "epoch": 1.55,
      "grad_norm": 4.44010066986084,
      "learning_rate": 0.00015600029246235715,
      "loss": 1.7075,
      "step": 77700
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.37117862701416,
      "learning_rate": 0.00015589613707060277,
      "loss": 1.7247,
      "step": 77800
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.756946563720703,
      "learning_rate": 0.00015579189341121834,
      "loss": 1.702,
      "step": 77900
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.3213934898376465,
      "learning_rate": 0.00015568756164881882,
      "loss": 1.7022,
      "step": 78000
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.266364097595215,
      "learning_rate": 0.0001555831419481583,
      "loss": 1.7185,
      "step": 78100
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.330582618713379,
      "learning_rate": 0.00015547863447412975,
      "loss": 1.7014,
      "step": 78200
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.6651699542999268,
      "learning_rate": 0.00015537403939176473,
      "loss": 1.7147,
      "step": 78300
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.6242802143096924,
      "learning_rate": 0.00015526935686623316,
      "loss": 1.732,
      "step": 78400
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.8444595336914062,
      "learning_rate": 0.00015516458706284303,
      "loss": 1.7137,
      "step": 78500
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.1971065998077393,
      "learning_rate": 0.00015505973014704017,
      "loss": 1.7029,
      "step": 78600
    },
    {
      "epoch": 1.57,
      "grad_norm": 3.4002931118011475,
      "learning_rate": 0.00015495478628440792,
      "loss": 1.7092,
      "step": 78700
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.252228260040283,
      "learning_rate": 0.00015484975564066704,
      "loss": 1.7122,
      "step": 78800
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.7346577644348145,
      "learning_rate": 0.00015474463838167522,
      "loss": 1.7332,
      "step": 78900
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.568159818649292,
      "learning_rate": 0.00015463943467342693,
      "loss": 1.7168,
      "step": 79000
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.6691110134124756,
      "learning_rate": 0.00015453414468205318,
      "loss": 1.6931,
      "step": 79100
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.87267804145813,
      "learning_rate": 0.0001544287685738213,
      "loss": 1.7047,
      "step": 79200
    },
    {
      "epoch": 1.59,
      "grad_norm": 3.288722276687622,
      "learning_rate": 0.0001543233065151345,
      "loss": 1.7143,
      "step": 79300
    },
    {
      "epoch": 1.59,
      "grad_norm": 3.8198719024658203,
      "learning_rate": 0.00015421775867253178,
      "loss": 1.7055,
      "step": 79400
    },
    {
      "epoch": 1.59,
      "grad_norm": 7.532622814178467,
      "learning_rate": 0.00015411212521268758,
      "loss": 1.6935,
      "step": 79500
    },
    {
      "epoch": 1.59,
      "grad_norm": 3.4905779361724854,
      "learning_rate": 0.0001540064063024116,
      "loss": 1.7263,
      "step": 79600
    },
    {
      "epoch": 1.59,
      "grad_norm": 3.5444228649139404,
      "learning_rate": 0.00015390060210864834,
      "loss": 1.6929,
      "step": 79700
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.263530254364014,
      "learning_rate": 0.00015379471279847713,
      "loss": 1.6959,
      "step": 79800
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.1025137901306152,
      "learning_rate": 0.00015368873853911164,
      "loss": 1.7275,
      "step": 79900
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.968282699584961,
      "learning_rate": 0.00015358267949789966,
      "loss": 1.7076,
      "step": 80000
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.4454100131988525,
      "learning_rate": 0.0001534765358423229,
      "loss": 1.7178,
      "step": 80100
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.79379940032959,
      "learning_rate": 0.00015337030773999674,
      "loss": 1.6978,
      "step": 80200
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.5039000511169434,
      "learning_rate": 0.00015326399535866978,
      "loss": 1.7135,
      "step": 80300
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.8292744159698486,
      "learning_rate": 0.0001531575988662238,
      "loss": 1.6902,
      "step": 80400
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.5832996368408203,
      "learning_rate": 0.0001530511184306734,
      "loss": 1.7272,
      "step": 80500
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.2859647274017334,
      "learning_rate": 0.00015294455422016574,
      "loss": 1.7015,
      "step": 80600
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.1801185607910156,
      "learning_rate": 0.00015283790640298017,
      "loss": 1.7062,
      "step": 80700
    },
    {
      "epoch": 1.62,
      "grad_norm": 4.147200107574463,
      "learning_rate": 0.00015273117514752826,
      "loss": 1.7034,
      "step": 80800
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.4437096118927,
      "learning_rate": 0.00015262436062235315,
      "loss": 1.7139,
      "step": 80900
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.567233085632324,
      "learning_rate": 0.0001525174629961296,
      "loss": 1.7128,
      "step": 81000
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.0209925174713135,
      "learning_rate": 0.00015241048243766348,
      "loss": 1.7034,
      "step": 81100
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.561424732208252,
      "learning_rate": 0.00015230341911589182,
      "loss": 1.7209,
      "step": 81200
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.708348035812378,
      "learning_rate": 0.00015219627319988213,
      "loss": 1.7016,
      "step": 81300
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.321240186691284,
      "learning_rate": 0.00015208904485883244,
      "loss": 1.6981,
      "step": 81400
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.577303171157837,
      "learning_rate": 0.00015198173426207094,
      "loss": 1.7104,
      "step": 81500
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.958380937576294,
      "learning_rate": 0.00015187434157905576,
      "loss": 1.6853,
      "step": 81600
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.264350652694702,
      "learning_rate": 0.00015176686697937453,
      "loss": 1.7139,
      "step": 81700
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.8236429691314697,
      "learning_rate": 0.00015165931063274441,
      "loss": 1.7292,
      "step": 81800
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.3809096813201904,
      "learning_rate": 0.00015155167270901142,
      "loss": 1.7059,
      "step": 81900
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.139348268508911,
      "learning_rate": 0.00015144395337815064,
      "loss": 1.726,
      "step": 82000
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.774827241897583,
      "learning_rate": 0.00015133615281026557,
      "loss": 1.7026,
      "step": 82100
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.9490509033203125,
      "learning_rate": 0.00015122827117558803,
      "loss": 1.7033,
      "step": 82200
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.1892898082733154,
      "learning_rate": 0.0001511203086444778,
      "loss": 1.6946,
      "step": 82300
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.440140962600708,
      "learning_rate": 0.00015101226538742247,
      "loss": 1.7117,
      "step": 82400
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.6092922687530518,
      "learning_rate": 0.00015090414157503714,
      "loss": 1.6925,
      "step": 82500
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.2557544708251953,
      "learning_rate": 0.00015079593737806399,
      "loss": 1.7074,
      "step": 82600
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.4822146892547607,
      "learning_rate": 0.00015068765296737233,
      "loss": 1.698,
      "step": 82700
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.1809020042419434,
      "learning_rate": 0.00015057928851395792,
      "loss": 1.6904,
      "step": 82800
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.990739345550537,
      "learning_rate": 0.00015047084418894305,
      "loss": 1.6952,
      "step": 82900
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.4259302616119385,
      "learning_rate": 0.0001503623201635761,
      "loss": 1.7083,
      "step": 83000
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.442553997039795,
      "learning_rate": 0.00015025371660923136,
      "loss": 1.7003,
      "step": 83100
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.7230029106140137,
      "learning_rate": 0.00015014503369740865,
      "loss": 1.6966,
      "step": 83200
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.878897190093994,
      "learning_rate": 0.00015003627159973309,
      "loss": 1.6982,
      "step": 83300
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.989219903945923,
      "learning_rate": 0.0001499274304879549,
      "loss": 1.6747,
      "step": 83400
    },
    {
      "epoch": 1.67,
      "grad_norm": 3.152923107147217,
      "learning_rate": 0.0001498185105339491,
      "loss": 1.6863,
      "step": 83500
    },
    {
      "epoch": 1.67,
      "grad_norm": 3.4861598014831543,
      "learning_rate": 0.00014970951190971512,
      "loss": 1.7001,
      "step": 83600
    },
    {
      "epoch": 1.67,
      "grad_norm": 3.071786403656006,
      "learning_rate": 0.00014960043478737662,
      "loss": 1.7081,
      "step": 83700
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.65855073928833,
      "learning_rate": 0.00014949127933918134,
      "loss": 1.6778,
      "step": 83800
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.3062751293182373,
      "learning_rate": 0.00014938204573750058,
      "loss": 1.6912,
      "step": 83900
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.197254180908203,
      "learning_rate": 0.00014927273415482915,
      "loss": 1.7028,
      "step": 84000
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.881802797317505,
      "learning_rate": 0.00014916334476378497,
      "loss": 1.7191,
      "step": 84100
    },
    {
      "epoch": 1.68,
      "grad_norm": 3.335754156112671,
      "learning_rate": 0.00014905387773710876,
      "loss": 1.7046,
      "step": 84200
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.292001962661743,
      "learning_rate": 0.00014894433324766392,
      "loss": 1.6841,
      "step": 84300
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.5825235843658447,
      "learning_rate": 0.00014883471146843617,
      "loss": 1.6776,
      "step": 84400
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.999434232711792,
      "learning_rate": 0.00014872501257253323,
      "loss": 1.6863,
      "step": 84500
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.1686818599700928,
      "learning_rate": 0.0001486152367331847,
      "loss": 1.7135,
      "step": 84600
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.621483564376831,
      "learning_rate": 0.0001485053841237415,
      "loss": 1.7191,
      "step": 84700
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.396699905395508,
      "learning_rate": 0.000148395454917676,
      "loss": 1.7149,
      "step": 84800
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.8513641357421875,
      "learning_rate": 0.00014828544928858136,
      "loss": 1.6876,
      "step": 84900
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.274188280105591,
      "learning_rate": 0.00014817536741017152,
      "loss": 1.7003,
      "step": 85000
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.224681377410889,
      "learning_rate": 0.00014806520945628078,
      "loss": 1.7056,
      "step": 85100
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.768460512161255,
      "learning_rate": 0.00014795497560086358,
      "loss": 1.669,
      "step": 85200
    },
    {
      "epoch": 1.71,
      "grad_norm": 3.382744073867798,
      "learning_rate": 0.00014784466601799423,
      "loss": 1.6815,
      "step": 85300
    },
    {
      "epoch": 1.71,
      "grad_norm": 3.7276055812835693,
      "learning_rate": 0.0001477342808818666,
      "loss": 1.6909,
      "step": 85400
    },
    {
      "epoch": 1.71,
      "grad_norm": 3.5400779247283936,
      "learning_rate": 0.0001476238203667939,
      "loss": 1.7123,
      "step": 85500
    },
    {
      "epoch": 1.71,
      "grad_norm": 3.333561897277832,
      "learning_rate": 0.00014751328464720841,
      "loss": 1.68,
      "step": 85600
    },
    {
      "epoch": 1.71,
      "grad_norm": 3.0506277084350586,
      "learning_rate": 0.00014740267389766102,
      "loss": 1.7298,
      "step": 85700
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.0129518508911133,
      "learning_rate": 0.00014729198829282127,
      "loss": 1.7163,
      "step": 85800
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.1740336418151855,
      "learning_rate": 0.0001471812280074768,
      "loss": 1.7041,
      "step": 85900
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.4960174560546875,
      "learning_rate": 0.0001470703932165333,
      "loss": 1.7063,
      "step": 86000
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.7242119312286377,
      "learning_rate": 0.0001469594840950139,
      "loss": 1.7193,
      "step": 86100
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.4779930114746094,
      "learning_rate": 0.00014684850081805935,
      "loss": 1.7136,
      "step": 86200
    },
    {
      "epoch": 1.73,
      "grad_norm": 4.01224422454834,
      "learning_rate": 0.00014673744356092736,
      "loss": 1.6886,
      "step": 86300
    },
    {
      "epoch": 1.73,
      "grad_norm": 3.6328823566436768,
      "learning_rate": 0.0001466263124989925,
      "loss": 1.7166,
      "step": 86400
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.7112605571746826,
      "learning_rate": 0.00014651510780774583,
      "loss": 1.6835,
      "step": 86500
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.7612879276275635,
      "learning_rate": 0.00014640382966279485,
      "loss": 1.716,
      "step": 86600
    },
    {
      "epoch": 1.73,
      "grad_norm": 3.8268203735351562,
      "learning_rate": 0.00014629247823986285,
      "loss": 1.7101,
      "step": 86700
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.429499626159668,
      "learning_rate": 0.00014618105371478897,
      "loss": 1.7318,
      "step": 86800
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.326573371887207,
      "learning_rate": 0.0001460695562635277,
      "loss": 1.6747,
      "step": 86900
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.6156623363494873,
      "learning_rate": 0.00014595798606214882,
      "loss": 1.6824,
      "step": 87000
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.357068061828613,
      "learning_rate": 0.0001458463432868368,
      "loss": 1.7145,
      "step": 87100
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.6516385078430176,
      "learning_rate": 0.00014573462811389088,
      "loss": 1.6962,
      "step": 87200
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.3551132678985596,
      "learning_rate": 0.00014562284071972453,
      "loss": 1.683,
      "step": 87300
    },
    {
      "epoch": 1.75,
      "grad_norm": 4.3693647384643555,
      "learning_rate": 0.00014551098128086538,
      "loss": 1.7006,
      "step": 87400
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.6617414951324463,
      "learning_rate": 0.00014539904997395468,
      "loss": 1.6931,
      "step": 87500
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.2406678199768066,
      "learning_rate": 0.0001452870469757473,
      "loss": 1.6752,
      "step": 87600
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.703172206878662,
      "learning_rate": 0.00014517497246311115,
      "loss": 1.7008,
      "step": 87700
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.841982364654541,
      "learning_rate": 0.00014506282661302735,
      "loss": 1.7086,
      "step": 87800
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.4661872386932373,
      "learning_rate": 0.00014495060960258938,
      "loss": 1.6973,
      "step": 87900
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.648998975753784,
      "learning_rate": 0.00014483832160900326,
      "loss": 1.7041,
      "step": 88000
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.596238136291504,
      "learning_rate": 0.00014472596280958703,
      "loss": 1.714,
      "step": 88100
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.682199716567993,
      "learning_rate": 0.0001446135333817706,
      "loss": 1.6929,
      "step": 88200
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.708414077758789,
      "learning_rate": 0.00014450103350309535,
      "loss": 1.7034,
      "step": 88300
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.867405891418457,
      "learning_rate": 0.00014438846335121402,
      "loss": 1.7125,
      "step": 88400
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.8527143001556396,
      "learning_rate": 0.0001442758231038902,
      "loss": 1.7208,
      "step": 88500
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.637730360031128,
      "learning_rate": 0.00014416311293899816,
      "loss": 1.7017,
      "step": 88600
    },
    {
      "epoch": 1.77,
      "grad_norm": 3.136979818344116,
      "learning_rate": 0.00014405033303452268,
      "loss": 1.7128,
      "step": 88700
    },
    {
      "epoch": 1.78,
      "grad_norm": 4.802621841430664,
      "learning_rate": 0.00014393748356855866,
      "loss": 1.7177,
      "step": 88800
    },
    {
      "epoch": 1.78,
      "grad_norm": 3.4467873573303223,
      "learning_rate": 0.00014382456471931075,
      "loss": 1.6974,
      "step": 88900
    },
    {
      "epoch": 1.78,
      "grad_norm": 4.367649078369141,
      "learning_rate": 0.0001437115766650933,
      "loss": 1.7075,
      "step": 89000
    },
    {
      "epoch": 1.78,
      "grad_norm": 3.436013698577881,
      "learning_rate": 0.00014359851958432981,
      "loss": 1.678,
      "step": 89100
    },
    {
      "epoch": 1.78,
      "grad_norm": 3.1758387088775635,
      "learning_rate": 0.00014348539365555282,
      "loss": 1.6932,
      "step": 89200
    },
    {
      "epoch": 1.79,
      "grad_norm": 2.8709349632263184,
      "learning_rate": 0.00014337219905740368,
      "loss": 1.6727,
      "step": 89300
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.708139657974243,
      "learning_rate": 0.00014325893596863208,
      "loss": 1.7098,
      "step": 89400
    },
    {
      "epoch": 1.79,
      "grad_norm": 4.390222072601318,
      "learning_rate": 0.0001431456045680959,
      "loss": 1.687,
      "step": 89500
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.806487560272217,
      "learning_rate": 0.0001430322050347609,
      "loss": 1.6858,
      "step": 89600
    },
    {
      "epoch": 1.79,
      "grad_norm": 3.429086923599243,
      "learning_rate": 0.00014291873754770037,
      "loss": 1.7145,
      "step": 89700
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.6191318035125732,
      "learning_rate": 0.00014280520228609502,
      "loss": 1.701,
      "step": 89800
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.4661474227905273,
      "learning_rate": 0.00014269159942923253,
      "loss": 1.7104,
      "step": 89900
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.0721280574798584,
      "learning_rate": 0.00014257792915650728,
      "loss": 1.7241,
      "step": 90000
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.2175064086914062,
      "learning_rate": 0.00014246419164742013,
      "loss": 1.6817,
      "step": 90100
    },
    {
      "epoch": 1.8,
      "grad_norm": 4.22261905670166,
      "learning_rate": 0.0001423503870815782,
      "loss": 1.6867,
      "step": 90200
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.9840404987335205,
      "learning_rate": 0.00014223651563869438,
      "loss": 1.7117,
      "step": 90300
    },
    {
      "epoch": 1.81,
      "grad_norm": 3.060767412185669,
      "learning_rate": 0.00014212257749858726,
      "loss": 1.6952,
      "step": 90400
    },
    {
      "epoch": 1.81,
      "grad_norm": 3.811305046081543,
      "learning_rate": 0.00014200857284118066,
      "loss": 1.7175,
      "step": 90500
    },
    {
      "epoch": 1.81,
      "grad_norm": 3.4281816482543945,
      "learning_rate": 0.00014189450184650353,
      "loss": 1.7075,
      "step": 90600
    },
    {
      "epoch": 1.81,
      "grad_norm": 3.606285572052002,
      "learning_rate": 0.00014178036469468953,
      "loss": 1.7047,
      "step": 90700
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.429044246673584,
      "learning_rate": 0.0001416661615659768,
      "loss": 1.7146,
      "step": 90800
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.2358269691467285,
      "learning_rate": 0.0001415518926407077,
      "loss": 1.7088,
      "step": 90900
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.288261890411377,
      "learning_rate": 0.00014143755809932845,
      "loss": 1.6991,
      "step": 91000
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.507356643676758,
      "learning_rate": 0.00014132315812238883,
      "loss": 1.6837,
      "step": 91100
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.102536678314209,
      "learning_rate": 0.0001412086928905421,
      "loss": 1.6844,
      "step": 91200
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.787712574005127,
      "learning_rate": 0.0001410941625845445,
      "loss": 1.6797,
      "step": 91300
    },
    {
      "epoch": 1.83,
      "grad_norm": 9.506422996520996,
      "learning_rate": 0.00014097956738525494,
      "loss": 1.7056,
      "step": 91400
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.7866714000701904,
      "learning_rate": 0.00014086490747363493,
      "loss": 1.6796,
      "step": 91500
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.856586217880249,
      "learning_rate": 0.00014075018303074806,
      "loss": 1.6595,
      "step": 91600
    },
    {
      "epoch": 1.83,
      "grad_norm": 3.35508131980896,
      "learning_rate": 0.00014063539423776,
      "loss": 1.7091,
      "step": 91700
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.9601128101348877,
      "learning_rate": 0.00014052054127593782,
      "loss": 1.6814,
      "step": 91800
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.322509288787842,
      "learning_rate": 0.00014040562432665005,
      "loss": 1.6938,
      "step": 91900
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.4480950832366943,
      "learning_rate": 0.00014029064357136628,
      "loss": 1.7133,
      "step": 92000
    },
    {
      "epoch": 1.84,
      "grad_norm": 3.25081467628479,
      "learning_rate": 0.00014017559919165675,
      "loss": 1.679,
      "step": 92100
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.9778339862823486,
      "learning_rate": 0.00014006049136919228,
      "loss": 1.7083,
      "step": 92200
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.981003522872925,
      "learning_rate": 0.00013994532028574385,
      "loss": 1.6999,
      "step": 92300
    },
    {
      "epoch": 1.85,
      "grad_norm": 3.663691520690918,
      "learning_rate": 0.00013983008612318228,
      "loss": 1.6844,
      "step": 92400
    },
    {
      "epoch": 1.85,
      "grad_norm": 3.44946551322937,
      "learning_rate": 0.00013971478906347806,
      "loss": 1.6955,
      "step": 92500
    },
    {
      "epoch": 1.85,
      "grad_norm": 3.6089653968811035,
      "learning_rate": 0.000139599429288701,
      "loss": 1.7025,
      "step": 92600
    },
    {
      "epoch": 1.85,
      "grad_norm": 4.227311611175537,
      "learning_rate": 0.00013948400698101992,
      "loss": 1.6898,
      "step": 92700
    },
    {
      "epoch": 1.86,
      "grad_norm": 3.8519065380096436,
      "learning_rate": 0.00013936852232270235,
      "loss": 1.6863,
      "step": 92800
    },
    {
      "epoch": 1.86,
      "grad_norm": 3.3633460998535156,
      "learning_rate": 0.0001392529754961144,
      "loss": 1.7284,
      "step": 92900
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.873133897781372,
      "learning_rate": 0.00013913736668372026,
      "loss": 1.6858,
      "step": 93000
    },
    {
      "epoch": 1.86,
      "grad_norm": 3.4834160804748535,
      "learning_rate": 0.000139021696068082,
      "loss": 1.6928,
      "step": 93100
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.8919568061828613,
      "learning_rate": 0.00013890596383185933,
      "loss": 1.6869,
      "step": 93200
    },
    {
      "epoch": 1.87,
      "grad_norm": 2.9903781414031982,
      "learning_rate": 0.00013879017015780927,
      "loss": 1.6706,
      "step": 93300
    },
    {
      "epoch": 1.87,
      "grad_norm": 3.2329070568084717,
      "learning_rate": 0.0001386743152287858,
      "loss": 1.7016,
      "step": 93400
    },
    {
      "epoch": 1.87,
      "grad_norm": 2.8896327018737793,
      "learning_rate": 0.00013855839922773968,
      "loss": 1.7277,
      "step": 93500
    },
    {
      "epoch": 1.87,
      "grad_norm": 3.544240713119507,
      "learning_rate": 0.0001384424223377181,
      "loss": 1.7155,
      "step": 93600
    },
    {
      "epoch": 1.87,
      "grad_norm": 2.9580023288726807,
      "learning_rate": 0.00013832638474186437,
      "loss": 1.6422,
      "step": 93700
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.345095157623291,
      "learning_rate": 0.00013821028662341776,
      "loss": 1.6903,
      "step": 93800
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.1725997924804688,
      "learning_rate": 0.00013809412816571297,
      "loss": 1.6906,
      "step": 93900
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.155991315841675,
      "learning_rate": 0.00013797790955218014,
      "loss": 1.6878,
      "step": 94000
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.712453842163086,
      "learning_rate": 0.00013786163096634422,
      "loss": 1.6976,
      "step": 94100
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.3110475540161133,
      "learning_rate": 0.00013774529259182508,
      "loss": 1.6968,
      "step": 94200
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.7633910179138184,
      "learning_rate": 0.00013762889461233684,
      "loss": 1.6791,
      "step": 94300
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.952622175216675,
      "learning_rate": 0.0001375124372116878,
      "loss": 1.6831,
      "step": 94400
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.8046579360961914,
      "learning_rate": 0.00013739592057378003,
      "loss": 1.7035,
      "step": 94500
    },
    {
      "epoch": 1.89,
      "grad_norm": 4.492152690887451,
      "learning_rate": 0.00013727934488260934,
      "loss": 1.701,
      "step": 94600
    },
    {
      "epoch": 1.89,
      "grad_norm": 3.309027910232544,
      "learning_rate": 0.00013716271032226452,
      "loss": 1.6663,
      "step": 94700
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.501859664916992,
      "learning_rate": 0.00013704601707692762,
      "loss": 1.6678,
      "step": 94800
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.6519336700439453,
      "learning_rate": 0.00013692926533087304,
      "loss": 1.6801,
      "step": 94900
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.896615505218506,
      "learning_rate": 0.00013681245526846783,
      "loss": 1.7049,
      "step": 95000
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.389478921890259,
      "learning_rate": 0.00013669558707417095,
      "loss": 1.6937,
      "step": 95100
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.944824457168579,
      "learning_rate": 0.00013657866093253328,
      "loss": 1.6981,
      "step": 95200
    },
    {
      "epoch": 1.91,
      "grad_norm": 4.083292007446289,
      "learning_rate": 0.00013646167702819714,
      "loss": 1.6873,
      "step": 95300
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.0654330253601074,
      "learning_rate": 0.00013634463554589607,
      "loss": 1.6909,
      "step": 95400
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.67370343208313,
      "learning_rate": 0.00013622753667045457,
      "loss": 1.7147,
      "step": 95500
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.7648448944091797,
      "learning_rate": 0.00013611038058678775,
      "loss": 1.6912,
      "step": 95600
    },
    {
      "epoch": 1.91,
      "grad_norm": 3.4829821586608887,
      "learning_rate": 0.00013599316747990107,
      "loss": 1.6955,
      "step": 95700
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.2738149166107178,
      "learning_rate": 0.00013587589753488998,
      "loss": 1.6927,
      "step": 95800
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.117837905883789,
      "learning_rate": 0.00013575857093693974,
      "loss": 1.6832,
      "step": 95900
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.0582516193389893,
      "learning_rate": 0.00013564118787132506,
      "loss": 1.6763,
      "step": 96000
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.3424289226531982,
      "learning_rate": 0.00013552374852340986,
      "loss": 1.682,
      "step": 96100
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.9428648948669434,
      "learning_rate": 0.0001354062530786469,
      "loss": 1.695,
      "step": 96200
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.052725076675415,
      "learning_rate": 0.00013528870172257752,
      "loss": 1.6738,
      "step": 96300
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.1385581493377686,
      "learning_rate": 0.0001351710946408313,
      "loss": 1.6828,
      "step": 96400
    },
    {
      "epoch": 1.93,
      "grad_norm": 2.984578847885132,
      "learning_rate": 0.0001350534320191259,
      "loss": 1.6803,
      "step": 96500
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.169373035430908,
      "learning_rate": 0.00013493571404326672,
      "loss": 1.6712,
      "step": 96600
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.220747232437134,
      "learning_rate": 0.00013481794089914643,
      "loss": 1.6651,
      "step": 96700
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.211940288543701,
      "learning_rate": 0.00013470011277274497,
      "loss": 1.6928,
      "step": 96800
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.1303648948669434,
      "learning_rate": 0.00013458222985012898,
      "loss": 1.6751,
      "step": 96900
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.2341361045837402,
      "learning_rate": 0.0001344642923174517,
      "loss": 1.6747,
      "step": 97000
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.128707408905029,
      "learning_rate": 0.0001343463003609526,
      "loss": 1.7091,
      "step": 97100
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.976058006286621,
      "learning_rate": 0.0001342282541669571,
      "loss": 1.7103,
      "step": 97200
    },
    {
      "epoch": 1.95,
      "grad_norm": 3.013003349304199,
      "learning_rate": 0.00013411015392187628,
      "loss": 1.6791,
      "step": 97300
    },
    {
      "epoch": 1.95,
      "grad_norm": 3.6513257026672363,
      "learning_rate": 0.00013399199981220647,
      "loss": 1.6734,
      "step": 97400
    },
    {
      "epoch": 1.95,
      "grad_norm": 3.2512803077697754,
      "learning_rate": 0.00013387379202452917,
      "loss": 1.6642,
      "step": 97500
    },
    {
      "epoch": 1.95,
      "grad_norm": 3.630016326904297,
      "learning_rate": 0.0001337555307455106,
      "loss": 1.677,
      "step": 97600
    },
    {
      "epoch": 1.95,
      "grad_norm": 3.668525457382202,
      "learning_rate": 0.00013363721616190148,
      "loss": 1.678,
      "step": 97700
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.423569440841675,
      "learning_rate": 0.00013351884846053667,
      "loss": 1.6904,
      "step": 97800
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.654881238937378,
      "learning_rate": 0.00013340042782833498,
      "loss": 1.6786,
      "step": 97900
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.284730911254883,
      "learning_rate": 0.00013328195445229868,
      "loss": 1.6759,
      "step": 98000
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.5195274353027344,
      "learning_rate": 0.00013316342851951344,
      "loss": 1.6965,
      "step": 98100
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.006006240844727,
      "learning_rate": 0.0001330448502171479,
      "loss": 1.6806,
      "step": 98200
    },
    {
      "epoch": 1.97,
      "grad_norm": 3.751802444458008,
      "learning_rate": 0.00013292621973245335,
      "loss": 1.6707,
      "step": 98300
    },
    {
      "epoch": 1.97,
      "grad_norm": 3.5033915042877197,
      "learning_rate": 0.00013280753725276352,
      "loss": 1.6795,
      "step": 98400
    },
    {
      "epoch": 1.97,
      "grad_norm": 3.418407678604126,
      "learning_rate": 0.00013268880296549425,
      "loss": 1.6709,
      "step": 98500
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.936194658279419,
      "learning_rate": 0.00013257001705814321,
      "loss": 1.6827,
      "step": 98600
    },
    {
      "epoch": 1.97,
      "grad_norm": 3.4386348724365234,
      "learning_rate": 0.00013245117971828955,
      "loss": 1.6617,
      "step": 98700
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.555455207824707,
      "learning_rate": 0.00013233229113359367,
      "loss": 1.68,
      "step": 98800
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.623957395553589,
      "learning_rate": 0.0001322133514917968,
      "loss": 1.6944,
      "step": 98900
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.0059568881988525,
      "learning_rate": 0.00013209436098072095,
      "loss": 1.6679,
      "step": 99000
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.860994577407837,
      "learning_rate": 0.00013197531978826837,
      "loss": 1.6746,
      "step": 99100
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.8008735179901123,
      "learning_rate": 0.00013185622810242128,
      "loss": 1.7014,
      "step": 99200
    },
    {
      "epoch": 1.99,
      "grad_norm": 3.1817374229431152,
      "learning_rate": 0.00013173708611124177,
      "loss": 1.7027,
      "step": 99300
    },
    {
      "epoch": 1.99,
      "grad_norm": 3.0613460540771484,
      "learning_rate": 0.0001316178940028713,
      "loss": 1.6877,
      "step": 99400
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.833043336868286,
      "learning_rate": 0.0001314986519655305,
      "loss": 1.6632,
      "step": 99500
    },
    {
      "epoch": 1.99,
      "grad_norm": 3.3530969619750977,
      "learning_rate": 0.00013137936018751874,
      "loss": 1.6794,
      "step": 99600
    },
    {
      "epoch": 1.99,
      "grad_norm": 3.9507627487182617,
      "learning_rate": 0.00013126001885721412,
      "loss": 1.6895,
      "step": 99700
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.8597934246063232,
      "learning_rate": 0.00013114062816307285,
      "loss": 1.6707,
      "step": 99800
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.622131109237671,
      "learning_rate": 0.0001310211882936291,
      "loss": 1.6488,
      "step": 99900
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.840106964111328,
      "learning_rate": 0.00013090169943749476,
      "loss": 1.6921,
      "step": 100000
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.2635374069213867,
      "learning_rate": 0.00013078216178335906,
      "loss": 1.6419,
      "step": 100100
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.815443515777588,
      "learning_rate": 0.00013066257551998822,
      "loss": 1.619,
      "step": 100200
    },
    {
      "epoch": 2.01,
      "grad_norm": 2.8227992057800293,
      "learning_rate": 0.00013054294083622532,
      "loss": 1.6314,
      "step": 100300
    },
    {
      "epoch": 2.01,
      "grad_norm": 3.537445306777954,
      "learning_rate": 0.0001304232579209898,
      "loss": 1.6474,
      "step": 100400
    },
    {
      "epoch": 2.01,
      "grad_norm": 3.715932607650757,
      "learning_rate": 0.00013030352696327742,
      "loss": 1.642,
      "step": 100500
    },
    {
      "epoch": 2.01,
      "grad_norm": 4.586463451385498,
      "learning_rate": 0.0001301837481521596,
      "loss": 1.6427,
      "step": 100600
    },
    {
      "epoch": 2.01,
      "grad_norm": 3.314213991165161,
      "learning_rate": 0.00013006392167678348,
      "loss": 1.6378,
      "step": 100700
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.1054842472076416,
      "learning_rate": 0.00012994404772637147,
      "loss": 1.6425,
      "step": 100800
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.6202454566955566,
      "learning_rate": 0.00012982412649022079,
      "loss": 1.6236,
      "step": 100900
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.224952459335327,
      "learning_rate": 0.0001297041581577035,
      "loss": 1.6637,
      "step": 101000
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.938910722732544,
      "learning_rate": 0.000129584142918266,
      "loss": 1.6458,
      "step": 101100
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.861830234527588,
      "learning_rate": 0.00012946408096142865,
      "loss": 1.6384,
      "step": 101200
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.1528565883636475,
      "learning_rate": 0.00012934397247678576,
      "loss": 1.6437,
      "step": 101300
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.9743752479553223,
      "learning_rate": 0.000129223817654005,
      "loss": 1.6726,
      "step": 101400
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.0384397506713867,
      "learning_rate": 0.00012910361668282719,
      "loss": 1.6558,
      "step": 101500
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.6602799892425537,
      "learning_rate": 0.0001289833697530661,
      "loss": 1.6419,
      "step": 101600
    },
    {
      "epoch": 2.03,
      "grad_norm": 3.178727388381958,
      "learning_rate": 0.00012886307705460809,
      "loss": 1.6433,
      "step": 101700
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.315685272216797,
      "learning_rate": 0.00012874273877741166,
      "loss": 1.6494,
      "step": 101800
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.4990320205688477,
      "learning_rate": 0.00012862235511150742,
      "loss": 1.6623,
      "step": 101900
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.1052379608154297,
      "learning_rate": 0.0001285019262469976,
      "loss": 1.6487,
      "step": 102000
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.394752025604248,
      "learning_rate": 0.0001283814523740559,
      "loss": 1.6565,
      "step": 102100
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.352616786956787,
      "learning_rate": 0.00012826093368292687,
      "loss": 1.6441,
      "step": 102200
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.1500186920166016,
      "learning_rate": 0.00012814037036392605,
      "loss": 1.6516,
      "step": 102300
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.7751448154449463,
      "learning_rate": 0.00012801976260743938,
      "loss": 1.6587,
      "step": 102400
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.6913397312164307,
      "learning_rate": 0.00012789911060392294,
      "loss": 1.6652,
      "step": 102500
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.2405471801757812,
      "learning_rate": 0.00012777841454390275,
      "loss": 1.6342,
      "step": 102600
    },
    {
      "epoch": 2.05,
      "grad_norm": 3.412980794906616,
      "learning_rate": 0.00012765767461797435,
      "loss": 1.6436,
      "step": 102700
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.1527276039123535,
      "learning_rate": 0.0001275368910168025,
      "loss": 1.6195,
      "step": 102800
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.4181885719299316,
      "learning_rate": 0.0001274160639311211,
      "loss": 1.6515,
      "step": 102900
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.0994560718536377,
      "learning_rate": 0.00012729519355173254,
      "loss": 1.6824,
      "step": 103000
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.6917574405670166,
      "learning_rate": 0.00012717428006950768,
      "loss": 1.652,
      "step": 103100
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.0645854473114014,
      "learning_rate": 0.0001270533236753854,
      "loss": 1.6636,
      "step": 103200
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.5499284267425537,
      "learning_rate": 0.00012693232456037232,
      "loss": 1.6591,
      "step": 103300
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.671185255050659,
      "learning_rate": 0.00012681128291554264,
      "loss": 1.6507,
      "step": 103400
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.284043550491333,
      "learning_rate": 0.00012669019893203759,
      "loss": 1.6435,
      "step": 103500
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.7545902729034424,
      "learning_rate": 0.00012656907280106527,
      "loss": 1.6354,
      "step": 103600
    },
    {
      "epoch": 2.07,
      "grad_norm": 3.4799964427948,
      "learning_rate": 0.00012644790471390044,
      "loss": 1.6656,
      "step": 103700
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.6707990169525146,
      "learning_rate": 0.00012632669486188402,
      "loss": 1.6489,
      "step": 103800
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.8013885021209717,
      "learning_rate": 0.00012620544343642292,
      "loss": 1.6726,
      "step": 103900
    },
    {
      "epoch": 2.08,
      "grad_norm": 4.043335914611816,
      "learning_rate": 0.00012608415062898972,
      "loss": 1.6574,
      "step": 104000
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.244119167327881,
      "learning_rate": 0.00012596281663112223,
      "loss": 1.656,
      "step": 104100
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.3696107864379883,
      "learning_rate": 0.00012584144163442347,
      "loss": 1.6483,
      "step": 104200
    },
    {
      "epoch": 2.09,
      "grad_norm": 3.3855631351470947,
      "learning_rate": 0.00012572002583056112,
      "loss": 1.6273,
      "step": 104300
    },
    {
      "epoch": 2.09,
      "grad_norm": 3.2461776733398438,
      "learning_rate": 0.00012559856941126728,
      "loss": 1.6512,
      "step": 104400
    },
    {
      "epoch": 2.09,
      "grad_norm": 9.526956558227539,
      "learning_rate": 0.00012547707256833823,
      "loss": 1.6645,
      "step": 104500
    },
    {
      "epoch": 2.09,
      "grad_norm": 3.2261722087860107,
      "learning_rate": 0.00012535553549363406,
      "loss": 1.6559,
      "step": 104600
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.9173619747161865,
      "learning_rate": 0.00012523395837907842,
      "loss": 1.6544,
      "step": 104700
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.6746249198913574,
      "learning_rate": 0.00012511234141665816,
      "loss": 1.6521,
      "step": 104800
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.7169840335845947,
      "learning_rate": 0.00012499068479842305,
      "loss": 1.6375,
      "step": 104900
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.011115550994873,
      "learning_rate": 0.0001248689887164855,
      "loss": 1.6375,
      "step": 105000
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.3296573162078857,
      "learning_rate": 0.00012474725336302024,
      "loss": 1.6328,
      "step": 105100
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.5652170181274414,
      "learning_rate": 0.00012462547893026403,
      "loss": 1.6569,
      "step": 105200
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.9181456565856934,
      "learning_rate": 0.00012450366561051526,
      "loss": 1.6529,
      "step": 105300
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.514939546585083,
      "learning_rate": 0.00012438181359613386,
      "loss": 1.6627,
      "step": 105400
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.400332450866699,
      "learning_rate": 0.00012425992307954075,
      "loss": 1.6396,
      "step": 105500
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.990779399871826,
      "learning_rate": 0.00012413799425321773,
      "loss": 1.6428,
      "step": 105600
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.8292393684387207,
      "learning_rate": 0.000124016027309707,
      "loss": 1.6617,
      "step": 105700
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.472580671310425,
      "learning_rate": 0.00012389402244161106,
      "loss": 1.6637,
      "step": 105800
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.0804879665374756,
      "learning_rate": 0.00012377197984159225,
      "loss": 1.651,
      "step": 105900
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.1372411251068115,
      "learning_rate": 0.00012364989970237248,
      "loss": 1.6646,
      "step": 106000
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.2495622634887695,
      "learning_rate": 0.00012352778221673294,
      "loss": 1.6358,
      "step": 106100
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.3163931369781494,
      "learning_rate": 0.00012340562757751384,
      "loss": 1.6438,
      "step": 106200
    },
    {
      "epoch": 2.13,
      "grad_norm": 3.580841302871704,
      "learning_rate": 0.000123283435977614,
      "loss": 1.6224,
      "step": 106300
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.9359354972839355,
      "learning_rate": 0.00012316120760999066,
      "loss": 1.6527,
      "step": 106400
    },
    {
      "epoch": 2.13,
      "grad_norm": 3.9793899059295654,
      "learning_rate": 0.00012303894266765908,
      "loss": 1.6469,
      "step": 106500
    },
    {
      "epoch": 2.13,
      "grad_norm": 3.443472146987915,
      "learning_rate": 0.00012291664134369228,
      "loss": 1.6844,
      "step": 106600
    },
    {
      "epoch": 2.13,
      "grad_norm": 3.7672719955444336,
      "learning_rate": 0.00012279430383122075,
      "loss": 1.6769,
      "step": 106700
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.6138973236083984,
      "learning_rate": 0.00012267193032343217,
      "loss": 1.658,
      "step": 106800
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.3782944679260254,
      "learning_rate": 0.00012254952101357095,
      "loss": 1.6723,
      "step": 106900
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.579547643661499,
      "learning_rate": 0.00012242707609493814,
      "loss": 1.6349,
      "step": 107000
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.254300832748413,
      "learning_rate": 0.00012230459576089095,
      "loss": 1.674,
      "step": 107100
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.683781862258911,
      "learning_rate": 0.00012218208020484255,
      "loss": 1.6433,
      "step": 107200
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.3956961631774902,
      "learning_rate": 0.00012205952962026173,
      "loss": 1.6646,
      "step": 107300
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.3684351444244385,
      "learning_rate": 0.00012193694420067261,
      "loss": 1.6626,
      "step": 107400
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.581700325012207,
      "learning_rate": 0.00012181432413965428,
      "loss": 1.6528,
      "step": 107500
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.363154888153076,
      "learning_rate": 0.00012169166963084055,
      "loss": 1.6519,
      "step": 107600
    },
    {
      "epoch": 2.15,
      "grad_norm": 4.272365570068359,
      "learning_rate": 0.00012156898086791964,
      "loss": 1.6643,
      "step": 107700
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.4681670665740967,
      "learning_rate": 0.00012144625804463383,
      "loss": 1.6311,
      "step": 107800
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.895744800567627,
      "learning_rate": 0.00012132350135477928,
      "loss": 1.6276,
      "step": 107900
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.013622760772705,
      "learning_rate": 0.00012120071099220549,
      "loss": 1.6295,
      "step": 108000
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.107049465179443,
      "learning_rate": 0.0001210778871508152,
      "loss": 1.6761,
      "step": 108100
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.565058469772339,
      "learning_rate": 0.00012095503002456405,
      "loss": 1.6535,
      "step": 108200
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.469205617904663,
      "learning_rate": 0.00012083213980746024,
      "loss": 1.6573,
      "step": 108300
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.4524178504943848,
      "learning_rate": 0.00012070921669356415,
      "loss": 1.6669,
      "step": 108400
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.9053452014923096,
      "learning_rate": 0.00012058626087698814,
      "loss": 1.6529,
      "step": 108500
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.470594882965088,
      "learning_rate": 0.00012046327255189627,
      "loss": 1.6568,
      "step": 108600
    },
    {
      "epoch": 2.17,
      "grad_norm": 4.307811260223389,
      "learning_rate": 0.00012034025191250387,
      "loss": 1.6302,
      "step": 108700
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.7417914867401123,
      "learning_rate": 0.00012021719915307736,
      "loss": 1.6442,
      "step": 108800
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.832219362258911,
      "learning_rate": 0.0001200941144679338,
      "loss": 1.6384,
      "step": 108900
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.604867696762085,
      "learning_rate": 0.00011997099805144069,
      "loss": 1.6624,
      "step": 109000
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.2430601119995117,
      "learning_rate": 0.00011984785009801571,
      "loss": 1.6574,
      "step": 109100
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.237039089202881,
      "learning_rate": 0.00011972467080212631,
      "loss": 1.6457,
      "step": 109200
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.1602275371551514,
      "learning_rate": 0.00011960146035828931,
      "loss": 1.6466,
      "step": 109300
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.5407650470733643,
      "learning_rate": 0.0001194782189610709,
      "loss": 1.6353,
      "step": 109400
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.253413438796997,
      "learning_rate": 0.00011935494680508606,
      "loss": 1.6481,
      "step": 109500
    },
    {
      "epoch": 2.19,
      "grad_norm": 3.1475329399108887,
      "learning_rate": 0.00011923164408499829,
      "loss": 1.6531,
      "step": 109600
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.8101797103881836,
      "learning_rate": 0.00011910831099551948,
      "loss": 1.6352,
      "step": 109700
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.834608554840088,
      "learning_rate": 0.00011898494773140942,
      "loss": 1.6556,
      "step": 109800
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.6228764057159424,
      "learning_rate": 0.00011886155448747549,
      "loss": 1.6397,
      "step": 109900
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.0414679050445557,
      "learning_rate": 0.00011873813145857249,
      "loss": 1.6558,
      "step": 110000
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.2235403060913086,
      "learning_rate": 0.00011861467883960222,
      "loss": 1.6421,
      "step": 110100
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.3141627311706543,
      "learning_rate": 0.00011849119682551322,
      "loss": 1.6537,
      "step": 110200
    },
    {
      "epoch": 2.21,
      "grad_norm": 3.5591118335723877,
      "learning_rate": 0.0001183676856113005,
      "loss": 1.6487,
      "step": 110300
    },
    {
      "epoch": 2.21,
      "grad_norm": 3.5809881687164307,
      "learning_rate": 0.00011824414539200504,
      "loss": 1.6544,
      "step": 110400
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.909960985183716,
      "learning_rate": 0.00011812057636271374,
      "loss": 1.6538,
      "step": 110500
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.9607720375061035,
      "learning_rate": 0.000117996978718559,
      "loss": 1.6586,
      "step": 110600
    },
    {
      "epoch": 2.21,
      "grad_norm": 3.659313440322876,
      "learning_rate": 0.00011787335265471831,
      "loss": 1.648,
      "step": 110700
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.1230878829956055,
      "learning_rate": 0.00011774969836641416,
      "loss": 1.6421,
      "step": 110800
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.0423691272735596,
      "learning_rate": 0.0001176260160489135,
      "loss": 1.6472,
      "step": 110900
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.272834539413452,
      "learning_rate": 0.00011750230589752762,
      "loss": 1.6451,
      "step": 111000
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.703946352005005,
      "learning_rate": 0.0001173785681076117,
      "loss": 1.6462,
      "step": 111100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.551379919052124,
      "learning_rate": 0.00011725480287456467,
      "loss": 1.6615,
      "step": 111200
    },
    {
      "epoch": 2.23,
      "grad_norm": 3.3152761459350586,
      "learning_rate": 0.00011713101039382866,
      "loss": 1.6637,
      "step": 111300
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.736870288848877,
      "learning_rate": 0.00011700719086088891,
      "loss": 1.6428,
      "step": 111400
    },
    {
      "epoch": 2.23,
      "grad_norm": 3.2623534202575684,
      "learning_rate": 0.00011688334447127338,
      "loss": 1.6555,
      "step": 111500
    },
    {
      "epoch": 2.23,
      "grad_norm": 3.0160653591156006,
      "learning_rate": 0.00011675947142055241,
      "loss": 1.6499,
      "step": 111600
    },
    {
      "epoch": 2.23,
      "grad_norm": 4.982773780822754,
      "learning_rate": 0.00011663557190433849,
      "loss": 1.6607,
      "step": 111700
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.313190460205078,
      "learning_rate": 0.0001165116461182858,
      "loss": 1.6239,
      "step": 111800
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.23287034034729,
      "learning_rate": 0.00011638769425809015,
      "loss": 1.6502,
      "step": 111900
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.43117094039917,
      "learning_rate": 0.00011626371651948838,
      "loss": 1.6315,
      "step": 112000
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.238929033279419,
      "learning_rate": 0.00011613971309825828,
      "loss": 1.6784,
      "step": 112100
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.6205060482025146,
      "learning_rate": 0.0001160156841902182,
      "loss": 1.6238,
      "step": 112200
    },
    {
      "epoch": 2.25,
      "grad_norm": 3.549851417541504,
      "learning_rate": 0.00011589162999122669,
      "loss": 1.6465,
      "step": 112300
    },
    {
      "epoch": 2.25,
      "grad_norm": 3.672940731048584,
      "learning_rate": 0.00011576755069718228,
      "loss": 1.6289,
      "step": 112400
    },
    {
      "epoch": 2.25,
      "grad_norm": 3.4631404876708984,
      "learning_rate": 0.0001156434465040231,
      "loss": 1.6407,
      "step": 112500
    },
    {
      "epoch": 2.25,
      "grad_norm": 3.377264976501465,
      "learning_rate": 0.00011551931760772661,
      "loss": 1.6166,
      "step": 112600
    },
    {
      "epoch": 2.25,
      "grad_norm": 3.6559805870056152,
      "learning_rate": 0.00011539516420430932,
      "loss": 1.665,
      "step": 112700
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.249216079711914,
      "learning_rate": 0.00011527098648982632,
      "loss": 1.6683,
      "step": 112800
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.2816755771636963,
      "learning_rate": 0.00011514678466037125,
      "loss": 1.6655,
      "step": 112900
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.3579797744750977,
      "learning_rate": 0.00011502255891207572,
      "loss": 1.6523,
      "step": 113000
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.089735269546509,
      "learning_rate": 0.00011489830944110913,
      "loss": 1.6399,
      "step": 113100
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.939317464828491,
      "learning_rate": 0.00011477403644367839,
      "loss": 1.6574,
      "step": 113200
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.0222930908203125,
      "learning_rate": 0.00011464974011602747,
      "loss": 1.6334,
      "step": 113300
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.1797468662261963,
      "learning_rate": 0.00011452542065443727,
      "loss": 1.64,
      "step": 113400
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.3774845600128174,
      "learning_rate": 0.00011440107825522521,
      "loss": 1.6365,
      "step": 113500
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.0157570838928223,
      "learning_rate": 0.00011427671311474488,
      "loss": 1.628,
      "step": 113600
    },
    {
      "epoch": 2.27,
      "grad_norm": 3.0660693645477295,
      "learning_rate": 0.00011415232542938586,
      "loss": 1.641,
      "step": 113700
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.8089818954467773,
      "learning_rate": 0.00011402791539557321,
      "loss": 1.6489,
      "step": 113800
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.174678325653076,
      "learning_rate": 0.00011390348320976738,
      "loss": 1.6404,
      "step": 113900
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.3670740127563477,
      "learning_rate": 0.0001137790290684638,
      "loss": 1.6537,
      "step": 114000
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.1318061351776123,
      "learning_rate": 0.00011365455316819256,
      "loss": 1.6354,
      "step": 114100
    },
    {
      "epoch": 2.28,
      "grad_norm": 3.735013484954834,
      "learning_rate": 0.00011353005570551802,
      "loss": 1.653,
      "step": 114200
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.525153398513794,
      "learning_rate": 0.00011340553687703876,
      "loss": 1.6329,
      "step": 114300
    },
    {
      "epoch": 2.29,
      "grad_norm": 4.531307697296143,
      "learning_rate": 0.00011328099687938695,
      "loss": 1.635,
      "step": 114400
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.566504716873169,
      "learning_rate": 0.00011315643590922827,
      "loss": 1.6458,
      "step": 114500
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.474243640899658,
      "learning_rate": 0.00011303185416326148,
      "loss": 1.602,
      "step": 114600
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.955482006072998,
      "learning_rate": 0.00011290725183821815,
      "loss": 1.6335,
      "step": 114700
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.691647529602051,
      "learning_rate": 0.00011278262913086237,
      "loss": 1.6434,
      "step": 114800
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.2394979000091553,
      "learning_rate": 0.00011265798623799042,
      "loss": 1.6448,
      "step": 114900
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.4944028854370117,
      "learning_rate": 0.00011253332335643043,
      "loss": 1.6336,
      "step": 115000
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.1256985664367676,
      "learning_rate": 0.00011240864068304213,
      "loss": 1.652,
      "step": 115100
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.007866859436035,
      "learning_rate": 0.00011228393841471643,
      "loss": 1.6551,
      "step": 115200
    },
    {
      "epoch": 2.31,
      "grad_norm": 3.58233642578125,
      "learning_rate": 0.00011215921674837526,
      "loss": 1.6398,
      "step": 115300
    },
    {
      "epoch": 2.31,
      "grad_norm": 3.465942859649658,
      "learning_rate": 0.00011203447588097116,
      "loss": 1.6704,
      "step": 115400
    },
    {
      "epoch": 2.31,
      "grad_norm": 3.3493897914886475,
      "learning_rate": 0.00011190971600948699,
      "loss": 1.6433,
      "step": 115500
    },
    {
      "epoch": 2.31,
      "grad_norm": 4.109338760375977,
      "learning_rate": 0.0001117849373309356,
      "loss": 1.6287,
      "step": 115600
    },
    {
      "epoch": 2.31,
      "grad_norm": 3.4016120433807373,
      "learning_rate": 0.00011166014004235956,
      "loss": 1.6514,
      "step": 115700
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.078575372695923,
      "learning_rate": 0.00011153532434083083,
      "loss": 1.6398,
      "step": 115800
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.3205127716064453,
      "learning_rate": 0.00011141049042345044,
      "loss": 1.6659,
      "step": 115900
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.2581028938293457,
      "learning_rate": 0.00011128563848734816,
      "loss": 1.6242,
      "step": 116000
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.189710855484009,
      "learning_rate": 0.00011116076872968231,
      "loss": 1.6606,
      "step": 116100
    },
    {
      "epoch": 2.32,
      "grad_norm": 4.015499114990234,
      "learning_rate": 0.00011103588134763918,
      "loss": 1.6572,
      "step": 116200
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.3557796478271484,
      "learning_rate": 0.00011091097653843305,
      "loss": 1.6367,
      "step": 116300
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.7073142528533936,
      "learning_rate": 0.00011078605449930568,
      "loss": 1.6346,
      "step": 116400
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.5443477630615234,
      "learning_rate": 0.000110661115427526,
      "loss": 1.6304,
      "step": 116500
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.2686569690704346,
      "learning_rate": 0.00011053615952038984,
      "loss": 1.6463,
      "step": 116600
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.4578797817230225,
      "learning_rate": 0.00011041118697521969,
      "loss": 1.6611,
      "step": 116700
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.885038137435913,
      "learning_rate": 0.00011028619798936417,
      "loss": 1.6411,
      "step": 116800
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.052489995956421,
      "learning_rate": 0.00011016119276019801,
      "loss": 1.6449,
      "step": 116900
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.099499464035034,
      "learning_rate": 0.00011003617148512149,
      "loss": 1.6331,
      "step": 117000
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.950115203857422,
      "learning_rate": 0.00010991113436156033,
      "loss": 1.6303,
      "step": 117100
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.8119659423828125,
      "learning_rate": 0.00010978608158696517,
      "loss": 1.6708,
      "step": 117200
    },
    {
      "epoch": 2.35,
      "grad_norm": 3.3439159393310547,
      "learning_rate": 0.0001096610133588114,
      "loss": 1.6155,
      "step": 117300
    },
    {
      "epoch": 2.35,
      "grad_norm": 3.8693761825561523,
      "learning_rate": 0.00010953592987459886,
      "loss": 1.6735,
      "step": 117400
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.7074100971221924,
      "learning_rate": 0.00010941083133185146,
      "loss": 1.6307,
      "step": 117500
    },
    {
      "epoch": 2.35,
      "grad_norm": 3.7582147121429443,
      "learning_rate": 0.0001092857179281168,
      "loss": 1.676,
      "step": 117600
    },
    {
      "epoch": 2.35,
      "grad_norm": 3.126359462738037,
      "learning_rate": 0.00010916058986096607,
      "loss": 1.6331,
      "step": 117700
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.356117010116577,
      "learning_rate": 0.00010903544732799355,
      "loss": 1.6586,
      "step": 117800
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.760004758834839,
      "learning_rate": 0.00010891029052681643,
      "loss": 1.652,
      "step": 117900
    },
    {
      "epoch": 2.36,
      "grad_norm": 11.088261604309082,
      "learning_rate": 0.00010878511965507434,
      "loss": 1.6614,
      "step": 118000
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.435418128967285,
      "learning_rate": 0.00010865993491042916,
      "loss": 1.6517,
      "step": 118100
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.1099801063537598,
      "learning_rate": 0.00010853473649056472,
      "loss": 1.6633,
      "step": 118200
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.07666015625,
      "learning_rate": 0.00010840952459318637,
      "loss": 1.6354,
      "step": 118300
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.9964611530303955,
      "learning_rate": 0.00010828429941602084,
      "loss": 1.643,
      "step": 118400
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.7626869678497314,
      "learning_rate": 0.00010815906115681578,
      "loss": 1.6638,
      "step": 118500
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.458265542984009,
      "learning_rate": 0.00010803381001333943,
      "loss": 1.6187,
      "step": 118600
    },
    {
      "epoch": 2.37,
      "grad_norm": 4.165770530700684,
      "learning_rate": 0.00010790854618338049,
      "loss": 1.6498,
      "step": 118700
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.579939842224121,
      "learning_rate": 0.00010778326986474765,
      "loss": 1.6666,
      "step": 118800
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.636035442352295,
      "learning_rate": 0.00010765798125526932,
      "loss": 1.6503,
      "step": 118900
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.1175270080566406,
      "learning_rate": 0.00010753268055279329,
      "loss": 1.6457,
      "step": 119000
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.986255168914795,
      "learning_rate": 0.00010740736795518649,
      "loss": 1.6867,
      "step": 119100
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.0586421489715576,
      "learning_rate": 0.00010728204366033459,
      "loss": 1.6426,
      "step": 119200
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.5998287200927734,
      "learning_rate": 0.00010715670786614178,
      "loss": 1.6415,
      "step": 119300
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.6249094009399414,
      "learning_rate": 0.00010703136077053039,
      "loss": 1.6127,
      "step": 119400
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.5326809883117676,
      "learning_rate": 0.00010690600257144061,
      "loss": 1.6272,
      "step": 119500
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.483863115310669,
      "learning_rate": 0.00010678063346683009,
      "loss": 1.6302,
      "step": 119600
    },
    {
      "epoch": 2.39,
      "grad_norm": 3.189805746078491,
      "learning_rate": 0.00010665525365467382,
      "loss": 1.6236,
      "step": 119700
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.5839948654174805,
      "learning_rate": 0.00010652986333296357,
      "loss": 1.6347,
      "step": 119800
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.452305555343628,
      "learning_rate": 0.00010640446269970785,
      "loss": 1.6319,
      "step": 119900
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.706264019012451,
      "learning_rate": 0.00010627905195293135,
      "loss": 1.6448,
      "step": 120000
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.0911200046539307,
      "learning_rate": 0.00010615363129067472,
      "loss": 1.6267,
      "step": 120100
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.8625612258911133,
      "learning_rate": 0.00010602820091099437,
      "loss": 1.6441,
      "step": 120200
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.997129201889038,
      "learning_rate": 0.00010590276101196192,
      "loss": 1.6468,
      "step": 120300
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.0737977027893066,
      "learning_rate": 0.00010577731179166414,
      "loss": 1.6275,
      "step": 120400
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.2030093669891357,
      "learning_rate": 0.00010565185344820247,
      "loss": 1.6391,
      "step": 120500
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.181879997253418,
      "learning_rate": 0.00010552638617969272,
      "loss": 1.644,
      "step": 120600
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.770538091659546,
      "learning_rate": 0.00010540091018426487,
      "loss": 1.6571,
      "step": 120700
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.2646021842956543,
      "learning_rate": 0.00010527542566006266,
      "loss": 1.6595,
      "step": 120800
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.4209177494049072,
      "learning_rate": 0.00010514993280524324,
      "loss": 1.6387,
      "step": 120900
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.3666162490844727,
      "learning_rate": 0.00010502443181797697,
      "loss": 1.6286,
      "step": 121000
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.8334226608276367,
      "learning_rate": 0.00010489892289644703,
      "loss": 1.6492,
      "step": 121100
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.2842209339141846,
      "learning_rate": 0.00010477340623884917,
      "loss": 1.6338,
      "step": 121200
    },
    {
      "epoch": 2.43,
      "grad_norm": 3.3720927238464355,
      "learning_rate": 0.0001046478820433913,
      "loss": 1.6271,
      "step": 121300
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.929643154144287,
      "learning_rate": 0.00010452235050829326,
      "loss": 1.6411,
      "step": 121400
    },
    {
      "epoch": 2.43,
      "grad_norm": 3.1951138973236084,
      "learning_rate": 0.0001043968118317865,
      "loss": 1.6557,
      "step": 121500
    },
    {
      "epoch": 2.43,
      "grad_norm": 3.2898175716400146,
      "learning_rate": 0.00010427126621211372,
      "loss": 1.6463,
      "step": 121600
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.6293575763702393,
      "learning_rate": 0.00010414571384752853,
      "loss": 1.6447,
      "step": 121700
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.6342508792877197,
      "learning_rate": 0.00010402015493629533,
      "loss": 1.6499,
      "step": 121800
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.1673219203948975,
      "learning_rate": 0.00010389458967668876,
      "loss": 1.6466,
      "step": 121900
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.810591697692871,
      "learning_rate": 0.00010376901826699348,
      "loss": 1.6474,
      "step": 122000
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.527615547180176,
      "learning_rate": 0.00010364344090550389,
      "loss": 1.6363,
      "step": 122100
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.6368465423583984,
      "learning_rate": 0.00010351785779052378,
      "loss": 1.6454,
      "step": 122200
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.305990219116211,
      "learning_rate": 0.00010339226912036608,
      "loss": 1.6599,
      "step": 122300
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.94757080078125,
      "learning_rate": 0.00010326667509335239,
      "loss": 1.6193,
      "step": 122400
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.057633638381958,
      "learning_rate": 0.00010314107590781284,
      "loss": 1.6417,
      "step": 122500
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.8345601558685303,
      "learning_rate": 0.00010301547176208568,
      "loss": 1.6337,
      "step": 122600
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.6272106170654297,
      "learning_rate": 0.000102889862854517,
      "loss": 1.6227,
      "step": 122700
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.1879522800445557,
      "learning_rate": 0.00010276424938346044,
      "loss": 1.624,
      "step": 122800
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.1568589210510254,
      "learning_rate": 0.0001026386315472768,
      "loss": 1.6528,
      "step": 122900
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.6268224716186523,
      "learning_rate": 0.00010251300954433376,
      "loss": 1.6513,
      "step": 123000
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.232250690460205,
      "learning_rate": 0.00010238738357300564,
      "loss": 1.653,
      "step": 123100
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.0408785343170166,
      "learning_rate": 0.00010226175383167298,
      "loss": 1.6299,
      "step": 123200
    },
    {
      "epoch": 2.47,
      "grad_norm": 3.1337034702301025,
      "learning_rate": 0.00010213612051872231,
      "loss": 1.6291,
      "step": 123300
    },
    {
      "epoch": 2.47,
      "grad_norm": 3.2026026248931885,
      "learning_rate": 0.00010201048383254577,
      "loss": 1.6169,
      "step": 123400
    },
    {
      "epoch": 2.47,
      "grad_norm": 3.092622756958008,
      "learning_rate": 0.00010188484397154084,
      "loss": 1.6525,
      "step": 123500
    },
    {
      "epoch": 2.47,
      "grad_norm": 3.044241428375244,
      "learning_rate": 0.00010175920113410998,
      "loss": 1.6344,
      "step": 123600
    },
    {
      "epoch": 2.47,
      "grad_norm": 3.6454482078552246,
      "learning_rate": 0.00010163355551866043,
      "loss": 1.6329,
      "step": 123700
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.789792537689209,
      "learning_rate": 0.00010150790732360372,
      "loss": 1.6498,
      "step": 123800
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.473637580871582,
      "learning_rate": 0.00010138225674735553,
      "loss": 1.6424,
      "step": 123900
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.006294012069702,
      "learning_rate": 0.00010125660398833528,
      "loss": 1.6299,
      "step": 124000
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.919670343399048,
      "learning_rate": 0.0001011309492449658,
      "loss": 1.6174,
      "step": 124100
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.7170047760009766,
      "learning_rate": 0.00010100529271567307,
      "loss": 1.641,
      "step": 124200
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.812053918838501,
      "learning_rate": 0.00010087963459888597,
      "loss": 1.6507,
      "step": 124300
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.9121756553649902,
      "learning_rate": 0.00010075397509303572,
      "loss": 1.6071,
      "step": 124400
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.271000623703003,
      "learning_rate": 0.00010062831439655591,
      "loss": 1.6366,
      "step": 124500
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.313460111618042,
      "learning_rate": 0.0001005026527078819,
      "loss": 1.6224,
      "step": 124600
    },
    {
      "epoch": 2.49,
      "grad_norm": 3.22684907913208,
      "learning_rate": 0.00010037699022545064,
      "loss": 1.6373,
      "step": 124700
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.890380859375,
      "learning_rate": 0.00010025132714770041,
      "loss": 1.6259,
      "step": 124800
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.1090352535247803,
      "learning_rate": 0.00010012566367307026,
      "loss": 1.6602,
      "step": 124900
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.7832515239715576,
      "learning_rate": 0.0001,
      "loss": 1.6257,
      "step": 125000
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.4852044582366943,
      "learning_rate": 9.987433632692979e-05,
      "loss": 1.6046,
      "step": 125100
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.003514528274536,
      "learning_rate": 9.974867285229963e-05,
      "loss": 1.6564,
      "step": 125200
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.858233690261841,
      "learning_rate": 9.962300977454938e-05,
      "loss": 1.6248,
      "step": 125300
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.4255764484405518,
      "learning_rate": 9.94973472921181e-05,
      "loss": 1.6262,
      "step": 125400
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.598281145095825,
      "learning_rate": 9.937168560344412e-05,
      "loss": 1.6238,
      "step": 125500
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.222630739212036,
      "learning_rate": 9.924602490696431e-05,
      "loss": 1.6232,
      "step": 125600
    },
    {
      "epoch": 2.51,
      "grad_norm": 3.096673011779785,
      "learning_rate": 9.912036540111406e-05,
      "loss": 1.6336,
      "step": 125700
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.7182140350341797,
      "learning_rate": 9.899470728432695e-05,
      "loss": 1.6101,
      "step": 125800
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.899848461151123,
      "learning_rate": 9.886905075503423e-05,
      "loss": 1.6202,
      "step": 125900
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.0675642490386963,
      "learning_rate": 9.874339601166473e-05,
      "loss": 1.6353,
      "step": 126000
    },
    {
      "epoch": 2.52,
      "grad_norm": 4.134138107299805,
      "learning_rate": 9.861774325264448e-05,
      "loss": 1.6392,
      "step": 126100
    },
    {
      "epoch": 2.52,
      "grad_norm": 6.231259822845459,
      "learning_rate": 9.849209267639629e-05,
      "loss": 1.6319,
      "step": 126200
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.175182819366455,
      "learning_rate": 9.836644448133959e-05,
      "loss": 1.6173,
      "step": 126300
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.019237518310547,
      "learning_rate": 9.824079886589003e-05,
      "loss": 1.6093,
      "step": 126400
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.4473042488098145,
      "learning_rate": 9.81151560284592e-05,
      "loss": 1.6292,
      "step": 126500
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.6650514602661133,
      "learning_rate": 9.798951616745428e-05,
      "loss": 1.6311,
      "step": 126600
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.1142101287841797,
      "learning_rate": 9.78638794812777e-05,
      "loss": 1.6269,
      "step": 126700
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.95446515083313,
      "learning_rate": 9.773824616832705e-05,
      "loss": 1.6343,
      "step": 126800
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.5840446949005127,
      "learning_rate": 9.761261642699437e-05,
      "loss": 1.6446,
      "step": 126900
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.0389084815979004,
      "learning_rate": 9.748699045566626e-05,
      "loss": 1.6376,
      "step": 127000
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.352458953857422,
      "learning_rate": 9.736136845272324e-05,
      "loss": 1.6391,
      "step": 127100
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.7468459606170654,
      "learning_rate": 9.723575061653957e-05,
      "loss": 1.6337,
      "step": 127200
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.3915884494781494,
      "learning_rate": 9.711013714548301e-05,
      "loss": 1.6368,
      "step": 127300
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.080355644226074,
      "learning_rate": 9.698452823791431e-05,
      "loss": 1.6244,
      "step": 127400
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.8671817779541016,
      "learning_rate": 9.685892409218717e-05,
      "loss": 1.5951,
      "step": 127500
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.69960618019104,
      "learning_rate": 9.673332490664764e-05,
      "loss": 1.6349,
      "step": 127600
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.630016326904297,
      "learning_rate": 9.660773087963393e-05,
      "loss": 1.6171,
      "step": 127700
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.8528876304626465,
      "learning_rate": 9.648214220947624e-05,
      "loss": 1.6261,
      "step": 127800
    },
    {
      "epoch": 2.56,
      "grad_norm": 5.239230632781982,
      "learning_rate": 9.63565590944961e-05,
      "loss": 1.6248,
      "step": 127900
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.34682559967041,
      "learning_rate": 9.623098173300654e-05,
      "loss": 1.6425,
      "step": 128000
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.2725679874420166,
      "learning_rate": 9.610541032331129e-05,
      "loss": 1.6111,
      "step": 128100
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.0273489952087402,
      "learning_rate": 9.597984506370467e-05,
      "loss": 1.6571,
      "step": 128200
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.969517230987549,
      "learning_rate": 9.585428615247149e-05,
      "loss": 1.6297,
      "step": 128300
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.7728540897369385,
      "learning_rate": 9.572873378788633e-05,
      "loss": 1.6172,
      "step": 128400
    },
    {
      "epoch": 2.57,
      "grad_norm": 3.2053279876708984,
      "learning_rate": 9.560318816821353e-05,
      "loss": 1.6316,
      "step": 128500
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.9617221355438232,
      "learning_rate": 9.547764949170675e-05,
      "loss": 1.6279,
      "step": 128600
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.9612319469451904,
      "learning_rate": 9.53521179566087e-05,
      "loss": 1.6409,
      "step": 128700
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.9589896202087402,
      "learning_rate": 9.522659376115086e-05,
      "loss": 1.6268,
      "step": 128800
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.6704976558685303,
      "learning_rate": 9.510107710355299e-05,
      "loss": 1.6234,
      "step": 128900
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.77402400970459,
      "learning_rate": 9.497556818202306e-05,
      "loss": 1.6138,
      "step": 129000
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.48547101020813,
      "learning_rate": 9.485006719475681e-05,
      "loss": 1.6291,
      "step": 129100
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.746082067489624,
      "learning_rate": 9.472457433993735e-05,
      "loss": 1.6305,
      "step": 129200
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.888617753982544,
      "learning_rate": 9.459908981573514e-05,
      "loss": 1.6424,
      "step": 129300
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.545963764190674,
      "learning_rate": 9.447361382030731e-05,
      "loss": 1.6084,
      "step": 129400
    },
    {
      "epoch": 2.59,
      "grad_norm": 4.045261383056641,
      "learning_rate": 9.434814655179755e-05,
      "loss": 1.6247,
      "step": 129500
    },
    {
      "epoch": 2.59,
      "grad_norm": 3.396822690963745,
      "learning_rate": 9.422268820833588e-05,
      "loss": 1.629,
      "step": 129600
    },
    {
      "epoch": 2.59,
      "grad_norm": 3.594179391860962,
      "learning_rate": 9.409723898803809e-05,
      "loss": 1.6424,
      "step": 129700
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.982264280319214,
      "learning_rate": 9.397179908900566e-05,
      "loss": 1.6319,
      "step": 129800
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.313197612762451,
      "learning_rate": 9.38463687093253e-05,
      "loss": 1.618,
      "step": 129900
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.96336030960083,
      "learning_rate": 9.372094804706867e-05,
      "loss": 1.6267,
      "step": 130000
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.8188202381134033,
      "learning_rate": 9.359553730029216e-05,
      "loss": 1.6264,
      "step": 130100
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.4321796894073486,
      "learning_rate": 9.347013666703641e-05,
      "loss": 1.6104,
      "step": 130200
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.5883266925811768,
      "learning_rate": 9.334474634532622e-05,
      "loss": 1.6275,
      "step": 130300
    },
    {
      "epoch": 2.61,
      "grad_norm": 3.2989091873168945,
      "learning_rate": 9.321936653316995e-05,
      "loss": 1.6308,
      "step": 130400
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.9768998622894287,
      "learning_rate": 9.309399742855942e-05,
      "loss": 1.6343,
      "step": 130500
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.8685998916625977,
      "learning_rate": 9.296863922946963e-05,
      "loss": 1.6104,
      "step": 130600
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.604508399963379,
      "learning_rate": 9.284329213385823e-05,
      "loss": 1.5931,
      "step": 130700
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.648000955581665,
      "learning_rate": 9.271795633966543e-05,
      "loss": 1.6251,
      "step": 130800
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.2368252277374268,
      "learning_rate": 9.259263204481355e-05,
      "loss": 1.6287,
      "step": 130900
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.773043632507324,
      "learning_rate": 9.246731944720675e-05,
      "loss": 1.6362,
      "step": 131000
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.912977695465088,
      "learning_rate": 9.23420187447307e-05,
      "loss": 1.6254,
      "step": 131100
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.7297098636627197,
      "learning_rate": 9.221673013525235e-05,
      "loss": 1.6273,
      "step": 131200
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.732844591140747,
      "learning_rate": 9.209145381661952e-05,
      "loss": 1.6274,
      "step": 131300
    },
    {
      "epoch": 2.63,
      "grad_norm": 3.009121894836426,
      "learning_rate": 9.196618998666059e-05,
      "loss": 1.6286,
      "step": 131400
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.8276824951171875,
      "learning_rate": 9.184093884318425e-05,
      "loss": 1.6421,
      "step": 131500
    },
    {
      "epoch": 2.63,
      "grad_norm": 3.083608627319336,
      "learning_rate": 9.171570058397917e-05,
      "loss": 1.6475,
      "step": 131600
    },
    {
      "epoch": 2.63,
      "grad_norm": 6.706410884857178,
      "learning_rate": 9.159047540681363e-05,
      "loss": 1.6138,
      "step": 131700
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.75919246673584,
      "learning_rate": 9.146526350943532e-05,
      "loss": 1.6271,
      "step": 131800
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.8838136196136475,
      "learning_rate": 9.134006508957089e-05,
      "loss": 1.6265,
      "step": 131900
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.832815647125244,
      "learning_rate": 9.121488034492569e-05,
      "loss": 1.6178,
      "step": 132000
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.0387051105499268,
      "learning_rate": 9.10897094731836e-05,
      "loss": 1.625,
      "step": 132100
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.339230537414551,
      "learning_rate": 9.096455267200643e-05,
      "loss": 1.6001,
      "step": 132200
    },
    {
      "epoch": 2.65,
      "grad_norm": 3.4943463802337646,
      "learning_rate": 9.083941013903396e-05,
      "loss": 1.6042,
      "step": 132300
    },
    {
      "epoch": 2.65,
      "grad_norm": 3.050887107849121,
      "learning_rate": 9.071428207188324e-05,
      "loss": 1.6253,
      "step": 132400
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.8004069328308105,
      "learning_rate": 9.058916866814858e-05,
      "loss": 1.5869,
      "step": 132500
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.606937885284424,
      "learning_rate": 9.046407012540115e-05,
      "loss": 1.6501,
      "step": 132600
    },
    {
      "epoch": 2.65,
      "grad_norm": 3.8790194988250732,
      "learning_rate": 9.033898664118858e-05,
      "loss": 1.6221,
      "step": 132700
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.8773770332336426,
      "learning_rate": 9.021391841303484e-05,
      "loss": 1.5996,
      "step": 132800
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.3151192665100098,
      "learning_rate": 9.00888656384397e-05,
      "loss": 1.6399,
      "step": 132900
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.454373836517334,
      "learning_rate": 8.99638285148785e-05,
      "loss": 1.6197,
      "step": 133000
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.603672981262207,
      "learning_rate": 8.983880723980202e-05,
      "loss": 1.637,
      "step": 133100
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.7111458778381348,
      "learning_rate": 8.971380201063587e-05,
      "loss": 1.6036,
      "step": 133200
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.2350916862487793,
      "learning_rate": 8.958881302478035e-05,
      "loss": 1.6272,
      "step": 133300
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.6103193759918213,
      "learning_rate": 8.946384047961018e-05,
      "loss": 1.6326,
      "step": 133400
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.1312735080718994,
      "learning_rate": 8.933888457247402e-05,
      "loss": 1.6084,
      "step": 133500
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.2659194469451904,
      "learning_rate": 8.921394550069434e-05,
      "loss": 1.6377,
      "step": 133600
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.545882225036621,
      "learning_rate": 8.908902346156693e-05,
      "loss": 1.6285,
      "step": 133700
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.914398670196533,
      "learning_rate": 8.896411865236084e-05,
      "loss": 1.6227,
      "step": 133800
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.577209711074829,
      "learning_rate": 8.883923127031775e-05,
      "loss": 1.6125,
      "step": 133900
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.093904733657837,
      "learning_rate": 8.871436151265184e-05,
      "loss": 1.6256,
      "step": 134000
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.0115559101104736,
      "learning_rate": 8.858950957654959e-05,
      "loss": 1.6191,
      "step": 134100
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.754624843597412,
      "learning_rate": 8.846467565916917e-05,
      "loss": 1.6228,
      "step": 134200
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.837341070175171,
      "learning_rate": 8.833985995764045e-05,
      "loss": 1.6127,
      "step": 134300
    },
    {
      "epoch": 2.69,
      "grad_norm": 3.1530206203460693,
      "learning_rate": 8.821506266906444e-05,
      "loss": 1.6369,
      "step": 134400
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.790886163711548,
      "learning_rate": 8.809028399051302e-05,
      "loss": 1.6238,
      "step": 134500
    },
    {
      "epoch": 2.69,
      "grad_norm": 3.0596888065338135,
      "learning_rate": 8.796552411902886e-05,
      "loss": 1.6083,
      "step": 134600
    },
    {
      "epoch": 2.69,
      "grad_norm": 3.049499750137329,
      "learning_rate": 8.784078325162479e-05,
      "loss": 1.6187,
      "step": 134700
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.0734517574310303,
      "learning_rate": 8.77160615852836e-05,
      "loss": 1.61,
      "step": 134800
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.0879228115081787,
      "learning_rate": 8.759135931695792e-05,
      "loss": 1.6304,
      "step": 134900
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.309840679168701,
      "learning_rate": 8.746667664356956e-05,
      "loss": 1.6267,
      "step": 135000
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.069556713104248,
      "learning_rate": 8.73420137620096e-05,
      "loss": 1.6177,
      "step": 135100
    },
    {
      "epoch": 2.7,
      "grad_norm": 4.098277568817139,
      "learning_rate": 8.721737086913766e-05,
      "loss": 1.6161,
      "step": 135200
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.623652696609497,
      "learning_rate": 8.709274816178186e-05,
      "loss": 1.6195,
      "step": 135300
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.498389959335327,
      "learning_rate": 8.696814583673856e-05,
      "loss": 1.6192,
      "step": 135400
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.638740062713623,
      "learning_rate": 8.684356409077176e-05,
      "loss": 1.6284,
      "step": 135500
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.000715732574463,
      "learning_rate": 8.671900312061307e-05,
      "loss": 1.6081,
      "step": 135600
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.789975166320801,
      "learning_rate": 8.659446312296126e-05,
      "loss": 1.6188,
      "step": 135700
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.708672285079956,
      "learning_rate": 8.646994429448199e-05,
      "loss": 1.6364,
      "step": 135800
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.8703715801239014,
      "learning_rate": 8.634544683180746e-05,
      "loss": 1.6053,
      "step": 135900
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.3134255409240723,
      "learning_rate": 8.62209709315362e-05,
      "loss": 1.6214,
      "step": 136000
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.5962235927581787,
      "learning_rate": 8.609651679023263e-05,
      "loss": 1.6174,
      "step": 136100
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.9369311332702637,
      "learning_rate": 8.597208460442681e-05,
      "loss": 1.623,
      "step": 136200
    },
    {
      "epoch": 2.73,
      "grad_norm": 3.214487075805664,
      "learning_rate": 8.584767457061416e-05,
      "loss": 1.6176,
      "step": 136300
    },
    {
      "epoch": 2.73,
      "grad_norm": 3.5122604370117188,
      "learning_rate": 8.572328688525513e-05,
      "loss": 1.5975,
      "step": 136400
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.7384033203125,
      "learning_rate": 8.559892174477479e-05,
      "loss": 1.6166,
      "step": 136500
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.9358208179473877,
      "learning_rate": 8.547457934556274e-05,
      "loss": 1.6048,
      "step": 136600
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.987180233001709,
      "learning_rate": 8.535025988397258e-05,
      "loss": 1.6186,
      "step": 136700
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.7147364616394043,
      "learning_rate": 8.522596355632164e-05,
      "loss": 1.6264,
      "step": 136800
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.55622935295105,
      "learning_rate": 8.51016905588909e-05,
      "loss": 1.5894,
      "step": 136900
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.372525453567505,
      "learning_rate": 8.497744108792429e-05,
      "loss": 1.6044,
      "step": 137000
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.248317003250122,
      "learning_rate": 8.485321533962876e-05,
      "loss": 1.6266,
      "step": 137100
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.141725778579712,
      "learning_rate": 8.47290135101737e-05,
      "loss": 1.607,
      "step": 137200
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.3468477725982666,
      "learning_rate": 8.46048357956907e-05,
      "loss": 1.6341,
      "step": 137300
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.6492276191711426,
      "learning_rate": 8.44806823922734e-05,
      "loss": 1.6057,
      "step": 137400
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.5677871704101562,
      "learning_rate": 8.435655349597689e-05,
      "loss": 1.615,
      "step": 137500
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.0086333751678467,
      "learning_rate": 8.423244930281775e-05,
      "loss": 1.6163,
      "step": 137600
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.910048007965088,
      "learning_rate": 8.410837000877334e-05,
      "loss": 1.5902,
      "step": 137700
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.9618353843688965,
      "learning_rate": 8.398431580978181e-05,
      "loss": 1.6255,
      "step": 137800
    },
    {
      "epoch": 2.76,
      "grad_norm": 3.323516845703125,
      "learning_rate": 8.386028690174174e-05,
      "loss": 1.5934,
      "step": 137900
    },
    {
      "epoch": 2.76,
      "grad_norm": 3.1979963779449463,
      "learning_rate": 8.373628348051165e-05,
      "loss": 1.6195,
      "step": 138000
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.6973977088928223,
      "learning_rate": 8.361230574190987e-05,
      "loss": 1.6252,
      "step": 138100
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.935185670852661,
      "learning_rate": 8.348835388171421e-05,
      "loss": 1.6171,
      "step": 138200
    },
    {
      "epoch": 2.77,
      "grad_norm": 3.237435817718506,
      "learning_rate": 8.336442809566152e-05,
      "loss": 1.6147,
      "step": 138300
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.59420108795166,
      "learning_rate": 8.32405285794476e-05,
      "loss": 1.6187,
      "step": 138400
    },
    {
      "epoch": 2.77,
      "grad_norm": 3.4812495708465576,
      "learning_rate": 8.311665552872662e-05,
      "loss": 1.6131,
      "step": 138500
    },
    {
      "epoch": 2.77,
      "grad_norm": 3.3317737579345703,
      "learning_rate": 8.299280913911111e-05,
      "loss": 1.6273,
      "step": 138600
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.7417726516723633,
      "learning_rate": 8.286898960617138e-05,
      "loss": 1.6162,
      "step": 138700
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.208632469177246,
      "learning_rate": 8.274519712543534e-05,
      "loss": 1.6277,
      "step": 138800
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.2176690101623535,
      "learning_rate": 8.262143189238832e-05,
      "loss": 1.6091,
      "step": 138900
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.9185500144958496,
      "learning_rate": 8.249769410247239e-05,
      "loss": 1.6142,
      "step": 139000
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.1602723598480225,
      "learning_rate": 8.237398395108653e-05,
      "loss": 1.6208,
      "step": 139100
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.8288650512695312,
      "learning_rate": 8.225030163358589e-05,
      "loss": 1.6125,
      "step": 139200
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.9411168098449707,
      "learning_rate": 8.212664734528169e-05,
      "loss": 1.6044,
      "step": 139300
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.193498134613037,
      "learning_rate": 8.200302128144104e-05,
      "loss": 1.6077,
      "step": 139400
    },
    {
      "epoch": 2.79,
      "grad_norm": 3.1284985542297363,
      "learning_rate": 8.187942363728625e-05,
      "loss": 1.6115,
      "step": 139500
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.8230721950531006,
      "learning_rate": 8.175585460799499e-05,
      "loss": 1.6085,
      "step": 139600
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.8259096145629883,
      "learning_rate": 8.163231438869954e-05,
      "loss": 1.5993,
      "step": 139700
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.2104122638702393,
      "learning_rate": 8.150880317448676e-05,
      "loss": 1.6045,
      "step": 139800
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.457353115081787,
      "learning_rate": 8.13853211603978e-05,
      "loss": 1.6143,
      "step": 139900
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.7412240505218506,
      "learning_rate": 8.126186854142752e-05,
      "loss": 1.6065,
      "step": 140000
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.9163713455200195,
      "learning_rate": 8.113844551252454e-05,
      "loss": 1.6075,
      "step": 140100
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.6846818923950195,
      "learning_rate": 8.101505226859063e-05,
      "loss": 1.6152,
      "step": 140200
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.922694444656372,
      "learning_rate": 8.089168900448053e-05,
      "loss": 1.6346,
      "step": 140300
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.944331645965576,
      "learning_rate": 8.076835591500173e-05,
      "loss": 1.6174,
      "step": 140400
    },
    {
      "epoch": 2.81,
      "grad_norm": 3.1968603134155273,
      "learning_rate": 8.064505319491398e-05,
      "loss": 1.6247,
      "step": 140500
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.7757956981658936,
      "learning_rate": 8.052178103892914e-05,
      "loss": 1.6337,
      "step": 140600
    },
    {
      "epoch": 2.81,
      "grad_norm": 3.625075340270996,
      "learning_rate": 8.039853964171071e-05,
      "loss": 1.5954,
      "step": 140700
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.88653826713562,
      "learning_rate": 8.027532919787371e-05,
      "loss": 1.5887,
      "step": 140800
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.9169182777404785,
      "learning_rate": 8.01521499019843e-05,
      "loss": 1.6142,
      "step": 140900
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.1549391746520996,
      "learning_rate": 8.002900194855932e-05,
      "loss": 1.5834,
      "step": 141000
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.691991090774536,
      "learning_rate": 7.990588553206623e-05,
      "loss": 1.6277,
      "step": 141100
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.3174283504486084,
      "learning_rate": 7.978280084692267e-05,
      "loss": 1.6247,
      "step": 141200
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.9913878440856934,
      "learning_rate": 7.965974808749613e-05,
      "loss": 1.6308,
      "step": 141300
    },
    {
      "epoch": 2.83,
      "grad_norm": 3.167459011077881,
      "learning_rate": 7.953672744810375e-05,
      "loss": 1.6173,
      "step": 141400
    },
    {
      "epoch": 2.83,
      "grad_norm": 3.0401599407196045,
      "learning_rate": 7.941373912301189e-05,
      "loss": 1.5926,
      "step": 141500
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.9828736782073975,
      "learning_rate": 7.929078330643589e-05,
      "loss": 1.6249,
      "step": 141600
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.8968563079833984,
      "learning_rate": 7.91678601925398e-05,
      "loss": 1.5997,
      "step": 141700
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.829559087753296,
      "learning_rate": 7.904496997543595e-05,
      "loss": 1.6044,
      "step": 141800
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.9344730377197266,
      "learning_rate": 7.892211284918483e-05,
      "loss": 1.6034,
      "step": 141900
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.8280365467071533,
      "learning_rate": 7.879928900779456e-05,
      "loss": 1.5966,
      "step": 142000
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.3954315185546875,
      "learning_rate": 7.867649864522074e-05,
      "loss": 1.6071,
      "step": 142100
    },
    {
      "epoch": 2.84,
      "grad_norm": 3.2013237476348877,
      "learning_rate": 7.855374195536618e-05,
      "loss": 1.6127,
      "step": 142200
    },
    {
      "epoch": 2.85,
      "grad_norm": 3.2033050060272217,
      "learning_rate": 7.843101913208037e-05,
      "loss": 1.597,
      "step": 142300
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.727945566177368,
      "learning_rate": 7.830833036915948e-05,
      "loss": 1.5923,
      "step": 142400
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.9325075149536133,
      "learning_rate": 7.818567586034577e-05,
      "loss": 1.6124,
      "step": 142500
    },
    {
      "epoch": 2.85,
      "grad_norm": 3.361098051071167,
      "learning_rate": 7.80630557993274e-05,
      "loss": 1.5963,
      "step": 142600
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.894955635070801,
      "learning_rate": 7.79404703797383e-05,
      "loss": 1.6146,
      "step": 142700
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.963670015335083,
      "learning_rate": 7.781791979515748e-05,
      "loss": 1.6086,
      "step": 142800
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.9020516872406006,
      "learning_rate": 7.769540423910909e-05,
      "loss": 1.6052,
      "step": 142900
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.7373363971710205,
      "learning_rate": 7.75729239050619e-05,
      "loss": 1.6183,
      "step": 143000
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.797348737716675,
      "learning_rate": 7.745047898642908e-05,
      "loss": 1.6298,
      "step": 143100
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.231121301651001,
      "learning_rate": 7.732806967656785e-05,
      "loss": 1.6295,
      "step": 143200
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.472541570663452,
      "learning_rate": 7.720569616877924e-05,
      "loss": 1.6438,
      "step": 143300
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.9392056465148926,
      "learning_rate": 7.708335865630774e-05,
      "loss": 1.6309,
      "step": 143400
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.9311375617980957,
      "learning_rate": 7.696105733234098e-05,
      "loss": 1.6085,
      "step": 143500
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.9556374549865723,
      "learning_rate": 7.683879239000936e-05,
      "loss": 1.6144,
      "step": 143600
    },
    {
      "epoch": 2.87,
      "grad_norm": 3.0318567752838135,
      "learning_rate": 7.671656402238602e-05,
      "loss": 1.5873,
      "step": 143700
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.0744354724884033,
      "learning_rate": 7.659437242248617e-05,
      "loss": 1.6402,
      "step": 143800
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.6564300060272217,
      "learning_rate": 7.647221778326707e-05,
      "loss": 1.6195,
      "step": 143900
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.077765703201294,
      "learning_rate": 7.635010029762756e-05,
      "loss": 1.6315,
      "step": 144000
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.7318873405456543,
      "learning_rate": 7.622802015840776e-05,
      "loss": 1.6294,
      "step": 144100
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.417386293411255,
      "learning_rate": 7.610597755838895e-05,
      "loss": 1.5941,
      "step": 144200
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.844219207763672,
      "learning_rate": 7.598397269029301e-05,
      "loss": 1.6346,
      "step": 144300
    },
    {
      "epoch": 2.89,
      "grad_norm": 3.3979592323303223,
      "learning_rate": 7.586200574678231e-05,
      "loss": 1.5866,
      "step": 144400
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.6469149589538574,
      "learning_rate": 7.574007692045928e-05,
      "loss": 1.5889,
      "step": 144500
    },
    {
      "epoch": 2.89,
      "grad_norm": 3.705573081970215,
      "learning_rate": 7.561818640386616e-05,
      "loss": 1.5891,
      "step": 144600
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.964141368865967,
      "learning_rate": 7.549633438948475e-05,
      "loss": 1.613,
      "step": 144700
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.710716962814331,
      "learning_rate": 7.5374521069736e-05,
      "loss": 1.5932,
      "step": 144800
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.75799298286438,
      "learning_rate": 7.525274663697977e-05,
      "loss": 1.5963,
      "step": 144900
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.471076726913452,
      "learning_rate": 7.513101128351454e-05,
      "loss": 1.62,
      "step": 145000
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.2496843338012695,
      "learning_rate": 7.500931520157697e-05,
      "loss": 1.6089,
      "step": 145100
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.9052953720092773,
      "learning_rate": 7.488765858334188e-05,
      "loss": 1.6057,
      "step": 145200
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.736034631729126,
      "learning_rate": 7.47660416209216e-05,
      "loss": 1.5899,
      "step": 145300
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.9422245025634766,
      "learning_rate": 7.464446450636596e-05,
      "loss": 1.6096,
      "step": 145400
    },
    {
      "epoch": 2.91,
      "grad_norm": 3.3560433387756348,
      "learning_rate": 7.45229274316618e-05,
      "loss": 1.5905,
      "step": 145500
    },
    {
      "epoch": 2.91,
      "grad_norm": 3.14709210395813,
      "learning_rate": 7.440143058873274e-05,
      "loss": 1.6059,
      "step": 145600
    },
    {
      "epoch": 2.91,
      "grad_norm": 3.1028387546539307,
      "learning_rate": 7.427997416943892e-05,
      "loss": 1.5947,
      "step": 145700
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.8833351135253906,
      "learning_rate": 7.415855836557653e-05,
      "loss": 1.6016,
      "step": 145800
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.752046585083008,
      "learning_rate": 7.403718336887779e-05,
      "loss": 1.6068,
      "step": 145900
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.790278434753418,
      "learning_rate": 7.391584937101033e-05,
      "loss": 1.6007,
      "step": 146000
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.6611058712005615,
      "learning_rate": 7.379455656357708e-05,
      "loss": 1.6011,
      "step": 146100
    },
    {
      "epoch": 2.92,
      "grad_norm": 3.2494046688079834,
      "learning_rate": 7.367330513811598e-05,
      "loss": 1.6182,
      "step": 146200
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.602405548095703,
      "learning_rate": 7.355209528609956e-05,
      "loss": 1.6352,
      "step": 146300
    },
    {
      "epoch": 2.93,
      "grad_norm": 4.869143009185791,
      "learning_rate": 7.343092719893474e-05,
      "loss": 1.5963,
      "step": 146400
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.4856512546539307,
      "learning_rate": 7.330980106796246e-05,
      "loss": 1.6203,
      "step": 146500
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.2496330738067627,
      "learning_rate": 7.318871708445738e-05,
      "loss": 1.6026,
      "step": 146600
    },
    {
      "epoch": 2.93,
      "grad_norm": 3.447953939437866,
      "learning_rate": 7.306767543962769e-05,
      "loss": 1.5936,
      "step": 146700
    },
    {
      "epoch": 2.94,
      "grad_norm": 3.3612987995147705,
      "learning_rate": 7.294667632461463e-05,
      "loss": 1.5986,
      "step": 146800
    },
    {
      "epoch": 2.94,
      "grad_norm": 3.5837032794952393,
      "learning_rate": 7.282571993049235e-05,
      "loss": 1.6297,
      "step": 146900
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.94887638092041,
      "learning_rate": 7.270480644826749e-05,
      "loss": 1.5952,
      "step": 147000
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.3012874126434326,
      "learning_rate": 7.258393606887892e-05,
      "loss": 1.5708,
      "step": 147100
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.6803510189056396,
      "learning_rate": 7.246310898319752e-05,
      "loss": 1.5953,
      "step": 147200
    },
    {
      "epoch": 2.95,
      "grad_norm": 3.537148952484131,
      "learning_rate": 7.234232538202572e-05,
      "loss": 1.5956,
      "step": 147300
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.868438482284546,
      "learning_rate": 7.222158545609727e-05,
      "loss": 1.6053,
      "step": 147400
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.533716917037964,
      "learning_rate": 7.210088939607708e-05,
      "loss": 1.6304,
      "step": 147500
    },
    {
      "epoch": 2.95,
      "grad_norm": 3.1777260303497314,
      "learning_rate": 7.198023739256066e-05,
      "loss": 1.6041,
      "step": 147600
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.8720593452453613,
      "learning_rate": 7.185962963607398e-05,
      "loss": 1.594,
      "step": 147700
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.9922900199890137,
      "learning_rate": 7.173906631707317e-05,
      "loss": 1.6068,
      "step": 147800
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.0860941410064697,
      "learning_rate": 7.161854762594415e-05,
      "loss": 1.6136,
      "step": 147900
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.8218014240264893,
      "learning_rate": 7.149807375300239e-05,
      "loss": 1.6037,
      "step": 148000
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.049861192703247,
      "learning_rate": 7.137764488849259e-05,
      "loss": 1.6026,
      "step": 148100
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.3143222332000732,
      "learning_rate": 7.125726122258837e-05,
      "loss": 1.5902,
      "step": 148200
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.160311460494995,
      "learning_rate": 7.113692294539196e-05,
      "loss": 1.6029,
      "step": 148300
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.7823855876922607,
      "learning_rate": 7.10166302469339e-05,
      "loss": 1.6076,
      "step": 148400
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.0567784309387207,
      "learning_rate": 7.089638331717284e-05,
      "loss": 1.5949,
      "step": 148500
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.0135746002197266,
      "learning_rate": 7.077618234599501e-05,
      "loss": 1.5909,
      "step": 148600
    },
    {
      "epoch": 2.97,
      "grad_norm": 2.4788005352020264,
      "learning_rate": 7.065602752321425e-05,
      "loss": 1.6024,
      "step": 148700
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.1158647537231445,
      "learning_rate": 7.053591903857138e-05,
      "loss": 1.5999,
      "step": 148800
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.343944549560547,
      "learning_rate": 7.041585708173404e-05,
      "loss": 1.6002,
      "step": 148900
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.8245840072631836,
      "learning_rate": 7.029584184229653e-05,
      "loss": 1.5982,
      "step": 149000
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.958995342254639,
      "learning_rate": 7.017587350977922e-05,
      "loss": 1.6136,
      "step": 149100
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.2461020946502686,
      "learning_rate": 7.005595227362858e-05,
      "loss": 1.5854,
      "step": 149200
    },
    {
      "epoch": 2.99,
      "grad_norm": 4.113161563873291,
      "learning_rate": 6.993607832321654e-05,
      "loss": 1.6196,
      "step": 149300
    },
    {
      "epoch": 2.99,
      "grad_norm": 2.3286967277526855,
      "learning_rate": 6.98162518478404e-05,
      "loss": 1.569,
      "step": 149400
    },
    {
      "epoch": 2.99,
      "grad_norm": 3.1297662258148193,
      "learning_rate": 6.969647303672262e-05,
      "loss": 1.5913,
      "step": 149500
    },
    {
      "epoch": 2.99,
      "grad_norm": 2.7361552715301514,
      "learning_rate": 6.957674207901018e-05,
      "loss": 1.5922,
      "step": 149600
    },
    {
      "epoch": 2.99,
      "grad_norm": 2.6898348331451416,
      "learning_rate": 6.945705916377472e-05,
      "loss": 1.5766,
      "step": 149700
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.0925991535186768,
      "learning_rate": 6.933742448001183e-05,
      "loss": 1.6014,
      "step": 149800
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.082119941711426,
      "learning_rate": 6.921783821664098e-05,
      "loss": 1.5577,
      "step": 149900
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.0795249938964844,
      "learning_rate": 6.909830056250527e-05,
      "loss": 1.5978,
      "step": 150000
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.0810694694519043,
      "learning_rate": 6.897881170637093e-05,
      "loss": 1.5368,
      "step": 150100
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.445739269256592,
      "learning_rate": 6.885937183692717e-05,
      "loss": 1.5684,
      "step": 150200
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.130156993865967,
      "learning_rate": 6.87399811427859e-05,
      "loss": 1.5544,
      "step": 150300
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.0654335021972656,
      "learning_rate": 6.862063981248125e-05,
      "loss": 1.5536,
      "step": 150400
    },
    {
      "epoch": 3.01,
      "grad_norm": 3.2825546264648438,
      "learning_rate": 6.850134803446954e-05,
      "loss": 1.5406,
      "step": 150500
    },
    {
      "epoch": 3.01,
      "grad_norm": 2.8428337574005127,
      "learning_rate": 6.838210599712869e-05,
      "loss": 1.5374,
      "step": 150600
    },
    {
      "epoch": 3.01,
      "grad_norm": 2.9834704399108887,
      "learning_rate": 6.826291388875825e-05,
      "loss": 1.5214,
      "step": 150700
    },
    {
      "epoch": 3.02,
      "grad_norm": 3.036475896835327,
      "learning_rate": 6.814377189757876e-05,
      "loss": 1.5149,
      "step": 150800
    },
    {
      "epoch": 3.02,
      "grad_norm": 3.814250946044922,
      "learning_rate": 6.802468021173167e-05,
      "loss": 1.5682,
      "step": 150900
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.8091747760772705,
      "learning_rate": 6.790563901927907e-05,
      "loss": 1.5777,
      "step": 151000
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.6333439350128174,
      "learning_rate": 6.77866485082032e-05,
      "loss": 1.5426,
      "step": 151100
    },
    {
      "epoch": 3.02,
      "grad_norm": 3.0254156589508057,
      "learning_rate": 6.766770886640637e-05,
      "loss": 1.5512,
      "step": 151200
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.9412853717803955,
      "learning_rate": 6.754882028171047e-05,
      "loss": 1.5461,
      "step": 151300
    },
    {
      "epoch": 3.03,
      "grad_norm": 3.203584671020508,
      "learning_rate": 6.742998294185678e-05,
      "loss": 1.5768,
      "step": 151400
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.8223648071289062,
      "learning_rate": 6.731119703450577e-05,
      "loss": 1.554,
      "step": 151500
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.8484137058258057,
      "learning_rate": 6.71924627472365e-05,
      "loss": 1.5706,
      "step": 151600
    },
    {
      "epoch": 3.03,
      "grad_norm": 3.700359582901001,
      "learning_rate": 6.707378026754669e-05,
      "loss": 1.5368,
      "step": 151700
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.4796764850616455,
      "learning_rate": 6.695514978285215e-05,
      "loss": 1.5337,
      "step": 151800
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.5002286434173584,
      "learning_rate": 6.683657148048657e-05,
      "loss": 1.5336,
      "step": 151900
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.2786951065063477,
      "learning_rate": 6.671804554770135e-05,
      "loss": 1.5659,
      "step": 152000
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.299952745437622,
      "learning_rate": 6.659957217166503e-05,
      "loss": 1.5358,
      "step": 152100
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.7324535846710205,
      "learning_rate": 6.648115153946333e-05,
      "loss": 1.5806,
      "step": 152200
    },
    {
      "epoch": 3.05,
      "grad_norm": 3.482731342315674,
      "learning_rate": 6.636278383809855e-05,
      "loss": 1.5625,
      "step": 152300
    },
    {
      "epoch": 3.05,
      "grad_norm": 2.860379695892334,
      "learning_rate": 6.624446925448944e-05,
      "loss": 1.5442,
      "step": 152400
    },
    {
      "epoch": 3.05,
      "grad_norm": 3.161111354827881,
      "learning_rate": 6.612620797547087e-05,
      "loss": 1.5332,
      "step": 152500
    },
    {
      "epoch": 3.05,
      "grad_norm": 2.653974771499634,
      "learning_rate": 6.600800018779356e-05,
      "loss": 1.5503,
      "step": 152600
    },
    {
      "epoch": 3.05,
      "grad_norm": 2.976484537124634,
      "learning_rate": 6.588984607812376e-05,
      "loss": 1.5509,
      "step": 152700
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.950972080230713,
      "learning_rate": 6.577174583304289e-05,
      "loss": 1.5346,
      "step": 152800
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.866882562637329,
      "learning_rate": 6.565369963904738e-05,
      "loss": 1.5341,
      "step": 152900
    },
    {
      "epoch": 3.06,
      "grad_norm": 4.031312942504883,
      "learning_rate": 6.55357076825483e-05,
      "loss": 1.5308,
      "step": 153000
    },
    {
      "epoch": 3.06,
      "grad_norm": 3.051915407180786,
      "learning_rate": 6.541777014987103e-05,
      "loss": 1.5353,
      "step": 153100
    },
    {
      "epoch": 3.06,
      "grad_norm": 3.723066806793213,
      "learning_rate": 6.529988722725507e-05,
      "loss": 1.545,
      "step": 153200
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.37084698677063,
      "learning_rate": 6.518205910085359e-05,
      "loss": 1.5533,
      "step": 153300
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.5341007709503174,
      "learning_rate": 6.506428595673331e-05,
      "loss": 1.5755,
      "step": 153400
    },
    {
      "epoch": 3.07,
      "grad_norm": 3.7494373321533203,
      "learning_rate": 6.494656798087412e-05,
      "loss": 1.5917,
      "step": 153500
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.596599817276001,
      "learning_rate": 6.482890535916876e-05,
      "loss": 1.5292,
      "step": 153600
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.9116554260253906,
      "learning_rate": 6.471129827742252e-05,
      "loss": 1.5512,
      "step": 153700
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.589392900466919,
      "learning_rate": 6.459374692135312e-05,
      "loss": 1.535,
      "step": 153800
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.978208065032959,
      "learning_rate": 6.447625147659012e-05,
      "loss": 1.5612,
      "step": 153900
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.139746904373169,
      "learning_rate": 6.435881212867493e-05,
      "loss": 1.5632,
      "step": 154000
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.970987558364868,
      "learning_rate": 6.424142906306029e-05,
      "loss": 1.5618,
      "step": 154100
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.5982987880706787,
      "learning_rate": 6.412410246511004e-05,
      "loss": 1.5644,
      "step": 154200
    },
    {
      "epoch": 3.09,
      "grad_norm": 3.4126739501953125,
      "learning_rate": 6.400683252009898e-05,
      "loss": 1.5394,
      "step": 154300
    },
    {
      "epoch": 3.09,
      "grad_norm": 2.582341432571411,
      "learning_rate": 6.388961941321225e-05,
      "loss": 1.5902,
      "step": 154400
    },
    {
      "epoch": 3.09,
      "grad_norm": 3.0697920322418213,
      "learning_rate": 6.377246332954544e-05,
      "loss": 1.563,
      "step": 154500
    },
    {
      "epoch": 3.09,
      "grad_norm": 3.2644450664520264,
      "learning_rate": 6.365536445410397e-05,
      "loss": 1.5802,
      "step": 154600
    },
    {
      "epoch": 3.09,
      "grad_norm": 2.703209638595581,
      "learning_rate": 6.35383229718029e-05,
      "loss": 1.5436,
      "step": 154700
    },
    {
      "epoch": 3.1,
      "grad_norm": 2.8271994590759277,
      "learning_rate": 6.342133906746676e-05,
      "loss": 1.5657,
      "step": 154800
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.179328203201294,
      "learning_rate": 6.330441292582908e-05,
      "loss": 1.5478,
      "step": 154900
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.050014019012451,
      "learning_rate": 6.318754473153221e-05,
      "loss": 1.5357,
      "step": 155000
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.1554131507873535,
      "learning_rate": 6.307073466912698e-05,
      "loss": 1.5532,
      "step": 155100
    },
    {
      "epoch": 3.1,
      "grad_norm": 2.9225029945373535,
      "learning_rate": 6.295398292307242e-05,
      "loss": 1.5636,
      "step": 155200
    },
    {
      "epoch": 3.11,
      "grad_norm": 3.2205541133880615,
      "learning_rate": 6.283728967773547e-05,
      "loss": 1.56,
      "step": 155300
    },
    {
      "epoch": 3.11,
      "grad_norm": 3.116685390472412,
      "learning_rate": 6.272065511739067e-05,
      "loss": 1.5522,
      "step": 155400
    },
    {
      "epoch": 3.11,
      "grad_norm": 2.9573593139648438,
      "learning_rate": 6.260407942621998e-05,
      "loss": 1.5511,
      "step": 155500
    },
    {
      "epoch": 3.11,
      "grad_norm": 3.7265470027923584,
      "learning_rate": 6.248756278831228e-05,
      "loss": 1.5198,
      "step": 155600
    },
    {
      "epoch": 3.11,
      "grad_norm": 3.251769781112671,
      "learning_rate": 6.237110538766319e-05,
      "loss": 1.5619,
      "step": 155700
    },
    {
      "epoch": 3.12,
      "grad_norm": 3.1584153175354004,
      "learning_rate": 6.225470740817496e-05,
      "loss": 1.5321,
      "step": 155800
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.4885549545288086,
      "learning_rate": 6.213836903365577e-05,
      "loss": 1.5418,
      "step": 155900
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.9000232219696045,
      "learning_rate": 6.20220904478199e-05,
      "loss": 1.5733,
      "step": 156000
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.738042116165161,
      "learning_rate": 6.190587183428707e-05,
      "loss": 1.5618,
      "step": 156100
    },
    {
      "epoch": 3.12,
      "grad_norm": 3.0647928714752197,
      "learning_rate": 6.178971337658225e-05,
      "loss": 1.5442,
      "step": 156200
    },
    {
      "epoch": 3.13,
      "grad_norm": 2.7533063888549805,
      "learning_rate": 6.167361525813565e-05,
      "loss": 1.5523,
      "step": 156300
    },
    {
      "epoch": 3.13,
      "grad_norm": 2.7211410999298096,
      "learning_rate": 6.155757766228192e-05,
      "loss": 1.5572,
      "step": 156400
    },
    {
      "epoch": 3.13,
      "grad_norm": 2.7436695098876953,
      "learning_rate": 6.144160077226036e-05,
      "loss": 1.5415,
      "step": 156500
    },
    {
      "epoch": 3.13,
      "grad_norm": 2.754809856414795,
      "learning_rate": 6.132568477121426e-05,
      "loss": 1.5422,
      "step": 156600
    },
    {
      "epoch": 3.13,
      "grad_norm": 2.811349630355835,
      "learning_rate": 6.120982984219075e-05,
      "loss": 1.5281,
      "step": 156700
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.614640951156616,
      "learning_rate": 6.109403616814069e-05,
      "loss": 1.5449,
      "step": 156800
    },
    {
      "epoch": 3.14,
      "grad_norm": 3.01682710647583,
      "learning_rate": 6.097830393191799e-05,
      "loss": 1.5594,
      "step": 156900
    },
    {
      "epoch": 3.14,
      "grad_norm": 3.491448402404785,
      "learning_rate": 6.086263331627976e-05,
      "loss": 1.5277,
      "step": 157000
    },
    {
      "epoch": 3.14,
      "grad_norm": 3.747361421585083,
      "learning_rate": 6.074702450388563e-05,
      "loss": 1.5274,
      "step": 157100
    },
    {
      "epoch": 3.14,
      "grad_norm": 3.1193039417266846,
      "learning_rate": 6.063147767729764e-05,
      "loss": 1.5506,
      "step": 157200
    },
    {
      "epoch": 3.15,
      "grad_norm": 2.8786423206329346,
      "learning_rate": 6.051599301898012e-05,
      "loss": 1.5347,
      "step": 157300
    },
    {
      "epoch": 3.15,
      "grad_norm": 2.9754390716552734,
      "learning_rate": 6.040057071129901e-05,
      "loss": 1.5608,
      "step": 157400
    },
    {
      "epoch": 3.15,
      "grad_norm": 3.0020878314971924,
      "learning_rate": 6.0285210936521955e-05,
      "loss": 1.5522,
      "step": 157500
    },
    {
      "epoch": 3.15,
      "grad_norm": 3.6168556213378906,
      "learning_rate": 6.016991387681774e-05,
      "loss": 1.5524,
      "step": 157600
    },
    {
      "epoch": 3.15,
      "grad_norm": 2.828462600708008,
      "learning_rate": 6.005467971425616e-05,
      "loss": 1.5451,
      "step": 157700
    },
    {
      "epoch": 3.16,
      "grad_norm": 3.429534435272217,
      "learning_rate": 5.993950863080773e-05,
      "loss": 1.5379,
      "step": 157800
    },
    {
      "epoch": 3.16,
      "grad_norm": 6.980747222900391,
      "learning_rate": 5.9824400808343236e-05,
      "loss": 1.5542,
      "step": 157900
    },
    {
      "epoch": 3.16,
      "grad_norm": 4.6347761154174805,
      "learning_rate": 5.9709356428633746e-05,
      "loss": 1.5507,
      "step": 158000
    },
    {
      "epoch": 3.16,
      "grad_norm": 3.189645767211914,
      "learning_rate": 5.959437567334998e-05,
      "loss": 1.5357,
      "step": 158100
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.7195241451263428,
      "learning_rate": 5.94794587240622e-05,
      "loss": 1.5625,
      "step": 158200
    },
    {
      "epoch": 3.17,
      "grad_norm": 3.332240581512451,
      "learning_rate": 5.9364605762240034e-05,
      "loss": 1.5555,
      "step": 158300
    },
    {
      "epoch": 3.17,
      "grad_norm": 3.1760430335998535,
      "learning_rate": 5.9249816969251914e-05,
      "loss": 1.547,
      "step": 158400
    },
    {
      "epoch": 3.17,
      "grad_norm": 2.69044828414917,
      "learning_rate": 5.913509252636511e-05,
      "loss": 1.5402,
      "step": 158500
    },
    {
      "epoch": 3.17,
      "grad_norm": 3.236981153488159,
      "learning_rate": 5.90204326147451e-05,
      "loss": 1.5484,
      "step": 158600
    },
    {
      "epoch": 3.17,
      "grad_norm": 2.534728527069092,
      "learning_rate": 5.890583741545552e-05,
      "loss": 1.5444,
      "step": 158700
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.1063849925994873,
      "learning_rate": 5.879130710945791e-05,
      "loss": 1.5481,
      "step": 158800
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.1440773010253906,
      "learning_rate": 5.8676841877611154e-05,
      "loss": 1.5536,
      "step": 158900
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.176447868347168,
      "learning_rate": 5.856244190067159e-05,
      "loss": 1.5555,
      "step": 159000
    },
    {
      "epoch": 3.18,
      "grad_norm": 2.813436508178711,
      "learning_rate": 5.8448107359292334e-05,
      "loss": 1.5378,
      "step": 159100
    },
    {
      "epoch": 3.18,
      "grad_norm": 2.8319506645202637,
      "learning_rate": 5.8333838434023203e-05,
      "loss": 1.567,
      "step": 159200
    },
    {
      "epoch": 3.19,
      "grad_norm": 3.198228359222412,
      "learning_rate": 5.82196353053105e-05,
      "loss": 1.5394,
      "step": 159300
    },
    {
      "epoch": 3.19,
      "grad_norm": 3.079406261444092,
      "learning_rate": 5.810549815349653e-05,
      "loss": 1.5545,
      "step": 159400
    },
    {
      "epoch": 3.19,
      "grad_norm": 3.100813627243042,
      "learning_rate": 5.799142715881938e-05,
      "loss": 1.5396,
      "step": 159500
    },
    {
      "epoch": 3.19,
      "grad_norm": 2.896867275238037,
      "learning_rate": 5.787742250141279e-05,
      "loss": 1.5443,
      "step": 159600
    },
    {
      "epoch": 3.19,
      "grad_norm": 3.21867036819458,
      "learning_rate": 5.776348436130562e-05,
      "loss": 1.5355,
      "step": 159700
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.834331750869751,
      "learning_rate": 5.7649612918421816e-05,
      "loss": 1.5481,
      "step": 159800
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.7185566425323486,
      "learning_rate": 5.753580835257988e-05,
      "loss": 1.5483,
      "step": 159900
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.1096692085266113,
      "learning_rate": 5.7422070843492734e-05,
      "loss": 1.5532,
      "step": 160000
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.9164345264434814,
      "learning_rate": 5.7308400570767495e-05,
      "loss": 1.5506,
      "step": 160100
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.248236894607544,
      "learning_rate": 5.719479771390494e-05,
      "loss": 1.5606,
      "step": 160200
    },
    {
      "epoch": 3.21,
      "grad_norm": 3.030231475830078,
      "learning_rate": 5.7081262452299623e-05,
      "loss": 1.5395,
      "step": 160300
    },
    {
      "epoch": 3.21,
      "grad_norm": 2.9394991397857666,
      "learning_rate": 5.696779496523913e-05,
      "loss": 1.5676,
      "step": 160400
    },
    {
      "epoch": 3.21,
      "grad_norm": 2.743873357772827,
      "learning_rate": 5.6854395431904094e-05,
      "loss": 1.5476,
      "step": 160500
    },
    {
      "epoch": 3.21,
      "grad_norm": 2.7804441452026367,
      "learning_rate": 5.674106403136792e-05,
      "loss": 1.5197,
      "step": 160600
    },
    {
      "epoch": 3.21,
      "grad_norm": 2.737722158432007,
      "learning_rate": 5.6627800942596296e-05,
      "loss": 1.5525,
      "step": 160700
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.9379701614379883,
      "learning_rate": 5.651460634444716e-05,
      "loss": 1.5559,
      "step": 160800
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.9127984046936035,
      "learning_rate": 5.6401480415670215e-05,
      "loss": 1.5309,
      "step": 160900
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.5972859859466553,
      "learning_rate": 5.6288423334906735e-05,
      "loss": 1.541,
      "step": 161000
    },
    {
      "epoch": 3.22,
      "grad_norm": 3.4648373126983643,
      "learning_rate": 5.6175435280689236e-05,
      "loss": 1.5572,
      "step": 161100
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.6559269428253174,
      "learning_rate": 5.606251643144136e-05,
      "loss": 1.5447,
      "step": 161200
    },
    {
      "epoch": 3.23,
      "grad_norm": 2.745666027069092,
      "learning_rate": 5.594966696547734e-05,
      "loss": 1.5418,
      "step": 161300
    },
    {
      "epoch": 3.23,
      "grad_norm": 3.0250942707061768,
      "learning_rate": 5.5836887061001875e-05,
      "loss": 1.5408,
      "step": 161400
    },
    {
      "epoch": 3.23,
      "grad_norm": 3.4424262046813965,
      "learning_rate": 5.572417689610987e-05,
      "loss": 1.5362,
      "step": 161500
    },
    {
      "epoch": 3.23,
      "grad_norm": 2.747594118118286,
      "learning_rate": 5.561153664878603e-05,
      "loss": 1.5708,
      "step": 161600
    },
    {
      "epoch": 3.23,
      "grad_norm": 3.218087673187256,
      "learning_rate": 5.549896649690465e-05,
      "loss": 1.5608,
      "step": 161700
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.97507381439209,
      "learning_rate": 5.5386466618229436e-05,
      "loss": 1.5636,
      "step": 161800
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.9088573455810547,
      "learning_rate": 5.527403719041304e-05,
      "loss": 1.5458,
      "step": 161900
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.0281097888946533,
      "learning_rate": 5.5161678390996796e-05,
      "loss": 1.5427,
      "step": 162000
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.6072657108306885,
      "learning_rate": 5.504939039741067e-05,
      "loss": 1.5369,
      "step": 162100
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.6915857791900635,
      "learning_rate": 5.493717338697267e-05,
      "loss": 1.5442,
      "step": 162200
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.434605360031128,
      "learning_rate": 5.482502753688885e-05,
      "loss": 1.5449,
      "step": 162300
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.3784642219543457,
      "learning_rate": 5.471295302425276e-05,
      "loss": 1.5526,
      "step": 162400
    },
    {
      "epoch": 3.25,
      "grad_norm": 2.424516201019287,
      "learning_rate": 5.4600950026045326e-05,
      "loss": 1.5511,
      "step": 162500
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.0607199668884277,
      "learning_rate": 5.4489018719134654e-05,
      "loss": 1.5599,
      "step": 162600
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.328063726425171,
      "learning_rate": 5.4377159280275457e-05,
      "loss": 1.5436,
      "step": 162700
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.7806382179260254,
      "learning_rate": 5.4265371886109163e-05,
      "loss": 1.5553,
      "step": 162800
    },
    {
      "epoch": 3.26,
      "grad_norm": 3.1831040382385254,
      "learning_rate": 5.415365671316326e-05,
      "loss": 1.5704,
      "step": 162900
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.914154052734375,
      "learning_rate": 5.404201393785122e-05,
      "loss": 1.5513,
      "step": 163000
    },
    {
      "epoch": 3.26,
      "grad_norm": 3.2377421855926514,
      "learning_rate": 5.393044373647231e-05,
      "loss": 1.5517,
      "step": 163100
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.4424259662628174,
      "learning_rate": 5.381894628521105e-05,
      "loss": 1.5276,
      "step": 163200
    },
    {
      "epoch": 3.27,
      "grad_norm": 3.040433645248413,
      "learning_rate": 5.370752176013717e-05,
      "loss": 1.5159,
      "step": 163300
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.7274603843688965,
      "learning_rate": 5.359617033720519e-05,
      "loss": 1.5463,
      "step": 163400
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.8096747398376465,
      "learning_rate": 5.348489219225416e-05,
      "loss": 1.5579,
      "step": 163500
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.804771900177002,
      "learning_rate": 5.337368750100755e-05,
      "loss": 1.5355,
      "step": 163600
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.6164512634277344,
      "learning_rate": 5.3262556439072654e-05,
      "loss": 1.5501,
      "step": 163700
    },
    {
      "epoch": 3.28,
      "grad_norm": 2.7113468647003174,
      "learning_rate": 5.315149918194067e-05,
      "loss": 1.5414,
      "step": 163800
    },
    {
      "epoch": 3.28,
      "grad_norm": 2.5936732292175293,
      "learning_rate": 5.304051590498613e-05,
      "loss": 1.5679,
      "step": 163900
    },
    {
      "epoch": 3.28,
      "grad_norm": 2.658165216445923,
      "learning_rate": 5.292960678346675e-05,
      "loss": 1.5107,
      "step": 164000
    },
    {
      "epoch": 3.28,
      "grad_norm": 3.0216445922851562,
      "learning_rate": 5.2818771992523206e-05,
      "loss": 1.5295,
      "step": 164100
    },
    {
      "epoch": 3.28,
      "grad_norm": 2.6388895511627197,
      "learning_rate": 5.270801170717874e-05,
      "loss": 1.5342,
      "step": 164200
    },
    {
      "epoch": 3.29,
      "grad_norm": 3.0697710514068604,
      "learning_rate": 5.2597326102339e-05,
      "loss": 1.5473,
      "step": 164300
    },
    {
      "epoch": 3.29,
      "grad_norm": 2.870326519012451,
      "learning_rate": 5.2486715352791636e-05,
      "loss": 1.5553,
      "step": 164400
    },
    {
      "epoch": 3.29,
      "grad_norm": 3.0080344676971436,
      "learning_rate": 5.237617963320608e-05,
      "loss": 1.5581,
      "step": 164500
    },
    {
      "epoch": 3.29,
      "grad_norm": 3.3427305221557617,
      "learning_rate": 5.2265719118133404e-05,
      "loss": 1.5444,
      "step": 164600
    },
    {
      "epoch": 3.29,
      "grad_norm": 2.936155319213867,
      "learning_rate": 5.215533398200576e-05,
      "loss": 1.5603,
      "step": 164700
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.7483632564544678,
      "learning_rate": 5.204502439913641e-05,
      "loss": 1.5444,
      "step": 164800
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.9938275814056396,
      "learning_rate": 5.1934790543719226e-05,
      "loss": 1.554,
      "step": 164900
    },
    {
      "epoch": 3.3,
      "grad_norm": 3.1938490867614746,
      "learning_rate": 5.182463258982846e-05,
      "loss": 1.5366,
      "step": 165000
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.8180508613586426,
      "learning_rate": 5.171455071141863e-05,
      "loss": 1.5662,
      "step": 165100
    },
    {
      "epoch": 3.3,
      "grad_norm": 3.546302080154419,
      "learning_rate": 5.160454508232397e-05,
      "loss": 1.5568,
      "step": 165200
    },
    {
      "epoch": 3.31,
      "grad_norm": 2.974881649017334,
      "learning_rate": 5.149461587625849e-05,
      "loss": 1.5185,
      "step": 165300
    },
    {
      "epoch": 3.31,
      "grad_norm": 3.1269993782043457,
      "learning_rate": 5.138476326681534e-05,
      "loss": 1.5144,
      "step": 165400
    },
    {
      "epoch": 3.31,
      "grad_norm": 2.398782730102539,
      "learning_rate": 5.127498742746675e-05,
      "loss": 1.5506,
      "step": 165500
    },
    {
      "epoch": 3.31,
      "grad_norm": 3.1887290477752686,
      "learning_rate": 5.116528853156384e-05,
      "loss": 1.5575,
      "step": 165600
    },
    {
      "epoch": 3.31,
      "grad_norm": 2.854076623916626,
      "learning_rate": 5.105566675233611e-05,
      "loss": 1.5311,
      "step": 165700
    },
    {
      "epoch": 3.32,
      "grad_norm": 3.276564359664917,
      "learning_rate": 5.094612226289128e-05,
      "loss": 1.5458,
      "step": 165800
    },
    {
      "epoch": 3.32,
      "grad_norm": 2.6526522636413574,
      "learning_rate": 5.083665523621506e-05,
      "loss": 1.5419,
      "step": 165900
    },
    {
      "epoch": 3.32,
      "grad_norm": 3.793381690979004,
      "learning_rate": 5.072726584517086e-05,
      "loss": 1.5264,
      "step": 166000
    },
    {
      "epoch": 3.32,
      "grad_norm": 2.7156670093536377,
      "learning_rate": 5.0617954262499444e-05,
      "loss": 1.5616,
      "step": 166100
    },
    {
      "epoch": 3.32,
      "grad_norm": 2.7533528804779053,
      "learning_rate": 5.0508720660818684e-05,
      "loss": 1.566,
      "step": 166200
    },
    {
      "epoch": 3.33,
      "grad_norm": 3.2370190620422363,
      "learning_rate": 5.039956521262341e-05,
      "loss": 1.5673,
      "step": 166300
    },
    {
      "epoch": 3.33,
      "grad_norm": 3.0926513671875,
      "learning_rate": 5.029048809028496e-05,
      "loss": 1.5454,
      "step": 166400
    },
    {
      "epoch": 3.33,
      "grad_norm": 2.9383482933044434,
      "learning_rate": 5.018148946605092e-05,
      "loss": 1.5181,
      "step": 166500
    },
    {
      "epoch": 3.33,
      "grad_norm": 3.103989362716675,
      "learning_rate": 5.007256951204512e-05,
      "loss": 1.5746,
      "step": 166600
    },
    {
      "epoch": 3.33,
      "grad_norm": 2.8239238262176514,
      "learning_rate": 4.9963728400266965e-05,
      "loss": 1.5566,
      "step": 166700
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.2327680587768555,
      "learning_rate": 4.98549663025914e-05,
      "loss": 1.5685,
      "step": 166800
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.883361339569092,
      "learning_rate": 4.974628339076869e-05,
      "loss": 1.5538,
      "step": 166900
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.1781952381134033,
      "learning_rate": 4.9637679836423924e-05,
      "loss": 1.571,
      "step": 167000
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.0348076820373535,
      "learning_rate": 4.9529155811057e-05,
      "loss": 1.5549,
      "step": 167100
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.8895137310028076,
      "learning_rate": 4.942071148604215e-05,
      "loss": 1.5381,
      "step": 167200
    },
    {
      "epoch": 3.35,
      "grad_norm": 2.7383196353912354,
      "learning_rate": 4.93123470326277e-05,
      "loss": 1.5352,
      "step": 167300
    },
    {
      "epoch": 3.35,
      "grad_norm": 2.5558173656463623,
      "learning_rate": 4.920406262193602e-05,
      "loss": 1.5186,
      "step": 167400
    },
    {
      "epoch": 3.35,
      "grad_norm": 2.853562355041504,
      "learning_rate": 4.909585842496287e-05,
      "loss": 1.5247,
      "step": 167500
    },
    {
      "epoch": 3.35,
      "grad_norm": 3.0054759979248047,
      "learning_rate": 4.898773461257754e-05,
      "loss": 1.5525,
      "step": 167600
    },
    {
      "epoch": 3.35,
      "grad_norm": 3.1220364570617676,
      "learning_rate": 4.887969135552225e-05,
      "loss": 1.5213,
      "step": 167700
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.4806768894195557,
      "learning_rate": 4.8771728824412e-05,
      "loss": 1.5578,
      "step": 167800
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.8156185150146484,
      "learning_rate": 4.866384718973446e-05,
      "loss": 1.554,
      "step": 167900
    },
    {
      "epoch": 3.36,
      "grad_norm": 3.0174503326416016,
      "learning_rate": 4.8556046621849346e-05,
      "loss": 1.5234,
      "step": 168000
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.944146156311035,
      "learning_rate": 4.844832729098858e-05,
      "loss": 1.575,
      "step": 168100
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.9207608699798584,
      "learning_rate": 4.8340689367255643e-05,
      "loss": 1.5252,
      "step": 168200
    },
    {
      "epoch": 3.37,
      "grad_norm": 2.9179086685180664,
      "learning_rate": 4.823313302062546e-05,
      "loss": 1.5627,
      "step": 168300
    },
    {
      "epoch": 3.37,
      "grad_norm": 2.735334873199463,
      "learning_rate": 4.812565842094426e-05,
      "loss": 1.5638,
      "step": 168400
    },
    {
      "epoch": 3.37,
      "grad_norm": 3.391099214553833,
      "learning_rate": 4.8018265737929044e-05,
      "loss": 1.5118,
      "step": 168500
    },
    {
      "epoch": 3.37,
      "grad_norm": 2.856962203979492,
      "learning_rate": 4.791095514116758e-05,
      "loss": 1.5401,
      "step": 168600
    },
    {
      "epoch": 3.37,
      "grad_norm": 2.7548837661743164,
      "learning_rate": 4.780372680011791e-05,
      "loss": 1.5359,
      "step": 168700
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.5148417949676514,
      "learning_rate": 4.769658088410819e-05,
      "loss": 1.5368,
      "step": 168800
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.465975284576416,
      "learning_rate": 4.7589517562336516e-05,
      "loss": 1.5368,
      "step": 168900
    },
    {
      "epoch": 3.38,
      "grad_norm": 3.0275955200195312,
      "learning_rate": 4.748253700387042e-05,
      "loss": 1.5429,
      "step": 169000
    },
    {
      "epoch": 3.38,
      "grad_norm": 3.189326763153076,
      "learning_rate": 4.737563937764686e-05,
      "loss": 1.5662,
      "step": 169100
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.5995633602142334,
      "learning_rate": 4.726882485247177e-05,
      "loss": 1.5569,
      "step": 169200
    },
    {
      "epoch": 3.39,
      "grad_norm": 3.152200937271118,
      "learning_rate": 4.716209359701982e-05,
      "loss": 1.5527,
      "step": 169300
    },
    {
      "epoch": 3.39,
      "grad_norm": 2.9627223014831543,
      "learning_rate": 4.705544577983429e-05,
      "loss": 1.5549,
      "step": 169400
    },
    {
      "epoch": 3.39,
      "grad_norm": 3.2571163177490234,
      "learning_rate": 4.694888156932658e-05,
      "loss": 1.5458,
      "step": 169500
    },
    {
      "epoch": 3.39,
      "grad_norm": 3.3616364002227783,
      "learning_rate": 4.684240113377619e-05,
      "loss": 1.5456,
      "step": 169600
    },
    {
      "epoch": 3.39,
      "grad_norm": 2.585843563079834,
      "learning_rate": 4.6736004641330236e-05,
      "loss": 1.5412,
      "step": 169700
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.9968605041503906,
      "learning_rate": 4.6629692260003245e-05,
      "loss": 1.5311,
      "step": 169800
    },
    {
      "epoch": 3.4,
      "grad_norm": 3.168574571609497,
      "learning_rate": 4.652346415767708e-05,
      "loss": 1.5368,
      "step": 169900
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.5999655723571777,
      "learning_rate": 4.6417320502100316e-05,
      "loss": 1.5609,
      "step": 170000
    },
    {
      "epoch": 3.4,
      "grad_norm": 8.35307502746582,
      "learning_rate": 4.6311261460888365e-05,
      "loss": 1.5598,
      "step": 170100
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.7937753200531006,
      "learning_rate": 4.620528720152288e-05,
      "loss": 1.5367,
      "step": 170200
    },
    {
      "epoch": 3.41,
      "grad_norm": 3.2621684074401855,
      "learning_rate": 4.609939789135165e-05,
      "loss": 1.5489,
      "step": 170300
    },
    {
      "epoch": 3.41,
      "grad_norm": 2.9340693950653076,
      "learning_rate": 4.5993593697588424e-05,
      "loss": 1.5576,
      "step": 170400
    },
    {
      "epoch": 3.41,
      "grad_norm": 2.4177651405334473,
      "learning_rate": 4.588787478731242e-05,
      "loss": 1.5244,
      "step": 170500
    },
    {
      "epoch": 3.41,
      "grad_norm": 2.7456586360931396,
      "learning_rate": 4.578224132746821e-05,
      "loss": 1.5382,
      "step": 170600
    },
    {
      "epoch": 3.41,
      "grad_norm": 2.7320690155029297,
      "learning_rate": 4.567669348486551e-05,
      "loss": 1.5379,
      "step": 170700
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.35155987739563,
      "learning_rate": 4.557123142617873e-05,
      "loss": 1.5304,
      "step": 170800
    },
    {
      "epoch": 3.42,
      "grad_norm": 3.7214488983154297,
      "learning_rate": 4.5465855317946846e-05,
      "loss": 1.5628,
      "step": 170900
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.8719890117645264,
      "learning_rate": 4.5360565326573104e-05,
      "loss": 1.5441,
      "step": 171000
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.4697117805480957,
      "learning_rate": 4.525536161832482e-05,
      "loss": 1.551,
      "step": 171100
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.7580745220184326,
      "learning_rate": 4.515024435933299e-05,
      "loss": 1.5339,
      "step": 171200
    },
    {
      "epoch": 3.43,
      "grad_norm": 2.5229997634887695,
      "learning_rate": 4.504521371559207e-05,
      "loss": 1.539,
      "step": 171300
    },
    {
      "epoch": 3.43,
      "grad_norm": 2.809619426727295,
      "learning_rate": 4.494026985295987e-05,
      "loss": 1.5441,
      "step": 171400
    },
    {
      "epoch": 3.43,
      "grad_norm": 2.4175119400024414,
      "learning_rate": 4.483541293715698e-05,
      "loss": 1.5423,
      "step": 171500
    },
    {
      "epoch": 3.43,
      "grad_norm": 2.9534473419189453,
      "learning_rate": 4.473064313376687e-05,
      "loss": 1.5374,
      "step": 171600
    },
    {
      "epoch": 3.43,
      "grad_norm": 2.797468900680542,
      "learning_rate": 4.4625960608235304e-05,
      "loss": 1.5591,
      "step": 171700
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.755629539489746,
      "learning_rate": 4.4521365525870276e-05,
      "loss": 1.5504,
      "step": 171800
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.960263252258301,
      "learning_rate": 4.441685805184173e-05,
      "loss": 1.5396,
      "step": 171900
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.3087375164031982,
      "learning_rate": 4.431243835118124e-05,
      "loss": 1.5492,
      "step": 172000
    },
    {
      "epoch": 3.44,
      "grad_norm": 5.997550010681152,
      "learning_rate": 4.420810658878169e-05,
      "loss": 1.5442,
      "step": 172100
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.9918596744537354,
      "learning_rate": 4.4103862929397265e-05,
      "loss": 1.5312,
      "step": 172200
    },
    {
      "epoch": 3.45,
      "grad_norm": 3.183151960372925,
      "learning_rate": 4.3999707537642865e-05,
      "loss": 1.5551,
      "step": 172300
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.982882261276245,
      "learning_rate": 4.389564057799414e-05,
      "loss": 1.5449,
      "step": 172400
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.930826187133789,
      "learning_rate": 4.379166221478697e-05,
      "loss": 1.5412,
      "step": 172500
    },
    {
      "epoch": 3.45,
      "grad_norm": 3.0964081287384033,
      "learning_rate": 4.368777261221737e-05,
      "loss": 1.5645,
      "step": 172600
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.9644341468811035,
      "learning_rate": 4.3583971934341263e-05,
      "loss": 1.541,
      "step": 172700
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.9311628341674805,
      "learning_rate": 4.348026034507402e-05,
      "loss": 1.5529,
      "step": 172800
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.7384660243988037,
      "learning_rate": 4.337663800819046e-05,
      "loss": 1.5465,
      "step": 172900
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.7379252910614014,
      "learning_rate": 4.327310508732437e-05,
      "loss": 1.5375,
      "step": 173000
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.7521986961364746,
      "learning_rate": 4.316966174596834e-05,
      "loss": 1.5795,
      "step": 173100
    },
    {
      "epoch": 3.46,
      "grad_norm": 5.9878249168396,
      "learning_rate": 4.306630814747358e-05,
      "loss": 1.5572,
      "step": 173200
    },
    {
      "epoch": 3.47,
      "grad_norm": 2.594768524169922,
      "learning_rate": 4.296304445504945e-05,
      "loss": 1.5343,
      "step": 173300
    },
    {
      "epoch": 3.47,
      "grad_norm": 2.488809108734131,
      "learning_rate": 4.28598708317635e-05,
      "loss": 1.5619,
      "step": 173400
    },
    {
      "epoch": 3.47,
      "grad_norm": 3.245906352996826,
      "learning_rate": 4.2756787440540936e-05,
      "loss": 1.5579,
      "step": 173500
    },
    {
      "epoch": 3.47,
      "grad_norm": 3.1339025497436523,
      "learning_rate": 4.265379444416445e-05,
      "loss": 1.5416,
      "step": 173600
    },
    {
      "epoch": 3.47,
      "grad_norm": 2.673191547393799,
      "learning_rate": 4.2550892005274126e-05,
      "loss": 1.5486,
      "step": 173700
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.4221978187561035,
      "learning_rate": 4.244808028636689e-05,
      "loss": 1.5259,
      "step": 173800
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.917160749435425,
      "learning_rate": 4.234535944979653e-05,
      "loss": 1.5289,
      "step": 173900
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.4988110065460205,
      "learning_rate": 4.224272965777326e-05,
      "loss": 1.5376,
      "step": 174000
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.5524532794952393,
      "learning_rate": 4.214019107236348e-05,
      "loss": 1.53,
      "step": 174100
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.9414281845092773,
      "learning_rate": 4.203774385548969e-05,
      "loss": 1.5488,
      "step": 174200
    },
    {
      "epoch": 3.49,
      "grad_norm": 2.6182003021240234,
      "learning_rate": 4.1935388168929946e-05,
      "loss": 1.5276,
      "step": 174300
    },
    {
      "epoch": 3.49,
      "grad_norm": 2.447549343109131,
      "learning_rate": 4.183312417431793e-05,
      "loss": 1.5322,
      "step": 174400
    },
    {
      "epoch": 3.49,
      "grad_norm": 2.7533297538757324,
      "learning_rate": 4.173095203314241e-05,
      "loss": 1.5362,
      "step": 174500
    },
    {
      "epoch": 3.49,
      "grad_norm": 2.776110887527466,
      "learning_rate": 4.16288719067471e-05,
      "loss": 1.5489,
      "step": 174600
    },
    {
      "epoch": 3.49,
      "grad_norm": 3.1509664058685303,
      "learning_rate": 4.1526883956330546e-05,
      "loss": 1.5496,
      "step": 174700
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.9190666675567627,
      "learning_rate": 4.1424988342945545e-05,
      "loss": 1.5514,
      "step": 174800
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.8891849517822266,
      "learning_rate": 4.132318522749927e-05,
      "loss": 1.5461,
      "step": 174900
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.828549385070801,
      "learning_rate": 4.12214747707527e-05,
      "loss": 1.5499,
      "step": 175000
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.4776723384857178,
      "learning_rate": 4.1119857133320473e-05,
      "loss": 1.5121,
      "step": 175100
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.711013078689575,
      "learning_rate": 4.1018332475670793e-05,
      "loss": 1.5445,
      "step": 175200
    },
    {
      "epoch": 3.51,
      "grad_norm": 2.8615200519561768,
      "learning_rate": 4.0916900958124924e-05,
      "loss": 1.5521,
      "step": 175300
    },
    {
      "epoch": 3.51,
      "grad_norm": 2.752736806869507,
      "learning_rate": 4.081556274085704e-05,
      "loss": 1.5335,
      "step": 175400
    },
    {
      "epoch": 3.51,
      "grad_norm": 2.7201554775238037,
      "learning_rate": 4.071431798389408e-05,
      "loss": 1.5454,
      "step": 175500
    },
    {
      "epoch": 3.51,
      "grad_norm": 4.890144348144531,
      "learning_rate": 4.0613166847115306e-05,
      "loss": 1.5455,
      "step": 175600
    },
    {
      "epoch": 3.51,
      "grad_norm": 2.9976706504821777,
      "learning_rate": 4.051210949025216e-05,
      "loss": 1.5214,
      "step": 175700
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.4977846145629883,
      "learning_rate": 4.041114607288799e-05,
      "loss": 1.537,
      "step": 175800
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.02236270904541,
      "learning_rate": 4.0310276754457844e-05,
      "loss": 1.5492,
      "step": 175900
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.863584280014038,
      "learning_rate": 4.020950169424815e-05,
      "loss": 1.5395,
      "step": 176000
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.962568521499634,
      "learning_rate": 4.010882105139643e-05,
      "loss": 1.5408,
      "step": 176100
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.8980295658111572,
      "learning_rate": 4.0008234984891226e-05,
      "loss": 1.5533,
      "step": 176200
    },
    {
      "epoch": 3.53,
      "grad_norm": 2.8360466957092285,
      "learning_rate": 3.9907743653571606e-05,
      "loss": 1.542,
      "step": 176300
    },
    {
      "epoch": 3.53,
      "grad_norm": 2.4216434955596924,
      "learning_rate": 3.9807347216127175e-05,
      "loss": 1.5302,
      "step": 176400
    },
    {
      "epoch": 3.53,
      "grad_norm": 2.704735040664673,
      "learning_rate": 3.9707045831097555e-05,
      "loss": 1.5572,
      "step": 176500
    },
    {
      "epoch": 3.53,
      "grad_norm": 4.768260478973389,
      "learning_rate": 3.960683965687232e-05,
      "loss": 1.5436,
      "step": 176600
    },
    {
      "epoch": 3.53,
      "grad_norm": 3.048431158065796,
      "learning_rate": 3.9506728851690736e-05,
      "loss": 1.558,
      "step": 176700
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.756798505783081,
      "learning_rate": 3.940671357364137e-05,
      "loss": 1.5374,
      "step": 176800
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.758929491043091,
      "learning_rate": 3.930679398066208e-05,
      "loss": 1.5479,
      "step": 176900
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.9173896312713623,
      "learning_rate": 3.920697023053949e-05,
      "loss": 1.5498,
      "step": 177000
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.625699996948242,
      "learning_rate": 3.9107242480908904e-05,
      "loss": 1.5512,
      "step": 177100
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.8058533668518066,
      "learning_rate": 3.900761088925411e-05,
      "loss": 1.534,
      "step": 177200
    },
    {
      "epoch": 3.55,
      "grad_norm": 3.3523826599121094,
      "learning_rate": 3.890807561290693e-05,
      "loss": 1.5241,
      "step": 177300
    },
    {
      "epoch": 3.55,
      "grad_norm": 2.8633196353912354,
      "learning_rate": 3.8808636809047204e-05,
      "loss": 1.5134,
      "step": 177400
    },
    {
      "epoch": 3.55,
      "grad_norm": 2.551020860671997,
      "learning_rate": 3.8709294634702376e-05,
      "loss": 1.529,
      "step": 177500
    },
    {
      "epoch": 3.55,
      "grad_norm": 3.456422805786133,
      "learning_rate": 3.8610049246747235e-05,
      "loss": 1.5145,
      "step": 177600
    },
    {
      "epoch": 3.55,
      "grad_norm": 2.717649459838867,
      "learning_rate": 3.851090080190387e-05,
      "loss": 1.5325,
      "step": 177700
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.693450450897217,
      "learning_rate": 3.841184945674114e-05,
      "loss": 1.5391,
      "step": 177800
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.64546275138855,
      "learning_rate": 3.8312895367674725e-05,
      "loss": 1.5605,
      "step": 177900
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.346815824508667,
      "learning_rate": 3.821403869096658e-05,
      "loss": 1.5251,
      "step": 178000
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.921006441116333,
      "learning_rate": 3.8115279582724874e-05,
      "loss": 1.5424,
      "step": 178100
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.757478713989258,
      "learning_rate": 3.8016618198903774e-05,
      "loss": 1.5348,
      "step": 178200
    },
    {
      "epoch": 3.57,
      "grad_norm": 2.6544301509857178,
      "learning_rate": 3.7918054695303054e-05,
      "loss": 1.5191,
      "step": 178300
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.066553831100464,
      "learning_rate": 3.7819589227567886e-05,
      "loss": 1.5289,
      "step": 178400
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.2161455154418945,
      "learning_rate": 3.7721221951188765e-05,
      "loss": 1.5044,
      "step": 178500
    },
    {
      "epoch": 3.57,
      "grad_norm": 3.094320774078369,
      "learning_rate": 3.7622953021500976e-05,
      "loss": 1.5415,
      "step": 178600
    },
    {
      "epoch": 3.57,
      "grad_norm": 2.7013344764709473,
      "learning_rate": 3.7524782593684635e-05,
      "loss": 1.5495,
      "step": 178700
    },
    {
      "epoch": 3.58,
      "grad_norm": 3.3412129878997803,
      "learning_rate": 3.742671082276423e-05,
      "loss": 1.5471,
      "step": 178800
    },
    {
      "epoch": 3.58,
      "grad_norm": 2.627272129058838,
      "learning_rate": 3.732873786360842e-05,
      "loss": 1.5347,
      "step": 178900
    },
    {
      "epoch": 3.58,
      "grad_norm": 2.754101514816284,
      "learning_rate": 3.7230863870929964e-05,
      "loss": 1.5378,
      "step": 179000
    },
    {
      "epoch": 3.58,
      "grad_norm": 2.9911065101623535,
      "learning_rate": 3.7133088999285174e-05,
      "loss": 1.5291,
      "step": 179100
    },
    {
      "epoch": 3.58,
      "grad_norm": 3.1157188415527344,
      "learning_rate": 3.7035413403073994e-05,
      "loss": 1.5061,
      "step": 179200
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.505725622177124,
      "learning_rate": 3.69378372365395e-05,
      "loss": 1.5246,
      "step": 179300
    },
    {
      "epoch": 3.59,
      "grad_norm": 2.8253285884857178,
      "learning_rate": 3.6840360653767714e-05,
      "loss": 1.5348,
      "step": 179400
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.154512643814087,
      "learning_rate": 3.674298380868756e-05,
      "loss": 1.5583,
      "step": 179500
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.132300853729248,
      "learning_rate": 3.66457068550703e-05,
      "loss": 1.5434,
      "step": 179600
    },
    {
      "epoch": 3.59,
      "grad_norm": 3.1491892337799072,
      "learning_rate": 3.654852994652956e-05,
      "loss": 1.5614,
      "step": 179700
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.1452858448028564,
      "learning_rate": 3.645145323652094e-05,
      "loss": 1.5352,
      "step": 179800
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.159954071044922,
      "learning_rate": 3.635447687834177e-05,
      "loss": 1.5387,
      "step": 179900
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.0785815715789795,
      "learning_rate": 3.6257601025131026e-05,
      "loss": 1.5473,
      "step": 180000
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.083461046218872,
      "learning_rate": 3.616082582986887e-05,
      "loss": 1.5258,
      "step": 180100
    },
    {
      "epoch": 3.6,
      "grad_norm": 2.5689356327056885,
      "learning_rate": 3.6064151445376516e-05,
      "loss": 1.5366,
      "step": 180200
    },
    {
      "epoch": 3.61,
      "grad_norm": 3.233084201812744,
      "learning_rate": 3.596757802431607e-05,
      "loss": 1.5088,
      "step": 180300
    },
    {
      "epoch": 3.61,
      "grad_norm": 2.868760108947754,
      "learning_rate": 3.587110571919011e-05,
      "loss": 1.5148,
      "step": 180400
    },
    {
      "epoch": 3.61,
      "grad_norm": 2.9900155067443848,
      "learning_rate": 3.577473468234156e-05,
      "loss": 1.5132,
      "step": 180500
    },
    {
      "epoch": 3.61,
      "grad_norm": 2.8891890048980713,
      "learning_rate": 3.5678465065953494e-05,
      "loss": 1.5353,
      "step": 180600
    },
    {
      "epoch": 3.61,
      "grad_norm": 2.7758493423461914,
      "learning_rate": 3.558229702204874e-05,
      "loss": 1.5331,
      "step": 180700
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.3333990573883057,
      "learning_rate": 3.5486230702489764e-05,
      "loss": 1.5136,
      "step": 180800
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.5365209579467773,
      "learning_rate": 3.539026625897838e-05,
      "loss": 1.5394,
      "step": 180900
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.9598679542541504,
      "learning_rate": 3.52944038430556e-05,
      "loss": 1.519,
      "step": 181000
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.308379650115967,
      "learning_rate": 3.519864360610119e-05,
      "loss": 1.5187,
      "step": 181100
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.7059662342071533,
      "learning_rate": 3.510298569933371e-05,
      "loss": 1.5466,
      "step": 181200
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.335528612136841,
      "learning_rate": 3.500743027381003e-05,
      "loss": 1.5298,
      "step": 181300
    },
    {
      "epoch": 3.63,
      "grad_norm": 8.957305908203125,
      "learning_rate": 3.491197748042515e-05,
      "loss": 1.5427,
      "step": 181400
    },
    {
      "epoch": 3.63,
      "grad_norm": 3.1017725467681885,
      "learning_rate": 3.481662746991214e-05,
      "loss": 1.5502,
      "step": 181500
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.6549108028411865,
      "learning_rate": 3.472138039284163e-05,
      "loss": 1.5177,
      "step": 181600
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.88808274269104,
      "learning_rate": 3.462623639962179e-05,
      "loss": 1.5357,
      "step": 181700
    },
    {
      "epoch": 3.64,
      "grad_norm": 3.4159207344055176,
      "learning_rate": 3.453119564049797e-05,
      "loss": 1.5574,
      "step": 181800
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.6705427169799805,
      "learning_rate": 3.4436258265552445e-05,
      "loss": 1.5403,
      "step": 181900
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.7576143741607666,
      "learning_rate": 3.4341424424704375e-05,
      "loss": 1.5378,
      "step": 182000
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.786623477935791,
      "learning_rate": 3.424669426770926e-05,
      "loss": 1.5398,
      "step": 182100
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.6504335403442383,
      "learning_rate": 3.415206794415901e-05,
      "loss": 1.5292,
      "step": 182200
    },
    {
      "epoch": 3.65,
      "grad_norm": 3.464529037475586,
      "learning_rate": 3.405754560348148e-05,
      "loss": 1.5352,
      "step": 182300
    },
    {
      "epoch": 3.65,
      "grad_norm": 2.5490307807922363,
      "learning_rate": 3.396312739494032e-05,
      "loss": 1.5289,
      "step": 182400
    },
    {
      "epoch": 3.65,
      "grad_norm": 2.884472608566284,
      "learning_rate": 3.386881346763483e-05,
      "loss": 1.5238,
      "step": 182500
    },
    {
      "epoch": 3.65,
      "grad_norm": 2.6739625930786133,
      "learning_rate": 3.377460397049951e-05,
      "loss": 1.5305,
      "step": 182600
    },
    {
      "epoch": 3.65,
      "grad_norm": 2.5945956707000732,
      "learning_rate": 3.368049905230407e-05,
      "loss": 1.5483,
      "step": 182700
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.4795520305633545,
      "learning_rate": 3.3586498861653e-05,
      "loss": 1.5581,
      "step": 182800
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.823237180709839,
      "learning_rate": 3.3492603546985403e-05,
      "loss": 1.5478,
      "step": 182900
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.509896993637085,
      "learning_rate": 3.339881325657484e-05,
      "loss": 1.5461,
      "step": 183000
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.6589086055755615,
      "learning_rate": 3.330512813852895e-05,
      "loss": 1.53,
      "step": 183100
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.145336151123047,
      "learning_rate": 3.3211548340789364e-05,
      "loss": 1.5188,
      "step": 183200
    },
    {
      "epoch": 3.67,
      "grad_norm": 2.9278383255004883,
      "learning_rate": 3.311807401113133e-05,
      "loss": 1.5381,
      "step": 183300
    },
    {
      "epoch": 3.67,
      "grad_norm": 3.0506887435913086,
      "learning_rate": 3.302470529716354e-05,
      "loss": 1.524,
      "step": 183400
    },
    {
      "epoch": 3.67,
      "grad_norm": 2.9094719886779785,
      "learning_rate": 3.2931442346328004e-05,
      "loss": 1.5354,
      "step": 183500
    },
    {
      "epoch": 3.67,
      "grad_norm": 2.584855318069458,
      "learning_rate": 3.2838285305899585e-05,
      "loss": 1.508,
      "step": 183600
    },
    {
      "epoch": 3.67,
      "grad_norm": 2.651608467102051,
      "learning_rate": 3.274523432298603e-05,
      "loss": 1.5364,
      "step": 183700
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.346896171569824,
      "learning_rate": 3.2652289544527506e-05,
      "loss": 1.5328,
      "step": 183800
    },
    {
      "epoch": 3.68,
      "grad_norm": 2.7879562377929688,
      "learning_rate": 3.255945111729648e-05,
      "loss": 1.5356,
      "step": 183900
    },
    {
      "epoch": 3.68,
      "grad_norm": 2.93381929397583,
      "learning_rate": 3.246671918789755e-05,
      "loss": 1.5572,
      "step": 184000
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.155839681625366,
      "learning_rate": 3.237409390276706e-05,
      "loss": 1.5377,
      "step": 184100
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.2653236389160156,
      "learning_rate": 3.2281575408173005e-05,
      "loss": 1.5473,
      "step": 184200
    },
    {
      "epoch": 3.69,
      "grad_norm": 3.2314133644104004,
      "learning_rate": 3.218916385021471e-05,
      "loss": 1.4972,
      "step": 184300
    },
    {
      "epoch": 3.69,
      "grad_norm": 2.5385043621063232,
      "learning_rate": 3.2096859374822585e-05,
      "loss": 1.5011,
      "step": 184400
    },
    {
      "epoch": 3.69,
      "grad_norm": 2.723593235015869,
      "learning_rate": 3.200466212775808e-05,
      "loss": 1.5243,
      "step": 184500
    },
    {
      "epoch": 3.69,
      "grad_norm": 2.4388394355773926,
      "learning_rate": 3.1912572254613184e-05,
      "loss": 1.5339,
      "step": 184600
    },
    {
      "epoch": 3.69,
      "grad_norm": 2.565457344055176,
      "learning_rate": 3.182058990081036e-05,
      "loss": 1.5283,
      "step": 184700
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.675748825073242,
      "learning_rate": 3.172871521160236e-05,
      "loss": 1.5066,
      "step": 184800
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.4118850231170654,
      "learning_rate": 3.163694833207181e-05,
      "loss": 1.5349,
      "step": 184900
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.4986655712127686,
      "learning_rate": 3.154528940713113e-05,
      "loss": 1.5308,
      "step": 185000
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.6983978748321533,
      "learning_rate": 3.1453738581522315e-05,
      "loss": 1.5356,
      "step": 185100
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.7979073524475098,
      "learning_rate": 3.136229599981661e-05,
      "loss": 1.5365,
      "step": 185200
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.984976053237915,
      "learning_rate": 3.127096180641428e-05,
      "loss": 1.5278,
      "step": 185300
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.87322998046875,
      "learning_rate": 3.117973614554456e-05,
      "loss": 1.5064,
      "step": 185400
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.7149384021759033,
      "learning_rate": 3.108861916126518e-05,
      "loss": 1.5398,
      "step": 185500
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.8665401935577393,
      "learning_rate": 3.099761099746229e-05,
      "loss": 1.5508,
      "step": 185600
    },
    {
      "epoch": 3.71,
      "grad_norm": 3.7477545738220215,
      "learning_rate": 3.0906711797850186e-05,
      "loss": 1.5416,
      "step": 185700
    },
    {
      "epoch": 3.72,
      "grad_norm": 2.5211875438690186,
      "learning_rate": 3.0815921705971165e-05,
      "loss": 1.544,
      "step": 185800
    },
    {
      "epoch": 3.72,
      "grad_norm": 2.7078397274017334,
      "learning_rate": 3.0725240865195114e-05,
      "loss": 1.5193,
      "step": 185900
    },
    {
      "epoch": 3.72,
      "grad_norm": 2.4688000679016113,
      "learning_rate": 3.063466941871952e-05,
      "loss": 1.5064,
      "step": 186000
    },
    {
      "epoch": 3.72,
      "grad_norm": 2.8394935131073,
      "learning_rate": 3.0544207509569035e-05,
      "loss": 1.5273,
      "step": 186100
    },
    {
      "epoch": 3.72,
      "grad_norm": 2.309835910797119,
      "learning_rate": 3.0453855280595324e-05,
      "loss": 1.5449,
      "step": 186200
    },
    {
      "epoch": 3.73,
      "grad_norm": 3.029649496078491,
      "learning_rate": 3.0363612874476945e-05,
      "loss": 1.5143,
      "step": 186300
    },
    {
      "epoch": 3.73,
      "grad_norm": 2.461505174636841,
      "learning_rate": 3.0273480433718927e-05,
      "loss": 1.5176,
      "step": 186400
    },
    {
      "epoch": 3.73,
      "grad_norm": 3.102325916290283,
      "learning_rate": 3.018345810065275e-05,
      "loss": 1.5332,
      "step": 186500
    },
    {
      "epoch": 3.73,
      "grad_norm": 2.4489376544952393,
      "learning_rate": 3.0093546017435938e-05,
      "loss": 1.5203,
      "step": 186600
    },
    {
      "epoch": 3.73,
      "grad_norm": 2.3945624828338623,
      "learning_rate": 3.000374432605191e-05,
      "loss": 1.5211,
      "step": 186700
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.885286569595337,
      "learning_rate": 2.991405316830985e-05,
      "loss": 1.5252,
      "step": 186800
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.39241623878479,
      "learning_rate": 2.9824472685844284e-05,
      "loss": 1.5317,
      "step": 186900
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.7684295177459717,
      "learning_rate": 2.9735003020115092e-05,
      "loss": 1.5277,
      "step": 187000
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.8188273906707764,
      "learning_rate": 2.964564431240704e-05,
      "loss": 1.5663,
      "step": 187100
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.9700074195861816,
      "learning_rate": 2.9556396703829704e-05,
      "loss": 1.5255,
      "step": 187200
    },
    {
      "epoch": 3.75,
      "grad_norm": 3.098564624786377,
      "learning_rate": 2.9467260335317303e-05,
      "loss": 1.5054,
      "step": 187300
    },
    {
      "epoch": 3.75,
      "grad_norm": 2.7142391204833984,
      "learning_rate": 2.937823534762827e-05,
      "loss": 1.526,
      "step": 187400
    },
    {
      "epoch": 3.75,
      "grad_norm": 2.6513421535491943,
      "learning_rate": 2.9289321881345254e-05,
      "loss": 1.5221,
      "step": 187500
    },
    {
      "epoch": 3.75,
      "grad_norm": 2.5588741302490234,
      "learning_rate": 2.920052007687475e-05,
      "loss": 1.5358,
      "step": 187600
    },
    {
      "epoch": 3.75,
      "grad_norm": 2.8353323936462402,
      "learning_rate": 2.9111830074446878e-05,
      "loss": 1.5448,
      "step": 187700
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.737353801727295,
      "learning_rate": 2.9023252014115332e-05,
      "loss": 1.5437,
      "step": 187800
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.245579242706299,
      "learning_rate": 2.893478603575689e-05,
      "loss": 1.5249,
      "step": 187900
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.45279598236084,
      "learning_rate": 2.8846432279071467e-05,
      "loss": 1.5296,
      "step": 188000
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.9756622314453125,
      "learning_rate": 2.875819088358169e-05,
      "loss": 1.4862,
      "step": 188100
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.7847931385040283,
      "learning_rate": 2.8670061988632714e-05,
      "loss": 1.5105,
      "step": 188200
    },
    {
      "epoch": 3.77,
      "grad_norm": 3.0660507678985596,
      "learning_rate": 2.858204573339217e-05,
      "loss": 1.5442,
      "step": 188300
    },
    {
      "epoch": 3.77,
      "grad_norm": 3.0423338413238525,
      "learning_rate": 2.8494142256849677e-05,
      "loss": 1.5254,
      "step": 188400
    },
    {
      "epoch": 3.77,
      "grad_norm": 2.387704610824585,
      "learning_rate": 2.840635169781688e-05,
      "loss": 1.5136,
      "step": 188500
    },
    {
      "epoch": 3.77,
      "grad_norm": 2.983213424682617,
      "learning_rate": 2.831867419492703e-05,
      "loss": 1.5282,
      "step": 188600
    },
    {
      "epoch": 3.77,
      "grad_norm": 3.2542569637298584,
      "learning_rate": 2.8231109886634834e-05,
      "loss": 1.5383,
      "step": 188700
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.723567247390747,
      "learning_rate": 2.814365891121634e-05,
      "loss": 1.544,
      "step": 188800
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.7901697158813477,
      "learning_rate": 2.8056321406768537e-05,
      "loss": 1.5719,
      "step": 188900
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.464909791946411,
      "learning_rate": 2.7969097511209308e-05,
      "loss": 1.5494,
      "step": 189000
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.7214508056640625,
      "learning_rate": 2.788198736227706e-05,
      "loss": 1.5234,
      "step": 189100
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.7732954025268555,
      "learning_rate": 2.77949910975306e-05,
      "loss": 1.5136,
      "step": 189200
    },
    {
      "epoch": 3.79,
      "grad_norm": 11.760047912597656,
      "learning_rate": 2.7708108854348935e-05,
      "loss": 1.5233,
      "step": 189300
    },
    {
      "epoch": 3.79,
      "grad_norm": 2.494019031524658,
      "learning_rate": 2.762134076993094e-05,
      "loss": 1.5324,
      "step": 189400
    },
    {
      "epoch": 3.79,
      "grad_norm": 2.7744243144989014,
      "learning_rate": 2.753468698129533e-05,
      "loss": 1.549,
      "step": 189500
    },
    {
      "epoch": 3.79,
      "grad_norm": 3.305800199508667,
      "learning_rate": 2.7448147625280217e-05,
      "loss": 1.5559,
      "step": 189600
    },
    {
      "epoch": 3.79,
      "grad_norm": 3.4270875453948975,
      "learning_rate": 2.736172283854308e-05,
      "loss": 1.5476,
      "step": 189700
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.296250343322754,
      "learning_rate": 2.7275412757560416e-05,
      "loss": 1.5313,
      "step": 189800
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.5851283073425293,
      "learning_rate": 2.7189217518627662e-05,
      "loss": 1.5286,
      "step": 189900
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.5690696239471436,
      "learning_rate": 2.7103137257858868e-05,
      "loss": 1.5083,
      "step": 190000
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.9826903343200684,
      "learning_rate": 2.701717211118646e-05,
      "loss": 1.521,
      "step": 190100
    },
    {
      "epoch": 3.8,
      "grad_norm": 3.007981061935425,
      "learning_rate": 2.693132221436122e-05,
      "loss": 1.54,
      "step": 190200
    },
    {
      "epoch": 3.81,
      "grad_norm": 3.1039867401123047,
      "learning_rate": 2.6845587702951813e-05,
      "loss": 1.5296,
      "step": 190300
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.8090503215789795,
      "learning_rate": 2.6759968712344697e-05,
      "loss": 1.524,
      "step": 190400
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.934752941131592,
      "learning_rate": 2.6674465377744017e-05,
      "loss": 1.5306,
      "step": 190500
    },
    {
      "epoch": 3.81,
      "grad_norm": 3.1148393154144287,
      "learning_rate": 2.6589077834171172e-05,
      "loss": 1.5529,
      "step": 190600
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.7687501907348633,
      "learning_rate": 2.6503806216464723e-05,
      "loss": 1.5272,
      "step": 190700
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.7447574138641357,
      "learning_rate": 2.6418650659280253e-05,
      "loss": 1.52,
      "step": 190800
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.950653553009033,
      "learning_rate": 2.6333611297089977e-05,
      "loss": 1.5111,
      "step": 190900
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.4755964279174805,
      "learning_rate": 2.624868826418262e-05,
      "loss": 1.5243,
      "step": 191000
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.358074903488159,
      "learning_rate": 2.6163881694663318e-05,
      "loss": 1.5157,
      "step": 191100
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.425814390182495,
      "learning_rate": 2.6079191722453155e-05,
      "loss": 1.5262,
      "step": 191200
    },
    {
      "epoch": 3.83,
      "grad_norm": 2.6391894817352295,
      "learning_rate": 2.5994618481289212e-05,
      "loss": 1.5519,
      "step": 191300
    },
    {
      "epoch": 3.83,
      "grad_norm": 2.910924196243286,
      "learning_rate": 2.5910162104724146e-05,
      "loss": 1.5265,
      "step": 191400
    },
    {
      "epoch": 3.83,
      "grad_norm": 2.5422210693359375,
      "learning_rate": 2.582582272612609e-05,
      "loss": 1.5219,
      "step": 191500
    },
    {
      "epoch": 3.83,
      "grad_norm": 2.924769878387451,
      "learning_rate": 2.5741600478678472e-05,
      "loss": 1.5427,
      "step": 191600
    },
    {
      "epoch": 3.83,
      "grad_norm": 2.9306609630584717,
      "learning_rate": 2.565749549537969e-05,
      "loss": 1.5103,
      "step": 191700
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.96408748626709,
      "learning_rate": 2.5573507909043014e-05,
      "loss": 1.5343,
      "step": 191800
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.4642183780670166,
      "learning_rate": 2.548963785229631e-05,
      "loss": 1.5302,
      "step": 191900
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.269968271255493,
      "learning_rate": 2.540588545758179e-05,
      "loss": 1.522,
      "step": 192000
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.609809637069702,
      "learning_rate": 2.5322250857155994e-05,
      "loss": 1.5439,
      "step": 192100
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.569199562072754,
      "learning_rate": 2.5238734183089308e-05,
      "loss": 1.5086,
      "step": 192200
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.9278626441955566,
      "learning_rate": 2.5155335567266014e-05,
      "loss": 1.5076,
      "step": 192300
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.902665853500366,
      "learning_rate": 2.5072055141383877e-05,
      "loss": 1.5559,
      "step": 192400
    },
    {
      "epoch": 3.85,
      "grad_norm": 3.3111255168914795,
      "learning_rate": 2.4988893036954043e-05,
      "loss": 1.5489,
      "step": 192500
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.5375468730926514,
      "learning_rate": 2.4905849385300883e-05,
      "loss": 1.5192,
      "step": 192600
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.8635904788970947,
      "learning_rate": 2.482292431756158e-05,
      "loss": 1.5114,
      "step": 192700
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.987138271331787,
      "learning_rate": 2.4740117964686217e-05,
      "loss": 1.5243,
      "step": 192800
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.3803319931030273,
      "learning_rate": 2.465743045743728e-05,
      "loss": 1.5114,
      "step": 192900
    },
    {
      "epoch": 3.86,
      "grad_norm": 3.077305793762207,
      "learning_rate": 2.4574861926389615e-05,
      "loss": 1.5077,
      "step": 193000
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.989102840423584,
      "learning_rate": 2.449241250193025e-05,
      "loss": 1.5286,
      "step": 193100
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.687075614929199,
      "learning_rate": 2.4410082314258032e-05,
      "loss": 1.5291,
      "step": 193200
    },
    {
      "epoch": 3.87,
      "grad_norm": 3.181117296218872,
      "learning_rate": 2.4327871493383612e-05,
      "loss": 1.5298,
      "step": 193300
    },
    {
      "epoch": 3.87,
      "grad_norm": 2.914052963256836,
      "learning_rate": 2.4245780169129084e-05,
      "loss": 1.5165,
      "step": 193400
    },
    {
      "epoch": 3.87,
      "grad_norm": 2.545685052871704,
      "learning_rate": 2.4163808471127812e-05,
      "loss": 1.5419,
      "step": 193500
    },
    {
      "epoch": 3.87,
      "grad_norm": 3.065004825592041,
      "learning_rate": 2.4081956528824357e-05,
      "loss": 1.5226,
      "step": 193600
    },
    {
      "epoch": 3.87,
      "grad_norm": 2.379718780517578,
      "learning_rate": 2.4000224471474043e-05,
      "loss": 1.511,
      "step": 193700
    },
    {
      "epoch": 3.88,
      "grad_norm": 3.2787678241729736,
      "learning_rate": 2.3918612428143016e-05,
      "loss": 1.5072,
      "step": 193800
    },
    {
      "epoch": 3.88,
      "grad_norm": 3.131042242050171,
      "learning_rate": 2.38371205277078e-05,
      "loss": 1.5358,
      "step": 193900
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.6987438201904297,
      "learning_rate": 2.37557488988552e-05,
      "loss": 1.534,
      "step": 194000
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.8576929569244385,
      "learning_rate": 2.3674497670082185e-05,
      "loss": 1.5069,
      "step": 194100
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.8117029666900635,
      "learning_rate": 2.359336696969546e-05,
      "loss": 1.5127,
      "step": 194200
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.8551909923553467,
      "learning_rate": 2.3512356925811563e-05,
      "loss": 1.5318,
      "step": 194300
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.247455358505249,
      "learning_rate": 2.3431467666356355e-05,
      "loss": 1.5011,
      "step": 194400
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.40299916267395,
      "learning_rate": 2.3350699319065026e-05,
      "loss": 1.5319,
      "step": 194500
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.788484811782837,
      "learning_rate": 2.32700520114818e-05,
      "loss": 1.5147,
      "step": 194600
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.394214630126953,
      "learning_rate": 2.318952587095984e-05,
      "loss": 1.5263,
      "step": 194700
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.7571210861206055,
      "learning_rate": 2.3109121024660872e-05,
      "loss": 1.5254,
      "step": 194800
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.0022342205047607,
      "learning_rate": 2.3028837599555107e-05,
      "loss": 1.5325,
      "step": 194900
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.0048773288726807,
      "learning_rate": 2.2948675722421086e-05,
      "loss": 1.5239,
      "step": 195000
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.9030375480651855,
      "learning_rate": 2.286863551984533e-05,
      "loss": 1.5094,
      "step": 195100
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.2551610469818115,
      "learning_rate": 2.2788717118222202e-05,
      "loss": 1.5246,
      "step": 195200
    },
    {
      "epoch": 3.91,
      "grad_norm": 3.433393955230713,
      "learning_rate": 2.270892064375384e-05,
      "loss": 1.5181,
      "step": 195300
    },
    {
      "epoch": 3.91,
      "grad_norm": 2.7404446601867676,
      "learning_rate": 2.262924622244973e-05,
      "loss": 1.5265,
      "step": 195400
    },
    {
      "epoch": 3.91,
      "grad_norm": 3.1462132930755615,
      "learning_rate": 2.254969398012663e-05,
      "loss": 1.5093,
      "step": 195500
    },
    {
      "epoch": 3.91,
      "grad_norm": 2.922959089279175,
      "learning_rate": 2.247026404240845e-05,
      "loss": 1.5094,
      "step": 195600
    },
    {
      "epoch": 3.91,
      "grad_norm": 3.143785238265991,
      "learning_rate": 2.2390956534725848e-05,
      "loss": 1.5371,
      "step": 195700
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.17812180519104,
      "learning_rate": 2.2311771582316255e-05,
      "loss": 1.5303,
      "step": 195800
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.7819454669952393,
      "learning_rate": 2.22327093102235e-05,
      "loss": 1.5306,
      "step": 195900
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.5626466274261475,
      "learning_rate": 2.2153769843297667e-05,
      "loss": 1.5114,
      "step": 196000
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.600099802017212,
      "learning_rate": 2.2074953306195e-05,
      "loss": 1.5285,
      "step": 196100
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.6347668170928955,
      "learning_rate": 2.199625982337753e-05,
      "loss": 1.5351,
      "step": 196200
    },
    {
      "epoch": 3.93,
      "grad_norm": 2.9754018783569336,
      "learning_rate": 2.191768951911305e-05,
      "loss": 1.5391,
      "step": 196300
    },
    {
      "epoch": 3.93,
      "grad_norm": 2.5034983158111572,
      "learning_rate": 2.1839242517474766e-05,
      "loss": 1.5326,
      "step": 196400
    },
    {
      "epoch": 3.93,
      "grad_norm": 2.365805149078369,
      "learning_rate": 2.1760918942341192e-05,
      "loss": 1.502,
      "step": 196500
    },
    {
      "epoch": 3.93,
      "grad_norm": 2.603790283203125,
      "learning_rate": 2.168271891739597e-05,
      "loss": 1.5204,
      "step": 196600
    },
    {
      "epoch": 3.93,
      "grad_norm": 5.035116672515869,
      "learning_rate": 2.1604642566127587e-05,
      "loss": 1.5149,
      "step": 196700
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.333749771118164,
      "learning_rate": 2.1526690011829297e-05,
      "loss": 1.5042,
      "step": 196800
    },
    {
      "epoch": 3.94,
      "grad_norm": 4.009657382965088,
      "learning_rate": 2.1448861377598805e-05,
      "loss": 1.5145,
      "step": 196900
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.7483906745910645,
      "learning_rate": 2.137115678633811e-05,
      "loss": 1.4917,
      "step": 197000
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.7595458030700684,
      "learning_rate": 2.1293576360753433e-05,
      "loss": 1.5155,
      "step": 197100
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.6423468589782715,
      "learning_rate": 2.121612022335482e-05,
      "loss": 1.5151,
      "step": 197200
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.634237766265869,
      "learning_rate": 2.113878849645605e-05,
      "loss": 1.5375,
      "step": 197300
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.912870168685913,
      "learning_rate": 2.106158130217456e-05,
      "loss": 1.5435,
      "step": 197400
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.7648544311523438,
      "learning_rate": 2.098449876243096e-05,
      "loss": 1.5275,
      "step": 197500
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.939011812210083,
      "learning_rate": 2.0907540998949172e-05,
      "loss": 1.527,
      "step": 197600
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.698481559753418,
      "learning_rate": 2.0830708133255984e-05,
      "loss": 1.5303,
      "step": 197700
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.654996633529663,
      "learning_rate": 2.0754000286680942e-05,
      "loss": 1.5209,
      "step": 197800
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.72951602935791,
      "learning_rate": 2.067741758035627e-05,
      "loss": 1.5163,
      "step": 197900
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.2456839084625244,
      "learning_rate": 2.0600960135216462e-05,
      "loss": 1.5056,
      "step": 198000
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.221004009246826,
      "learning_rate": 2.05246280719983e-05,
      "loss": 1.5097,
      "step": 198100
    },
    {
      "epoch": 3.96,
      "grad_norm": 3.1113407611846924,
      "learning_rate": 2.044842151124051e-05,
      "loss": 1.5008,
      "step": 198200
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.490079402923584,
      "learning_rate": 2.0372340573283633e-05,
      "loss": 1.5177,
      "step": 198300
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.3305625915527344,
      "learning_rate": 2.02963853782699e-05,
      "loss": 1.5304,
      "step": 198400
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.7087066173553467,
      "learning_rate": 2.0220556046142893e-05,
      "loss": 1.4945,
      "step": 198500
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.834400177001953,
      "learning_rate": 2.014485269664751e-05,
      "loss": 1.5271,
      "step": 198600
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.603806734085083,
      "learning_rate": 2.006927544932966e-05,
      "loss": 1.5382,
      "step": 198700
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.519742727279663,
      "learning_rate": 1.99938244235361e-05,
      "loss": 1.543,
      "step": 198800
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.623040199279785,
      "learning_rate": 1.9918499738414355e-05,
      "loss": 1.5307,
      "step": 198900
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.668750524520874,
      "learning_rate": 1.9843301512912327e-05,
      "loss": 1.5331,
      "step": 199000
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.535632371902466,
      "learning_rate": 1.9768229865778343e-05,
      "loss": 1.5171,
      "step": 199100
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.814148426055908,
      "learning_rate": 1.9693284915560738e-05,
      "loss": 1.5167,
      "step": 199200
    },
    {
      "epoch": 3.99,
      "grad_norm": 3.216536521911621,
      "learning_rate": 1.9618466780607803e-05,
      "loss": 1.5056,
      "step": 199300
    },
    {
      "epoch": 3.99,
      "grad_norm": 2.723789930343628,
      "learning_rate": 1.9543775579067636e-05,
      "loss": 1.5295,
      "step": 199400
    },
    {
      "epoch": 3.99,
      "grad_norm": 3.040821075439453,
      "learning_rate": 1.946921142888781e-05,
      "loss": 1.4952,
      "step": 199500
    },
    {
      "epoch": 3.99,
      "grad_norm": 2.2770798206329346,
      "learning_rate": 1.93947744478153e-05,
      "loss": 1.5109,
      "step": 199600
    },
    {
      "epoch": 3.99,
      "grad_norm": 4.596993446350098,
      "learning_rate": 1.932046475339624e-05,
      "loss": 1.5458,
      "step": 199700
    },
    {
      "epoch": 4.0,
      "grad_norm": 8.51403522491455,
      "learning_rate": 1.9246282462975808e-05,
      "loss": 1.5196,
      "step": 199800
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.6288797855377197,
      "learning_rate": 1.9172227693697964e-05,
      "loss": 1.537,
      "step": 199900
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.5064711570739746,
      "learning_rate": 1.9098300562505266e-05,
      "loss": 1.504,
      "step": 200000
    }
  ],
  "logging_steps": 100,
  "max_steps": 250000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 1.6470827048888574e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
