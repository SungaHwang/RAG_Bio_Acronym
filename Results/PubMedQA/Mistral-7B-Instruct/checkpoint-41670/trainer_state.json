{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 41670,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.6981425881385803,
      "learning_rate": 0.0001999971580221308,
      "loss": 1.2774,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7040753364562988,
      "learning_rate": 0.00019998863225005993,
      "loss": 1.2407,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6932312250137329,
      "learning_rate": 0.0001999744231683885,
      "loss": 1.2528,
      "step": 300
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7031133770942688,
      "learning_rate": 0.00019995453158475442,
      "loss": 1.2506,
      "step": 400
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6599948406219482,
      "learning_rate": 0.00019992895862978654,
      "loss": 1.2467,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7029753923416138,
      "learning_rate": 0.00019989770575704025,
      "loss": 1.2503,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7960375547409058,
      "learning_rate": 0.00019986077474291506,
      "loss": 1.263,
      "step": 700
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7133380770683289,
      "learning_rate": 0.00019981816768655338,
      "loss": 1.2505,
      "step": 800
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7796468734741211,
      "learning_rate": 0.00019976988700972154,
      "loss": 1.2481,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8646925091743469,
      "learning_rate": 0.00019971593545667178,
      "loss": 1.2568,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8349616527557373,
      "learning_rate": 0.00019965631609398648,
      "loss": 1.2603,
      "step": 1100
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8887637853622437,
      "learning_rate": 0.00019959103231040386,
      "loss": 1.252,
      "step": 1200
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1684625148773193,
      "learning_rate": 0.00019952008781662527,
      "loss": 1.2636,
      "step": 1300
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7453286051750183,
      "learning_rate": 0.00019944348664510436,
      "loss": 1.255,
      "step": 1400
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8974413871765137,
      "learning_rate": 0.00019936123314981782,
      "loss": 1.2518,
      "step": 1500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1536930799484253,
      "learning_rate": 0.00019927333200601784,
      "loss": 1.2554,
      "step": 1600
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3888564109802246,
      "learning_rate": 0.0001991797882099666,
      "loss": 1.2633,
      "step": 1700
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.863832414150238,
      "learning_rate": 0.00019908060707865202,
      "loss": 1.2549,
      "step": 1800
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8464203476905823,
      "learning_rate": 0.00019897579424948573,
      "loss": 1.2473,
      "step": 1900
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8896610140800476,
      "learning_rate": 0.00019886535567998256,
      "loss": 1.2585,
      "step": 2000
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.4695866107940674,
      "learning_rate": 0.0001987492976474219,
      "loss": 1.2597,
      "step": 2100
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8281014561653137,
      "learning_rate": 0.00019862762674849094,
      "loss": 1.2582,
      "step": 2200
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.181678295135498,
      "learning_rate": 0.00019850034989890976,
      "loss": 1.2625,
      "step": 2300
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8439759612083435,
      "learning_rate": 0.00019836747433303812,
      "loss": 1.2609,
      "step": 2400
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9388151168823242,
      "learning_rate": 0.00019822900760346434,
      "loss": 1.2621,
      "step": 2500
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.163500189781189,
      "learning_rate": 0.00019808495758057615,
      "loss": 1.2604,
      "step": 2600
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9279312491416931,
      "learning_rate": 0.00019793533245211298,
      "loss": 1.2635,
      "step": 2700
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9890842437744141,
      "learning_rate": 0.00019778014072270096,
      "loss": 1.2483,
      "step": 2800
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.192237138748169,
      "learning_rate": 0.0001976193912133693,
      "loss": 1.2651,
      "step": 2900
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.907252848148346,
      "learning_rate": 0.000197453093061049,
      "loss": 1.2674,
      "step": 3000
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0041733980178833,
      "learning_rate": 0.0001972812557180533,
      "loss": 1.2681,
      "step": 3100
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.974820613861084,
      "learning_rate": 0.00019710388895154084,
      "loss": 1.2589,
      "step": 3200
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2636041641235352,
      "learning_rate": 0.00019692100284296007,
      "loss": 1.2559,
      "step": 3300
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9312978386878967,
      "learning_rate": 0.0001967326077874765,
      "loss": 1.2654,
      "step": 3400
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9801630973815918,
      "learning_rate": 0.00019653871449338165,
      "loss": 1.2577,
      "step": 3500
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.176688551902771,
      "learning_rate": 0.00019633933398148452,
      "loss": 1.2581,
      "step": 3600
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9081061482429504,
      "learning_rate": 0.00019613447758448519,
      "loss": 1.2591,
      "step": 3700
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.911351203918457,
      "learning_rate": 0.00019592415694633062,
      "loss": 1.2609,
      "step": 3800
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3247052431106567,
      "learning_rate": 0.00019570838402155276,
      "loss": 1.2719,
      "step": 3900
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3718626499176025,
      "learning_rate": 0.00019548717107458914,
      "loss": 1.2573,
      "step": 4000
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9689525365829468,
      "learning_rate": 0.00019526053067908577,
      "loss": 1.2595,
      "step": 4100
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9631202816963196,
      "learning_rate": 0.00019502847571718242,
      "loss": 1.2679,
      "step": 4200
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.992476224899292,
      "learning_rate": 0.00019479101937878039,
      "loss": 1.2552,
      "step": 4300
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.0636487007141113,
      "learning_rate": 0.00019454817516079286,
      "loss": 1.2641,
      "step": 4400
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9121803641319275,
      "learning_rate": 0.0001942999568663777,
      "loss": 1.2608,
      "step": 4500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9316822290420532,
      "learning_rate": 0.00019404637860415293,
      "loss": 1.2606,
      "step": 4600
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9325159192085266,
      "learning_rate": 0.0001937874547873947,
      "loss": 1.2666,
      "step": 4700
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.774377703666687,
      "learning_rate": 0.00019352320013321815,
      "loss": 1.2628,
      "step": 4800
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1432417631149292,
      "learning_rate": 0.00019325362966174085,
      "loss": 1.2562,
      "step": 4900
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2254955768585205,
      "learning_rate": 0.00019297875869522913,
      "loss": 1.2605,
      "step": 5000
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0544886589050293,
      "learning_rate": 0.00019269860285722702,
      "loss": 1.2631,
      "step": 5100
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8678834438323975,
      "learning_rate": 0.00019241317807166836,
      "loss": 1.2703,
      "step": 5200
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3046067953109741,
      "learning_rate": 0.00019212250056197165,
      "loss": 1.2542,
      "step": 5300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9127993583679199,
      "learning_rate": 0.00019182658685011785,
      "loss": 1.2533,
      "step": 5400
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0916966199874878,
      "learning_rate": 0.0001915254537557114,
      "loss": 1.2488,
      "step": 5500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9675857424736023,
      "learning_rate": 0.00019121911839502408,
      "loss": 1.2577,
      "step": 5600
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9994040131568909,
      "learning_rate": 0.0001909075981800222,
      "loss": 1.2603,
      "step": 5700
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.017836093902588,
      "learning_rate": 0.0001905909108173769,
      "loss": 1.2574,
      "step": 5800
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.103286862373352,
      "learning_rate": 0.0001902690743074577,
      "loss": 1.2642,
      "step": 5900
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.9345674514770508,
      "learning_rate": 0.00018994210694330937,
      "loss": 1.2612,
      "step": 6000
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1246540546417236,
      "learning_rate": 0.0001896100273096122,
      "loss": 1.2491,
      "step": 6100
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4206115007400513,
      "learning_rate": 0.00018927285428162551,
      "loss": 1.2619,
      "step": 6200
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9903866052627563,
      "learning_rate": 0.00018893060702411508,
      "loss": 1.2656,
      "step": 6300
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9364132881164551,
      "learning_rate": 0.00018858330499026344,
      "loss": 1.2519,
      "step": 6400
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.9152011871337891,
      "learning_rate": 0.00018823096792056453,
      "loss": 1.2657,
      "step": 6500
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0214412212371826,
      "learning_rate": 0.00018787361584170147,
      "loss": 1.2609,
      "step": 6600
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.0851147174835205,
      "learning_rate": 0.00018751126906540818,
      "loss": 1.2596,
      "step": 6700
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1802085638046265,
      "learning_rate": 0.0001871439481873151,
      "loss": 1.2546,
      "step": 6800
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9519866108894348,
      "learning_rate": 0.0001867716740857783,
      "loss": 1.2641,
      "step": 6900
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0073254108428955,
      "learning_rate": 0.000186394467920693,
      "loss": 1.2576,
      "step": 7000
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0304243564605713,
      "learning_rate": 0.0001860123511322906,
      "loss": 1.264,
      "step": 7100
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.0619184970855713,
      "learning_rate": 0.0001856253454399203,
      "loss": 1.2547,
      "step": 7200
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2690417766571045,
      "learning_rate": 0.0001852334728408143,
      "loss": 1.2657,
      "step": 7300
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.1324920654296875,
      "learning_rate": 0.00018483675560883772,
      "loss": 1.2571,
      "step": 7400
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5303937196731567,
      "learning_rate": 0.0001844352162932224,
      "loss": 1.2505,
      "step": 7500
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.03567373752594,
      "learning_rate": 0.00018402887771728533,
      "loss": 1.2529,
      "step": 7600
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9836075305938721,
      "learning_rate": 0.00018361776297713136,
      "loss": 1.255,
      "step": 7700
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9614046812057495,
      "learning_rate": 0.00018320189544034028,
      "loss": 1.2571,
      "step": 7800
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.0177961587905884,
      "learning_rate": 0.0001827812987446388,
      "loss": 1.2494,
      "step": 7900
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7767815589904785,
      "learning_rate": 0.00018235599679655704,
      "loss": 1.2637,
      "step": 8000
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1252403259277344,
      "learning_rate": 0.0001819260137700694,
      "loss": 1.2558,
      "step": 8100
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.035783290863037,
      "learning_rate": 0.0001814913741052208,
      "loss": 1.2588,
      "step": 8200
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1877031326293945,
      "learning_rate": 0.0001810521025067374,
      "loss": 1.2593,
      "step": 8300
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6264069676399231,
      "learning_rate": 0.00018060822394262252,
      "loss": 1.2235,
      "step": 8400
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6783645749092102,
      "learning_rate": 0.00018015976364273715,
      "loss": 1.2116,
      "step": 8500
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6233148574829102,
      "learning_rate": 0.00017970674709736636,
      "loss": 1.2131,
      "step": 8600
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.7017917037010193,
      "learning_rate": 0.00017924920005576994,
      "loss": 1.2098,
      "step": 8700
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6982297301292419,
      "learning_rate": 0.00017878714852471937,
      "loss": 1.2186,
      "step": 8800
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6808584928512573,
      "learning_rate": 0.00017832061876701905,
      "loss": 1.2219,
      "step": 8900
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6673710942268372,
      "learning_rate": 0.00017784963730001395,
      "loss": 1.2199,
      "step": 9000
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6779312491416931,
      "learning_rate": 0.00017737423089408217,
      "loss": 1.2246,
      "step": 9100
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.7214013934135437,
      "learning_rate": 0.00017689442657111345,
      "loss": 1.2296,
      "step": 9200
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6566030979156494,
      "learning_rate": 0.00017641025160297313,
      "loss": 1.2256,
      "step": 9300
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6947325468063354,
      "learning_rate": 0.00017592173350995205,
      "loss": 1.2278,
      "step": 9400
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.69602370262146,
      "learning_rate": 0.00017542890005920242,
      "loss": 1.2252,
      "step": 9500
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9050189852714539,
      "learning_rate": 0.00017493177926315948,
      "loss": 1.2207,
      "step": 9600
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7046684622764587,
      "learning_rate": 0.00017443039937794916,
      "loss": 1.2279,
      "step": 9700
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6652553081512451,
      "learning_rate": 0.00017392478890178228,
      "loss": 1.2345,
      "step": 9800
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6911348700523376,
      "learning_rate": 0.00017341497657333448,
      "loss": 1.2326,
      "step": 9900
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.606702446937561,
      "learning_rate": 0.00017290099137011287,
      "loss": 1.2286,
      "step": 10000
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.7204700112342834,
      "learning_rate": 0.00017238286250680895,
      "loss": 1.2317,
      "step": 10100
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6765396595001221,
      "learning_rate": 0.00017186061943363793,
      "loss": 1.2264,
      "step": 10200
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6615779399871826,
      "learning_rate": 0.00017133429183466495,
      "loss": 1.2302,
      "step": 10300
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6893002390861511,
      "learning_rate": 0.00017080390962611773,
      "loss": 1.228,
      "step": 10400
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.7163342237472534,
      "learning_rate": 0.0001702695029546863,
      "loss": 1.2258,
      "step": 10500
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6877480745315552,
      "learning_rate": 0.00016973110219580933,
      "loss": 1.2339,
      "step": 10600
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6081364750862122,
      "learning_rate": 0.00016918873795194762,
      "loss": 1.2216,
      "step": 10700
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6528582572937012,
      "learning_rate": 0.00016864244105084473,
      "loss": 1.2329,
      "step": 10800
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6502185463905334,
      "learning_rate": 0.00016809224254377475,
      "loss": 1.2283,
      "step": 10900
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.7307736873626709,
      "learning_rate": 0.0001675381737037773,
      "loss": 1.239,
      "step": 11000
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6314235925674438,
      "learning_rate": 0.00016698026602387998,
      "loss": 1.2442,
      "step": 11100
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6935105323791504,
      "learning_rate": 0.0001664185512153084,
      "loss": 1.229,
      "step": 11200
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.8099641799926758,
      "learning_rate": 0.00016585306120568357,
      "loss": 1.2332,
      "step": 11300
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6421312093734741,
      "learning_rate": 0.00016528382813720747,
      "loss": 1.2331,
      "step": 11400
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6044790148735046,
      "learning_rate": 0.0001647108843648357,
      "loss": 1.2264,
      "step": 11500
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6807593703269958,
      "learning_rate": 0.00016413426245443863,
      "loss": 1.2339,
      "step": 11600
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.649512529373169,
      "learning_rate": 0.00016355399518095052,
      "loss": 1.2342,
      "step": 11700
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7377294301986694,
      "learning_rate": 0.00016297011552650635,
      "loss": 1.2376,
      "step": 11800
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.775394082069397,
      "learning_rate": 0.0001623826566785672,
      "loss": 1.233,
      "step": 11900
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.4196351766586304,
      "learning_rate": 0.00016179165202803394,
      "loss": 1.2322,
      "step": 12000
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.8309333324432373,
      "learning_rate": 0.00016119713516734942,
      "loss": 1.2331,
      "step": 12100
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.667341411113739,
      "learning_rate": 0.0001605991398885888,
      "loss": 1.2349,
      "step": 12200
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6838857531547546,
      "learning_rate": 0.00015999770018153904,
      "loss": 1.2344,
      "step": 12300
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5995292663574219,
      "learning_rate": 0.00015939285023176686,
      "loss": 1.2283,
      "step": 12400
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7290477752685547,
      "learning_rate": 0.00015878462441867573,
      "loss": 1.2205,
      "step": 12500
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6393193602561951,
      "learning_rate": 0.00015817305731355167,
      "loss": 1.2273,
      "step": 12600
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6087949275970459,
      "learning_rate": 0.0001575581836775982,
      "loss": 1.2292,
      "step": 12700
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6639635562896729,
      "learning_rate": 0.00015694003845996064,
      "loss": 1.2262,
      "step": 12800
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.7370661497116089,
      "learning_rate": 0.00015631865679573958,
      "loss": 1.2402,
      "step": 12900
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6059471964836121,
      "learning_rate": 0.00015569407400399377,
      "loss": 1.234,
      "step": 13000
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7411069869995117,
      "learning_rate": 0.00015506632558573267,
      "loss": 1.2344,
      "step": 13100
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.7346100211143494,
      "learning_rate": 0.00015443544722189848,
      "loss": 1.2315,
      "step": 13200
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.669887125492096,
      "learning_rate": 0.0001538014747713382,
      "loss": 1.2352,
      "step": 13300
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6497841477394104,
      "learning_rate": 0.0001531644442687653,
      "loss": 1.2342,
      "step": 13400
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7674705386161804,
      "learning_rate": 0.00015252439192271156,
      "loss": 1.2297,
      "step": 13500
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6228821873664856,
      "learning_rate": 0.00015188135411346908,
      "loss": 1.2349,
      "step": 13600
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5757179260253906,
      "learning_rate": 0.00015123536739102225,
      "loss": 1.2346,
      "step": 13700
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.7138799428939819,
      "learning_rate": 0.00015058646847297054,
      "loss": 1.2314,
      "step": 13800
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6619715690612793,
      "learning_rate": 0.00014993469424244115,
      "loss": 1.2263,
      "step": 13900
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6898482441902161,
      "learning_rate": 0.00014928008174599296,
      "loss": 1.2264,
      "step": 14000
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6103514432907104,
      "learning_rate": 0.00014862266819151042,
      "loss": 1.2276,
      "step": 14100
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6298162937164307,
      "learning_rate": 0.00014796249094608906,
      "loss": 1.2326,
      "step": 14200
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6284545063972473,
      "learning_rate": 0.00014729958753391127,
      "loss": 1.2309,
      "step": 14300
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6324261426925659,
      "learning_rate": 0.00014663399563411358,
      "loss": 1.2363,
      "step": 14400
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6364430785179138,
      "learning_rate": 0.000145965753078645,
      "loss": 1.2377,
      "step": 14500
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6564081311225891,
      "learning_rate": 0.0001452948978501166,
      "loss": 1.2324,
      "step": 14600
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6888115406036377,
      "learning_rate": 0.00014462146807964262,
      "loss": 1.2322,
      "step": 14700
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.702623188495636,
      "learning_rate": 0.00014394550204467317,
      "loss": 1.2378,
      "step": 14800
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6195892095565796,
      "learning_rate": 0.00014326703816681846,
      "loss": 1.2301,
      "step": 14900
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6432708501815796,
      "learning_rate": 0.000142586115009665,
      "loss": 1.2349,
      "step": 15000
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6806597113609314,
      "learning_rate": 0.0001419027712765837,
      "loss": 1.236,
      "step": 15100
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6686682105064392,
      "learning_rate": 0.0001412170458085299,
      "loss": 1.2371,
      "step": 15200
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.696628987789154,
      "learning_rate": 0.0001405289775818356,
      "loss": 1.2318,
      "step": 15300
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.597684919834137,
      "learning_rate": 0.00013983860570599435,
      "loss": 1.2328,
      "step": 15400
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.0130857229232788,
      "learning_rate": 0.00013914596942143795,
      "loss": 1.2325,
      "step": 15500
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.644250750541687,
      "learning_rate": 0.00013845110809730625,
      "loss": 1.2314,
      "step": 15600
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6208543181419373,
      "learning_rate": 0.00013775406122920936,
      "loss": 1.2228,
      "step": 15700
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6617963314056396,
      "learning_rate": 0.0001370548684369828,
      "loss": 1.2286,
      "step": 15800
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6469053030014038,
      "learning_rate": 0.00013635356946243527,
      "loss": 1.2313,
      "step": 15900
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6415169835090637,
      "learning_rate": 0.0001356502041670902,
      "loss": 1.2342,
      "step": 16000
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6622956395149231,
      "learning_rate": 0.0001349448125299196,
      "loss": 1.2232,
      "step": 16100
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.8729138970375061,
      "learning_rate": 0.00013423743464507194,
      "loss": 1.2292,
      "step": 16200
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6892922520637512,
      "learning_rate": 0.00013352811071959305,
      "loss": 1.224,
      "step": 16300
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6501036882400513,
      "learning_rate": 0.00013281688107114097,
      "loss": 1.2281,
      "step": 16400
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6774815917015076,
      "learning_rate": 0.00013210378612569406,
      "loss": 1.2234,
      "step": 16500
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.5942255854606628,
      "learning_rate": 0.0001313888664152534,
      "loss": 1.2315,
      "step": 16600
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7527040243148804,
      "learning_rate": 0.00013067216257553889,
      "loss": 1.2112,
      "step": 16700
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6677101254463196,
      "learning_rate": 0.00012995371534367956,
      "loss": 1.166,
      "step": 16800
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6833613514900208,
      "learning_rate": 0.00012923356555589812,
      "loss": 1.1723,
      "step": 16900
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7153499126434326,
      "learning_rate": 0.0001285117541451897,
      "loss": 1.1821,
      "step": 17000
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6699815988540649,
      "learning_rate": 0.0001277883221389954,
      "loss": 1.1811,
      "step": 17100
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.8003095984458923,
      "learning_rate": 0.00012706331065687033,
      "loss": 1.176,
      "step": 17200
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.7213133573532104,
      "learning_rate": 0.00012633676090814612,
      "loss": 1.1765,
      "step": 17300
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6767472624778748,
      "learning_rate": 0.00012560871418958896,
      "loss": 1.1815,
      "step": 17400
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.7012325525283813,
      "learning_rate": 0.0001248792118830521,
      "loss": 1.1825,
      "step": 17500
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.7565284371376038,
      "learning_rate": 0.00012414829545312372,
      "loss": 1.1847,
      "step": 17600
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6847351789474487,
      "learning_rate": 0.0001234160064447702,
      "loss": 1.181,
      "step": 17700
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.679831862449646,
      "learning_rate": 0.00012268238648097468,
      "loss": 1.1872,
      "step": 17800
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.7652668356895447,
      "learning_rate": 0.00012194747726037112,
      "loss": 1.1855,
      "step": 17900
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.7752842307090759,
      "learning_rate": 0.00012121132055487441,
      "loss": 1.1825,
      "step": 18000
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.745097815990448,
      "learning_rate": 0.00012047395820730583,
      "loss": 1.1882,
      "step": 18100
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6910642981529236,
      "learning_rate": 0.00011973543212901481,
      "loss": 1.188,
      "step": 18200
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.8454493880271912,
      "learning_rate": 0.0001189957842974968,
      "loss": 1.1828,
      "step": 18300
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.675772488117218,
      "learning_rate": 0.00011825505675400716,
      "loss": 1.1861,
      "step": 18400
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.886593759059906,
      "learning_rate": 0.00011751329160117163,
      "loss": 1.1873,
      "step": 18500
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.7432951331138611,
      "learning_rate": 0.00011677053100059311,
      "loss": 1.1867,
      "step": 18600
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.7216116189956665,
      "learning_rate": 0.00011602681717045545,
      "loss": 1.1853,
      "step": 18700
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6861324310302734,
      "learning_rate": 0.0001152821923831235,
      "loss": 1.1895,
      "step": 18800
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.8095968961715698,
      "learning_rate": 0.00011453669896274066,
      "loss": 1.1941,
      "step": 18900
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.706137478351593,
      "learning_rate": 0.00011379037928282294,
      "loss": 1.1814,
      "step": 19000
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.7693684101104736,
      "learning_rate": 0.0001130432757638506,
      "loss": 1.1818,
      "step": 19100
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6594825983047485,
      "learning_rate": 0.00011229543087085703,
      "loss": 1.1856,
      "step": 19200
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6461026072502136,
      "learning_rate": 0.00011154688711101491,
      "loss": 1.1873,
      "step": 19300
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6797797679901123,
      "learning_rate": 0.00011079768703122025,
      "loss": 1.1955,
      "step": 19400
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.7120657563209534,
      "learning_rate": 0.00011004787321567393,
      "loss": 1.1846,
      "step": 19500
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.7084999084472656,
      "learning_rate": 0.00010929748828346137,
      "loss": 1.1958,
      "step": 19600
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6332096457481384,
      "learning_rate": 0.00010854657488613002,
      "loss": 1.1952,
      "step": 19700
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.7049711346626282,
      "learning_rate": 0.00010779517570526499,
      "loss": 1.1964,
      "step": 19800
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.7012147903442383,
      "learning_rate": 0.00010704333345006315,
      "loss": 1.1959,
      "step": 19900
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7259053587913513,
      "learning_rate": 0.00010629109085490547,
      "loss": 1.187,
      "step": 20000
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.7043011784553528,
      "learning_rate": 0.00010553849067692813,
      "loss": 1.1896,
      "step": 20100
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6830801367759705,
      "learning_rate": 0.00010478557569359216,
      "loss": 1.192,
      "step": 20200
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6909466981887817,
      "learning_rate": 0.00010403238870025195,
      "loss": 1.1931,
      "step": 20300
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6833591461181641,
      "learning_rate": 0.0001032789725077228,
      "loss": 1.1938,
      "step": 20400
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.7104496359825134,
      "learning_rate": 0.00010252536993984762,
      "loss": 1.1876,
      "step": 20500
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.7577082514762878,
      "learning_rate": 0.00010177162383106284,
      "loss": 1.1876,
      "step": 20600
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.749803364276886,
      "learning_rate": 0.00010101777702396367,
      "loss": 1.1919,
      "step": 20700
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6854878664016724,
      "learning_rate": 0.00010026387236686891,
      "loss": 1.1867,
      "step": 20800
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.7063712477684021,
      "learning_rate": 9.950995271138562e-05,
      "loss": 1.187,
      "step": 20900
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.7698471546173096,
      "learning_rate": 9.875606090997331e-05,
      "loss": 1.1856,
      "step": 21000
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6764432191848755,
      "learning_rate": 9.80022398135083e-05,
      "loss": 1.1838,
      "step": 21100
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7001171112060547,
      "learning_rate": 9.724853226884804e-05,
      "loss": 1.1935,
      "step": 21200
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6716188192367554,
      "learning_rate": 9.649498111639578e-05,
      "loss": 1.1818,
      "step": 21300
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.7506818771362305,
      "learning_rate": 9.57416291876655e-05,
      "loss": 1.1896,
      "step": 21400
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6943191289901733,
      "learning_rate": 9.498851930284735e-05,
      "loss": 1.1921,
      "step": 21500
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.693394660949707,
      "learning_rate": 9.423569426837388e-05,
      "loss": 1.1873,
      "step": 21600
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5972011089324951,
      "learning_rate": 9.348319687448682e-05,
      "loss": 1.1821,
      "step": 21700
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6479949951171875,
      "learning_rate": 9.2731069892805e-05,
      "loss": 1.1838,
      "step": 21800
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6905553340911865,
      "learning_rate": 9.197935607389312e-05,
      "loss": 1.1879,
      "step": 21900
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7307922840118408,
      "learning_rate": 9.122809814483192e-05,
      "loss": 1.1893,
      "step": 22000
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.008750081062317,
      "learning_rate": 9.047733880678958e-05,
      "loss": 1.183,
      "step": 22100
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.7066651582717896,
      "learning_rate": 8.972712073259459e-05,
      "loss": 1.1892,
      "step": 22200
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7031169533729553,
      "learning_rate": 8.897748656431022e-05,
      "loss": 1.1842,
      "step": 22300
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.668494462966919,
      "learning_rate": 8.82284789108108e-05,
      "loss": 1.1886,
      "step": 22400
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.7020173668861389,
      "learning_rate": 8.748014034535983e-05,
      "loss": 1.1872,
      "step": 22500
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6623201370239258,
      "learning_rate": 8.673251340319013e-05,
      "loss": 1.1885,
      "step": 22600
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.644439160823822,
      "learning_rate": 8.59856405790862e-05,
      "loss": 1.1897,
      "step": 22700
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.7209752798080444,
      "learning_rate": 8.523956432496878e-05,
      "loss": 1.1798,
      "step": 22800
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.7003660202026367,
      "learning_rate": 8.449432704748193e-05,
      "loss": 1.1875,
      "step": 22900
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6322221755981445,
      "learning_rate": 8.374997110558265e-05,
      "loss": 1.183,
      "step": 23000
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6721917390823364,
      "learning_rate": 8.30065388081332e-05,
      "loss": 1.188,
      "step": 23100
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.7781361937522888,
      "learning_rate": 8.226407241149632e-05,
      "loss": 1.1925,
      "step": 23200
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6906613111495972,
      "learning_rate": 8.152261411713339e-05,
      "loss": 1.1814,
      "step": 23300
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6194880604743958,
      "learning_rate": 8.078220606920564e-05,
      "loss": 1.1845,
      "step": 23400
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.7209756970405579,
      "learning_rate": 8.004289035217883e-05,
      "loss": 1.184,
      "step": 23500
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6887866258621216,
      "learning_rate": 7.930470898843106e-05,
      "loss": 1.1907,
      "step": 23600
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6588846445083618,
      "learning_rate": 7.856770393586435e-05,
      "loss": 1.1823,
      "step": 23700
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.7079312801361084,
      "learning_rate": 7.783191708551962e-05,
      "loss": 1.1853,
      "step": 23800
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6162320375442505,
      "learning_rate": 7.709739025919583e-05,
      "loss": 1.1959,
      "step": 23900
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.7518942356109619,
      "learning_rate": 7.636416520707265e-05,
      "loss": 1.1943,
      "step": 24000
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6552833318710327,
      "learning_rate": 7.56322836053375e-05,
      "loss": 1.1852,
      "step": 24100
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.7564977407455444,
      "learning_rate": 7.49017870538167e-05,
      "loss": 1.1849,
      "step": 24200
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6730246543884277,
      "learning_rate": 7.41727170736109e-05,
      "loss": 1.1827,
      "step": 24300
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.7286050319671631,
      "learning_rate": 7.344511510473507e-05,
      "loss": 1.1886,
      "step": 24400
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.7231141924858093,
      "learning_rate": 7.271902250376306e-05,
      "loss": 1.1841,
      "step": 24500
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6721851229667664,
      "learning_rate": 7.199448054147695e-05,
      "loss": 1.1844,
      "step": 24600
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6893160343170166,
      "learning_rate": 7.12715304005212e-05,
      "loss": 1.1901,
      "step": 24700
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6582173705101013,
      "learning_rate": 7.055021317306178e-05,
      "loss": 1.1838,
      "step": 24800
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6475837230682373,
      "learning_rate": 6.983056985845068e-05,
      "loss": 1.1837,
      "step": 24900
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7806287407875061,
      "learning_rate": 6.911264136089537e-05,
      "loss": 1.1866,
      "step": 25000
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.8383200764656067,
      "learning_rate": 6.839646848713385e-05,
      "loss": 1.1222,
      "step": 25100
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.8262445330619812,
      "learning_rate": 6.768209194411532e-05,
      "loss": 1.1184,
      "step": 25200
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.8557741045951843,
      "learning_rate": 6.696955233668626e-05,
      "loss": 1.1259,
      "step": 25300
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.8346348404884338,
      "learning_rate": 6.625889016528262e-05,
      "loss": 1.1253,
      "step": 25400
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.8266474604606628,
      "learning_rate": 6.555014582362761e-05,
      "loss": 1.1123,
      "step": 25500
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.8464966416358948,
      "learning_rate": 6.484335959643594e-05,
      "loss": 1.1253,
      "step": 25600
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.8946718573570251,
      "learning_rate": 6.413857165712393e-05,
      "loss": 1.127,
      "step": 25700
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.9472619295120239,
      "learning_rate": 6.343582206552609e-05,
      "loss": 1.1328,
      "step": 25800
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.8496593832969666,
      "learning_rate": 6.273515076561817e-05,
      "loss": 1.1241,
      "step": 25900
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.9137018322944641,
      "learning_rate": 6.203659758324671e-05,
      "loss": 1.1208,
      "step": 26000
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.8802458047866821,
      "learning_rate": 6.134020222386544e-05,
      "loss": 1.1227,
      "step": 26100
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.8639869689941406,
      "learning_rate": 6.064600427027832e-05,
      "loss": 1.1155,
      "step": 26200
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.8518739342689514,
      "learning_rate": 5.995404318038979e-05,
      "loss": 1.124,
      "step": 26300
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.8657488822937012,
      "learning_rate": 5.926435828496191e-05,
      "loss": 1.1261,
      "step": 26400
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.9311553239822388,
      "learning_rate": 5.8576988785378875e-05,
      "loss": 1.1246,
      "step": 26500
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.9488492608070374,
      "learning_rate": 5.789197375141882e-05,
      "loss": 1.1226,
      "step": 26600
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.9935003519058228,
      "learning_rate": 5.720935211903301e-05,
      "loss": 1.1248,
      "step": 26700
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.8926942944526672,
      "learning_rate": 5.6529162688133e-05,
      "loss": 1.1233,
      "step": 26800
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.9019454121589661,
      "learning_rate": 5.585144412038487e-05,
      "loss": 1.1187,
      "step": 26900
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.841285765171051,
      "learning_rate": 5.517623493701213e-05,
      "loss": 1.1328,
      "step": 27000
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.9323878288269043,
      "learning_rate": 5.450357351660582e-05,
      "loss": 1.1242,
      "step": 27100
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.866675853729248,
      "learning_rate": 5.383349809294345e-05,
      "loss": 1.1297,
      "step": 27200
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.8875929117202759,
      "learning_rate": 5.3166046752815404e-05,
      "loss": 1.1229,
      "step": 27300
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.8995616436004639,
      "learning_rate": 5.2501257433860515e-05,
      "loss": 1.1252,
      "step": 27400
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.8750340938568115,
      "learning_rate": 5.183916792240937e-05,
      "loss": 1.1281,
      "step": 27500
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.9822657108306885,
      "learning_rate": 5.117981585133681e-05,
      "loss": 1.1243,
      "step": 27600
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.8934537172317505,
      "learning_rate": 5.052323869792264e-05,
      "loss": 1.1251,
      "step": 27700
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.8705052733421326,
      "learning_rate": 4.986947378172172e-05,
      "loss": 1.1363,
      "step": 27800
    },
    {
      "epoch": 3.35,
      "grad_norm": 1.0674082040786743,
      "learning_rate": 4.921855826244248e-05,
      "loss": 1.1271,
      "step": 27900
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.913118302822113,
      "learning_rate": 4.857052913783495e-05,
      "loss": 1.1242,
      "step": 28000
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.8826408386230469,
      "learning_rate": 4.79254232415877e-05,
      "loss": 1.1301,
      "step": 28100
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.9070506691932678,
      "learning_rate": 4.728327724123439e-05,
      "loss": 1.1285,
      "step": 28200
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.8832093477249146,
      "learning_rate": 4.6644127636069414e-05,
      "loss": 1.1324,
      "step": 28300
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.9178816676139832,
      "learning_rate": 4.6008010755073485e-05,
      "loss": 1.1315,
      "step": 28400
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.8974946737289429,
      "learning_rate": 4.5374962754848496e-05,
      "loss": 1.1259,
      "step": 28500
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.9177870154380798,
      "learning_rate": 4.474501961756267e-05,
      "loss": 1.1282,
      "step": 28600
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.8884141445159912,
      "learning_rate": 4.4118217148905004e-05,
      "loss": 1.1281,
      "step": 28700
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.8572977781295776,
      "learning_rate": 4.349459097605047e-05,
      "loss": 1.1355,
      "step": 28800
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.8691651225090027,
      "learning_rate": 4.2874176545634696e-05,
      "loss": 1.1352,
      "step": 28900
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.9043652415275574,
      "learning_rate": 4.225700912173923e-05,
      "loss": 1.1249,
      "step": 29000
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.824870228767395,
      "learning_rate": 4.1643123783887363e-05,
      "loss": 1.1277,
      "step": 29100
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.9484803676605225,
      "learning_rate": 4.103255542504991e-05,
      "loss": 1.1288,
      "step": 29200
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.008730173110962,
      "learning_rate": 4.0425338749662225e-05,
      "loss": 1.1272,
      "step": 29300
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.8611360788345337,
      "learning_rate": 3.9821508271651286e-05,
      "loss": 1.1313,
      "step": 29400
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.8826280832290649,
      "learning_rate": 3.922109831247427e-05,
      "loss": 1.1342,
      "step": 29500
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.876549482345581,
      "learning_rate": 3.862414299916745e-05,
      "loss": 1.1232,
      "step": 29600
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.8295924067497253,
      "learning_rate": 3.803067626240665e-05,
      "loss": 1.1282,
      "step": 29700
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.8668109774589539,
      "learning_rate": 3.744073183457848e-05,
      "loss": 1.1219,
      "step": 29800
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.9494876265525818,
      "learning_rate": 3.6854343247863146e-05,
      "loss": 1.1226,
      "step": 29900
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.9123871922492981,
      "learning_rate": 3.6271543832328304e-05,
      "loss": 1.1354,
      "step": 30000
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.8508325219154358,
      "learning_rate": 3.5692366714034854e-05,
      "loss": 1.1188,
      "step": 30100
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.882003128528595,
      "learning_rate": 3.511684481315377e-05,
      "loss": 1.1249,
      "step": 30200
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.8384694457054138,
      "learning_rate": 3.4545010842095236e-05,
      "loss": 1.1303,
      "step": 30300
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.8843955397605896,
      "learning_rate": 3.3976897303649e-05,
      "loss": 1.1269,
      "step": 30400
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.9375507235527039,
      "learning_rate": 3.341253648913719e-05,
      "loss": 1.1347,
      "step": 30500
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.8506535291671753,
      "learning_rate": 3.285196047657865e-05,
      "loss": 1.1204,
      "step": 30600
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.9389586448669434,
      "learning_rate": 3.229520112886587e-05,
      "loss": 1.1303,
      "step": 30700
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.8844342231750488,
      "learning_rate": 3.1742290091953675e-05,
      "loss": 1.1117,
      "step": 30800
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.8787387609481812,
      "learning_rate": 3.1193258793060764e-05,
      "loss": 1.1258,
      "step": 30900
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.8391913175582886,
      "learning_rate": 3.064813843888307e-05,
      "loss": 1.1312,
      "step": 31000
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.8613812923431396,
      "learning_rate": 3.0106960013820307e-05,
      "loss": 1.1238,
      "step": 31100
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.8674994707107544,
      "learning_rate": 2.9569754278214612e-05,
      "loss": 1.128,
      "step": 31200
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.9051371216773987,
      "learning_rate": 2.903655176660217e-05,
      "loss": 1.1257,
      "step": 31300
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.8691610097885132,
      "learning_rate": 2.850738278597781e-05,
      "loss": 1.1217,
      "step": 31400
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.8983471989631653,
      "learning_rate": 2.79822774140721e-05,
      "loss": 1.1342,
      "step": 31500
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.877066433429718,
      "learning_rate": 2.7461265497642043e-05,
      "loss": 1.1297,
      "step": 31600
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.88484126329422,
      "learning_rate": 2.694437665077427e-05,
      "loss": 1.1273,
      "step": 31700
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.8630954623222351,
      "learning_rate": 2.6431640253202128e-05,
      "loss": 1.1315,
      "step": 31800
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.9348406195640564,
      "learning_rate": 2.5923085448635454e-05,
      "loss": 1.1269,
      "step": 31900
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.8553705811500549,
      "learning_rate": 2.5418741143104295e-05,
      "loss": 1.1287,
      "step": 32000
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.8983051180839539,
      "learning_rate": 2.491863600331571e-05,
      "loss": 1.128,
      "step": 32100
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.8365461230278015,
      "learning_rate": 2.442279845502452e-05,
      "loss": 1.1209,
      "step": 32200
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.9399882555007935,
      "learning_rate": 2.393125668141746e-05,
      "loss": 1.124,
      "step": 32300
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.8062536716461182,
      "learning_rate": 2.3444038621511433e-05,
      "loss": 1.1219,
      "step": 32400
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.9219691753387451,
      "learning_rate": 2.2961171968565255e-05,
      "loss": 1.1276,
      "step": 32500
    },
    {
      "epoch": 3.91,
      "grad_norm": 1.02284836769104,
      "learning_rate": 2.2482684168505818e-05,
      "loss": 1.1201,
      "step": 32600
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.9491103887557983,
      "learning_rate": 2.2008602418367828e-05,
      "loss": 1.1316,
      "step": 32700
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.8337113857269287,
      "learning_rate": 2.1538953664748197e-05,
      "loss": 1.1229,
      "step": 32800
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.9154683947563171,
      "learning_rate": 2.1073764602274127e-05,
      "loss": 1.1241,
      "step": 32900
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.8987712860107422,
      "learning_rate": 2.06130616720861e-05,
      "loss": 1.1238,
      "step": 33000
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.8489583134651184,
      "learning_rate": 2.0156871060334703e-05,
      "loss": 1.1213,
      "step": 33100
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.9135437607765198,
      "learning_rate": 1.970521869669243e-05,
      "loss": 1.1301,
      "step": 33200
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.8944217562675476,
      "learning_rate": 1.925813025287968e-05,
      "loss": 1.1218,
      "step": 33300
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.6980898380279541,
      "learning_rate": 1.8815631141205757e-05,
      "loss": 1.0858,
      "step": 33400
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.6717778444290161,
      "learning_rate": 1.8377746513124273e-05,
      "loss": 1.062,
      "step": 33500
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.7065768241882324,
      "learning_rate": 1.7944501257803704e-05,
      "loss": 1.0648,
      "step": 33600
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.6918165683746338,
      "learning_rate": 1.7515920000712583e-05,
      "loss": 1.0639,
      "step": 33700
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.7343596816062927,
      "learning_rate": 1.7092027102219854e-05,
      "loss": 1.0686,
      "step": 33800
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.7346488237380981,
      "learning_rate": 1.6672846656210285e-05,
      "loss": 1.0667,
      "step": 33900
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.703957736492157,
      "learning_rate": 1.625840248871483e-05,
      "loss": 1.0676,
      "step": 34000
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.6935194134712219,
      "learning_rate": 1.5848718156556607e-05,
      "loss": 1.0641,
      "step": 34100
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.7008188366889954,
      "learning_rate": 1.5443816946011657e-05,
      "loss": 1.0626,
      "step": 34200
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.7693954706192017,
      "learning_rate": 1.5043721871485617e-05,
      "loss": 1.067,
      "step": 34300
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.7323284149169922,
      "learning_rate": 1.464845567420542e-05,
      "loss": 1.0737,
      "step": 34400
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.727475643157959,
      "learning_rate": 1.4258040820926732e-05,
      "loss": 1.0715,
      "step": 34500
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.7116953134536743,
      "learning_rate": 1.3872499502657076e-05,
      "loss": 1.0748,
      "step": 34600
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.7094509601593018,
      "learning_rate": 1.349185363339429e-05,
      "loss": 1.0684,
      "step": 34700
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.7105120420455933,
      "learning_rate": 1.3116124848881106e-05,
      "loss": 1.0729,
      "step": 34800
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.7415768504142761,
      "learning_rate": 1.274533450537535e-05,
      "loss": 1.0729,
      "step": 34900
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.7546505331993103,
      "learning_rate": 1.237950367843601e-05,
      "loss": 1.0651,
      "step": 35000
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.7524662613868713,
      "learning_rate": 1.201865316172539e-05,
      "loss": 1.07,
      "step": 35100
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.7468551993370056,
      "learning_rate": 1.166280346582711e-05,
      "loss": 1.0701,
      "step": 35200
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.7426124811172485,
      "learning_rate": 1.1311974817080429e-05,
      "loss": 1.0723,
      "step": 35300
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.7317282557487488,
      "learning_rate": 1.0966187156430397e-05,
      "loss": 1.0717,
      "step": 35400
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.7603490948677063,
      "learning_rate": 1.0625460138294652e-05,
      "loss": 1.0628,
      "step": 35500
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.6962137222290039,
      "learning_rate": 1.0289813129446047e-05,
      "loss": 1.0634,
      "step": 35600
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.6922950148582458,
      "learning_rate": 9.959265207912039e-06,
      "loss": 1.0679,
      "step": 35700
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.7325984239578247,
      "learning_rate": 9.633835161890148e-06,
      "loss": 1.0663,
      "step": 35800
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.7454845309257507,
      "learning_rate": 9.3135414886802e-06,
      "loss": 1.0633,
      "step": 35900
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.7670834064483643,
      "learning_rate": 8.998402393632754e-06,
      "loss": 1.0703,
      "step": 36000
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.7658300995826721,
      "learning_rate": 8.688435789114524e-06,
      "loss": 1.071,
      "step": 36100
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.7729864120483398,
      "learning_rate": 8.383659293490098e-06,
      "loss": 1.0672,
      "step": 36200
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.7887037396430969,
      "learning_rate": 8.08409023012061e-06,
      "loss": 1.0685,
      "step": 36300
    },
    {
      "epoch": 4.37,
      "grad_norm": 0.7197092175483704,
      "learning_rate": 7.789745626378997e-06,
      "loss": 1.0741,
      "step": 36400
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.7449615597724915,
      "learning_rate": 7.500642212682296e-06,
      "loss": 1.0724,
      "step": 36500
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.7116999626159668,
      "learning_rate": 7.216796421540528e-06,
      "loss": 1.0657,
      "step": 36600
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.730103611946106,
      "learning_rate": 6.938224386622872e-06,
      "loss": 1.074,
      "step": 36700
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.715757429599762,
      "learning_rate": 6.664941941840452e-06,
      "loss": 1.0711,
      "step": 36800
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.7541577816009521,
      "learning_rate": 6.396964620446522e-06,
      "loss": 1.0579,
      "step": 36900
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.7112264633178711,
      "learning_rate": 6.1343076541533705e-06,
      "loss": 1.0673,
      "step": 37000
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.780244767665863,
      "learning_rate": 5.876985972266724e-06,
      "loss": 1.0648,
      "step": 37100
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.7351667881011963,
      "learning_rate": 5.6250142008370974e-06,
      "loss": 1.0668,
      "step": 37200
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.7367942929267883,
      "learning_rate": 5.378406661828428e-06,
      "loss": 1.0625,
      "step": 37300
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.7317399978637695,
      "learning_rate": 5.137177372304103e-06,
      "loss": 1.066,
      "step": 37400
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.7303010821342468,
      "learning_rate": 4.901340043630143e-06,
      "loss": 1.0698,
      "step": 37500
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.7545244693756104,
      "learning_rate": 4.670908080695957e-06,
      "loss": 1.0695,
      "step": 37600
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.7006019949913025,
      "learning_rate": 4.445894581152299e-06,
      "loss": 1.0689,
      "step": 37700
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.7493399977684021,
      "learning_rate": 4.226312334666904e-06,
      "loss": 1.0684,
      "step": 37800
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.6978711485862732,
      "learning_rate": 4.0121738221974514e-06,
      "loss": 1.0713,
      "step": 37900
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.6975617408752441,
      "learning_rate": 3.80349121528224e-06,
      "loss": 1.0694,
      "step": 38000
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.7113161683082581,
      "learning_rate": 3.6002763753482436e-06,
      "loss": 1.0713,
      "step": 38100
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.7735912203788757,
      "learning_rate": 3.402540853037051e-06,
      "loss": 1.0762,
      "step": 38200
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.7472934126853943,
      "learning_rate": 3.210295887548209e-06,
      "loss": 1.0682,
      "step": 38300
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.7196155190467834,
      "learning_rate": 3.023552406000485e-06,
      "loss": 1.0689,
      "step": 38400
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.7116894721984863,
      "learning_rate": 2.84232102281069e-06,
      "loss": 1.0675,
      "step": 38500
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.7503312230110168,
      "learning_rate": 2.666612039090444e-06,
      "loss": 1.0646,
      "step": 38600
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.815954327583313,
      "learning_rate": 2.4964354420606073e-06,
      "loss": 1.0624,
      "step": 38700
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.748673141002655,
      "learning_rate": 2.3318009044836276e-06,
      "loss": 1.0694,
      "step": 38800
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.7453585267066956,
      "learning_rate": 2.1727177841137537e-06,
      "loss": 1.0559,
      "step": 38900
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.7079322338104248,
      "learning_rate": 2.019195123165152e-06,
      "loss": 1.0716,
      "step": 39000
    },
    {
      "epoch": 4.69,
      "grad_norm": 0.7360408306121826,
      "learning_rate": 1.8712416477978834e-06,
      "loss": 1.0708,
      "step": 39100
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.7275112271308899,
      "learning_rate": 1.7288657676220344e-06,
      "loss": 1.0705,
      "step": 39200
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.7062197327613831,
      "learning_rate": 1.5920755752195982e-06,
      "loss": 1.063,
      "step": 39300
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.6857000589370728,
      "learning_rate": 1.4608788456845658e-06,
      "loss": 1.0752,
      "step": 39400
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.7182890772819519,
      "learning_rate": 1.3352830361809898e-06,
      "loss": 1.0712,
      "step": 39500
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.7207533121109009,
      "learning_rate": 1.2152952855190692e-06,
      "loss": 1.0686,
      "step": 39600
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.7240204215049744,
      "learning_rate": 1.1009224137494611e-06,
      "loss": 1.0673,
      "step": 39700
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.7835178971290588,
      "learning_rate": 9.921709217755593e-07,
      "loss": 1.0677,
      "step": 39800
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.752371609210968,
      "learning_rate": 8.890469909840549e-07,
      "loss": 1.0693,
      "step": 39900
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.8120123744010925,
      "learning_rate": 7.915564828935074e-07,
      "loss": 1.0719,
      "step": 40000
    },
    {
      "epoch": 4.81,
      "grad_norm": 0.7510949969291687,
      "learning_rate": 6.99704938821255e-07,
      "loss": 1.0722,
      "step": 40100
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.7104037404060364,
      "learning_rate": 6.134975795684005e-07,
      "loss": 1.0697,
      "step": 40200
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.6966211199760437,
      "learning_rate": 5.329393051230924e-07,
      "loss": 1.0638,
      "step": 40300
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.7979309558868408,
      "learning_rate": 4.580346943820035e-07,
      "loss": 1.0716,
      "step": 40400
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.7528038620948792,
      "learning_rate": 3.887880048900394e-07,
      "loss": 1.0736,
      "step": 40500
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.7424132227897644,
      "learning_rate": 3.2520317259838726e-07,
      "loss": 1.0655,
      "step": 40600
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.7240486145019531,
      "learning_rate": 2.6728381164077275e-07,
      "loss": 1.07,
      "step": 40700
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.7302499413490295,
      "learning_rate": 2.1503321412803536e-07,
      "loss": 1.0726,
      "step": 40800
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.7210370898246765,
      "learning_rate": 1.684543499610114e-07,
      "loss": 1.0679,
      "step": 40900
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.9304574728012085,
      "learning_rate": 1.2754986666172476e-07,
      "loss": 1.066,
      "step": 41000
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.6816917061805725,
      "learning_rate": 9.232208922288488e-08,
      "loss": 1.0691,
      "step": 41100
    },
    {
      "epoch": 4.94,
      "grad_norm": 0.663236141204834,
      "learning_rate": 6.277301997579255e-08,
      "loss": 1.0705,
      "step": 41200
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.6720283031463623,
      "learning_rate": 3.890433847645314e-08,
      "loss": 1.0673,
      "step": 41300
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.6949299573898315,
      "learning_rate": 2.0717401410164096e-08,
      "loss": 1.0669,
      "step": 41400
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.7178308367729187,
      "learning_rate": 8.213242514376608e-09,
      "loss": 1.0701,
      "step": 41500
    },
    {
      "epoch": 4.99,
      "grad_norm": 0.6987224817276001,
      "learning_rate": 1.3925725199426254e-09,
      "loss": 1.069,
      "step": 41600
    }
  ],
  "logging_steps": 100,
  "max_steps": 41670,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 2.29547560354488e+19,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
