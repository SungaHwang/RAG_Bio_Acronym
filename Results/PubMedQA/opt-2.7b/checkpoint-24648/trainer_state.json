{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 24648,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 0.3199014961719513,
      "learning_rate": 0.00019999187729838948,
      "loss": 1.9333,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.31557387113571167,
      "learning_rate": 0.0001999675105131235,
      "loss": 1.8738,
      "step": 200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.27423229813575745,
      "learning_rate": 0.0001999269036026846,
      "loss": 1.8649,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3093225061893463,
      "learning_rate": 0.00019987006316382912,
      "loss": 1.8477,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.26347869634628296,
      "learning_rate": 0.00019979699843051553,
      "loss": 1.854,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2929430902004242,
      "learning_rate": 0.0001997077212724044,
      "loss": 1.8469,
      "step": 600
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3298189640045166,
      "learning_rate": 0.00019960224619293003,
      "loss": 1.8487,
      "step": 700
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3369308412075043,
      "learning_rate": 0.00019948059032694432,
      "loss": 1.8432,
      "step": 800
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.33436039090156555,
      "learning_rate": 0.00019934277343793336,
      "loss": 1.8365,
      "step": 900
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.328355997800827,
      "learning_rate": 0.0001991888179148064,
      "loss": 1.8415,
      "step": 1000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3176323175430298,
      "learning_rate": 0.00019901874876825895,
      "loss": 1.8385,
      "step": 1100
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3384109139442444,
      "learning_rate": 0.00019883259362670966,
      "loss": 1.8421,
      "step": 1200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3337010145187378,
      "learning_rate": 0.00019863038273181186,
      "loss": 1.8411,
      "step": 1300
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.34296372532844543,
      "learning_rate": 0.0001984121489335408,
      "loss": 1.8374,
      "step": 1400
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.33125534653663635,
      "learning_rate": 0.00019817792768485695,
      "loss": 1.8417,
      "step": 1500
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3406755328178406,
      "learning_rate": 0.0001979277570359466,
      "loss": 1.8354,
      "step": 1600
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.34858450293540955,
      "learning_rate": 0.00019766167762804045,
      "loss": 1.829,
      "step": 1700
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3436935842037201,
      "learning_rate": 0.00019737973268681115,
      "loss": 1.8333,
      "step": 1800
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.35513541102409363,
      "learning_rate": 0.00019708196801535127,
      "loss": 1.8312,
      "step": 1900
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3350276052951813,
      "learning_rate": 0.00019676843198673235,
      "loss": 1.8302,
      "step": 2000
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3818223476409912,
      "learning_rate": 0.00019643917553614646,
      "loss": 1.8267,
      "step": 2100
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3519965708255768,
      "learning_rate": 0.00019609425215263166,
      "loss": 1.8307,
      "step": 2200
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.386987566947937,
      "learning_rate": 0.0001957337178703824,
      "loss": 1.8267,
      "step": 2300
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.36842671036720276,
      "learning_rate": 0.00019535763125964659,
      "loss": 1.828,
      "step": 2400
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3483472764492035,
      "learning_rate": 0.0001949660534172106,
      "loss": 1.8295,
      "step": 2500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4098972678184509,
      "learning_rate": 0.0001945590479564738,
      "loss": 1.8174,
      "step": 2600
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3656255900859833,
      "learning_rate": 0.0001941366809971145,
      "loss": 1.8359,
      "step": 2700
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.36824965476989746,
      "learning_rate": 0.00019369902115434827,
      "loss": 1.8229,
      "step": 2800
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.38989150524139404,
      "learning_rate": 0.0001932461395277813,
      "loss": 1.8313,
      "step": 2900
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4073052704334259,
      "learning_rate": 0.00019277810968986004,
      "loss": 1.8199,
      "step": 3000
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.38983699679374695,
      "learning_rate": 0.0001922950076739187,
      "loss": 1.8197,
      "step": 3100
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42809152603149414,
      "learning_rate": 0.00019179691196182782,
      "loss": 1.8153,
      "step": 3200
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4070201814174652,
      "learning_rate": 0.0001912839034712443,
      "loss": 1.8182,
      "step": 3300
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4604605734348297,
      "learning_rate": 0.00019075606554246592,
      "loss": 1.8229,
      "step": 3400
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.38839831948280334,
      "learning_rate": 0.00019021348392489257,
      "loss": 1.8184,
      "step": 3500
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.38686811923980713,
      "learning_rate": 0.00018965624676309587,
      "loss": 1.824,
      "step": 3600
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4421638250350952,
      "learning_rate": 0.00018908444458249962,
      "loss": 1.8122,
      "step": 3700
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4304783344268799,
      "learning_rate": 0.00018849817027467373,
      "loss": 1.8089,
      "step": 3800
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.42683330178260803,
      "learning_rate": 0.00018789751908224338,
      "loss": 1.8202,
      "step": 3900
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4119640588760376,
      "learning_rate": 0.00018728258858341686,
      "loss": 1.8096,
      "step": 4000
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4748394787311554,
      "learning_rate": 0.00018665347867613313,
      "loss": 1.8145,
      "step": 4100
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.41103342175483704,
      "learning_rate": 0.0001860102915618334,
      "loss": 1.8172,
      "step": 4200
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.44777336716651917,
      "learning_rate": 0.00018535313172885786,
      "loss": 1.8174,
      "step": 4300
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4070757329463959,
      "learning_rate": 0.00018468210593547112,
      "loss": 1.8124,
      "step": 4400
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4192977547645569,
      "learning_rate": 0.0001839973231925191,
      "loss": 1.8083,
      "step": 4500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3897058367729187,
      "learning_rate": 0.00018329889474571952,
      "loss": 1.8062,
      "step": 4600
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.46047207713127136,
      "learning_rate": 0.0001825869340575898,
      "loss": 1.8061,
      "step": 4700
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4451441764831543,
      "learning_rate": 0.00018186155678901457,
      "loss": 1.8178,
      "step": 4800
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.44243451952934265,
      "learning_rate": 0.00018112288078045587,
      "loss": 1.8158,
      "step": 4900
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4334425926208496,
      "learning_rate": 0.00018037102603280983,
      "loss": 1.8075,
      "step": 5000
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.47284191846847534,
      "learning_rate": 0.00017960611468791185,
      "loss": 1.8083,
      "step": 5100
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4158216118812561,
      "learning_rate": 0.0001788282710086942,
      "loss": 1.7986,
      "step": 5200
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4075261354446411,
      "learning_rate": 0.000178037621358999,
      "loss": 1.8177,
      "step": 5300
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.43783333897590637,
      "learning_rate": 0.0001772342941830499,
      "loss": 1.8122,
      "step": 5400
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4215741753578186,
      "learning_rate": 0.0001764184199845858,
      "loss": 1.8121,
      "step": 5500
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.49544548988342285,
      "learning_rate": 0.00017559013130566005,
      "loss": 1.8105,
      "step": 5600
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4185347855091095,
      "learning_rate": 0.00017474956270510837,
      "loss": 1.8022,
      "step": 5700
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4369489848613739,
      "learning_rate": 0.00017389685073668926,
      "loss": 1.8098,
      "step": 5800
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.48732954263687134,
      "learning_rate": 0.00017303213392690027,
      "loss": 1.812,
      "step": 5900
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.4338562786579132,
      "learning_rate": 0.0001721555527524739,
      "loss": 1.8139,
      "step": 6000
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.4669409692287445,
      "learning_rate": 0.00017126724961755654,
      "loss": 1.8108,
      "step": 6100
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.33899298310279846,
      "learning_rate": 0.0001703673688305742,
      "loss": 1.7979,
      "step": 6200
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.36493661999702454,
      "learning_rate": 0.0001694560565807893,
      "loss": 1.8041,
      "step": 6300
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.3897903561592102,
      "learning_rate": 0.00016853346091455143,
      "loss": 1.7907,
      "step": 6400
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.36587393283843994,
      "learning_rate": 0.0001675997317112466,
      "loss": 1.7918,
      "step": 6500
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.3881327211856842,
      "learning_rate": 0.0001666550206589489,
      "loss": 1.7965,
      "step": 6600
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.3622571527957916,
      "learning_rate": 0.00016569948122977809,
      "loss": 1.7987,
      "step": 6700
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.3944644331932068,
      "learning_rate": 0.00016473326865496736,
      "loss": 1.8068,
      "step": 6800
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.38146182894706726,
      "learning_rate": 0.0001637565398996454,
      "loss": 1.7935,
      "step": 6900
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.3565707802772522,
      "learning_rate": 0.00016276945363733703,
      "loss": 1.8053,
      "step": 7000
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.4202902019023895,
      "learning_rate": 0.00016177217022418557,
      "loss": 1.8007,
      "step": 7100
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.35684823989868164,
      "learning_rate": 0.00016076485167290276,
      "loss": 1.8027,
      "step": 7200
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.38923367857933044,
      "learning_rate": 0.00015974766162644904,
      "loss": 1.7964,
      "step": 7300
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.4062521755695343,
      "learning_rate": 0.0001587207653314489,
      "loss": 1.8066,
      "step": 7400
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.40247398614883423,
      "learning_rate": 0.0001576843296113462,
      "loss": 1.7908,
      "step": 7500
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.39766591787338257,
      "learning_rate": 0.00015663852283930276,
      "loss": 1.8009,
      "step": 7600
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.42849141359329224,
      "learning_rate": 0.00015558351491084561,
      "loss": 1.8023,
      "step": 7700
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.3883616030216217,
      "learning_rate": 0.00015451947721626676,
      "loss": 1.7986,
      "step": 7800
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.3756130039691925,
      "learning_rate": 0.0001534465826127801,
      "loss": 1.8012,
      "step": 7900
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.4000913202762604,
      "learning_rate": 0.00015236500539644014,
      "loss": 1.8047,
      "step": 8000
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.37291181087493896,
      "learning_rate": 0.00015127492127382677,
      "loss": 1.7907,
      "step": 8100
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.4039224684238434,
      "learning_rate": 0.0001501765073335012,
      "loss": 1.7899,
      "step": 8200
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.39638906717300415,
      "learning_rate": 0.00014906994201723702,
      "loss": 1.7977,
      "step": 8300
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.3822886645793915,
      "learning_rate": 0.0001479554050910318,
      "loss": 1.7927,
      "step": 8400
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.40312686562538147,
      "learning_rate": 0.00014683307761590326,
      "loss": 1.7999,
      "step": 8500
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.4037407338619232,
      "learning_rate": 0.0001457031419184752,
      "loss": 1.7998,
      "step": 8600
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.40786921977996826,
      "learning_rate": 0.00014456578156135777,
      "loss": 1.8004,
      "step": 8700
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.3835951089859009,
      "learning_rate": 0.00014342118131332706,
      "loss": 1.7998,
      "step": 8800
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.401628702878952,
      "learning_rate": 0.00014226952711930867,
      "loss": 1.7963,
      "step": 8900
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.40717625617980957,
      "learning_rate": 0.00014111100607017008,
      "loss": 1.8006,
      "step": 9000
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.40715253353118896,
      "learning_rate": 0.00013994580637232716,
      "loss": 1.7883,
      "step": 9100
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.40169569849967957,
      "learning_rate": 0.00013877411731716917,
      "loss": 1.7888,
      "step": 9200
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.38223856687545776,
      "learning_rate": 0.0001375961292503076,
      "loss": 1.7923,
      "step": 9300
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.38774362206459045,
      "learning_rate": 0.00013641203354065377,
      "loss": 1.7925,
      "step": 9400
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.42607539892196655,
      "learning_rate": 0.00013522202254933027,
      "loss": 1.7989,
      "step": 9500
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.3945029079914093,
      "learning_rate": 0.00013402628959842104,
      "loss": 1.7954,
      "step": 9600
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.37094029784202576,
      "learning_rate": 0.0001328250289395654,
      "loss": 1.7917,
      "step": 9700
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.41238677501678467,
      "learning_rate": 0.00013161843572240107,
      "loss": 1.7955,
      "step": 9800
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.4202016294002533,
      "learning_rate": 0.00013040670596286145,
      "loss": 1.7854,
      "step": 9900
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.3934457302093506,
      "learning_rate": 0.00012919003651133188,
      "loss": 1.8018,
      "step": 10000
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.3964065611362457,
      "learning_rate": 0.0001279686250206707,
      "loss": 1.7823,
      "step": 10100
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.4208189845085144,
      "learning_rate": 0.00012674266991409948,
      "loss": 1.7859,
      "step": 10200
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.42138949036598206,
      "learning_rate": 0.0001255123703529687,
      "loss": 1.7882,
      "step": 10300
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.4158044159412384,
      "learning_rate": 0.00012427792620440278,
      "loss": 1.7885,
      "step": 10400
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.42732179164886475,
      "learning_rate": 0.00012303953800883125,
      "loss": 1.8026,
      "step": 10500
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.36842450499534607,
      "learning_rate": 0.00012179740694740993,
      "loss": 1.7887,
      "step": 10600
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.4088449776172638,
      "learning_rate": 0.00012055173480933826,
      "loss": 1.797,
      "step": 10700
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.3806442320346832,
      "learning_rate": 0.00011930272395907788,
      "loss": 1.7975,
      "step": 10800
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.4234325587749481,
      "learning_rate": 0.00011805057730347772,
      "loss": 1.7878,
      "step": 10900
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.42196783423423767,
      "learning_rate": 0.00011679549825881086,
      "loss": 1.7864,
      "step": 11000
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.4148810803890228,
      "learning_rate": 0.00011553769071772889,
      "loss": 1.7972,
      "step": 11100
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.4018569886684418,
      "learning_rate": 0.00011427735901613854,
      "loss": 1.8005,
      "step": 11200
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.38957732915878296,
      "learning_rate": 0.00011301470790000672,
      "loss": 1.7806,
      "step": 11300
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.44005367159843445,
      "learning_rate": 0.00011174994249209852,
      "loss": 1.7862,
      "step": 11400
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.4350876808166504,
      "learning_rate": 0.0001104832682586542,
      "loss": 1.7881,
      "step": 11500
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.4157077670097351,
      "learning_rate": 0.00010921489097601054,
      "loss": 1.7958,
      "step": 11600
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.4473842978477478,
      "learning_rate": 0.00010794501669717145,
      "loss": 1.785,
      "step": 11700
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.4149024188518524,
      "learning_rate": 0.00010667385171833391,
      "loss": 1.7785,
      "step": 11800
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.4124818444252014,
      "learning_rate": 0.00010540160254537437,
      "loss": 1.7964,
      "step": 11900
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.4193514585494995,
      "learning_rate": 0.0001041284758603009,
      "loss": 1.7891,
      "step": 12000
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.41994407773017883,
      "learning_rate": 0.00010285467848767705,
      "loss": 1.787,
      "step": 12100
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.4286908209323883,
      "learning_rate": 0.00010158041736102222,
      "loss": 1.7909,
      "step": 12200
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.41522979736328125,
      "learning_rate": 0.00010030589948919451,
      "loss": 1.7773,
      "step": 12300
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.4339887201786041,
      "learning_rate": 9.903133192276134e-05,
      "loss": 1.7766,
      "step": 12400
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.4408562481403351,
      "learning_rate": 9.775692172036318e-05,
      "loss": 1.7819,
      "step": 12500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.3764166533946991,
      "learning_rate": 9.648287591507614e-05,
      "loss": 1.7809,
      "step": 12600
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.416456401348114,
      "learning_rate": 9.520940148077842e-05,
      "loss": 1.7868,
      "step": 12700
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.4244050979614258,
      "learning_rate": 9.39367052985269e-05,
      "loss": 1.7843,
      "step": 12800
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.4100601375102997,
      "learning_rate": 9.26649941229481e-05,
      "loss": 1.7732,
      "step": 12900
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.39834538102149963,
      "learning_rate": 9.139447454865033e-05,
      "loss": 1.77,
      "step": 13000
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.4686886966228485,
      "learning_rate": 9.012535297666143e-05,
      "loss": 1.7791,
      "step": 13100
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.4320836067199707,
      "learning_rate": 8.885783558089809e-05,
      "loss": 1.7728,
      "step": 13200
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.4117935299873352,
      "learning_rate": 8.759212827467221e-05,
      "loss": 1.7853,
      "step": 13300
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.40719226002693176,
      "learning_rate": 8.632843667723927e-05,
      "loss": 1.7827,
      "step": 13400
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.43140551447868347,
      "learning_rate": 8.506696608039473e-05,
      "loss": 1.7743,
      "step": 13500
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.42914721369743347,
      "learning_rate": 8.380792141512354e-05,
      "loss": 1.7924,
      "step": 13600
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.37870240211486816,
      "learning_rate": 8.255150721830837e-05,
      "loss": 1.7746,
      "step": 13700
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3891776502132416,
      "learning_rate": 8.129792759950157e-05,
      "loss": 1.7798,
      "step": 13800
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.42138269543647766,
      "learning_rate": 8.004738620776694e-05,
      "loss": 1.7875,
      "step": 13900
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.4074726998806,
      "learning_rate": 7.880008619859601e-05,
      "loss": 1.7874,
      "step": 14000
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.4192056655883789,
      "learning_rate": 7.755623020090462e-05,
      "loss": 1.7822,
      "step": 14100
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.4192463755607605,
      "learning_rate": 7.631602028411512e-05,
      "loss": 1.7823,
      "step": 14200
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.4201546311378479,
      "learning_rate": 7.507965792532921e-05,
      "loss": 1.7915,
      "step": 14300
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.4128924310207367,
      "learning_rate": 7.384734397659745e-05,
      "loss": 1.7769,
      "step": 14400
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.41972094774246216,
      "learning_rate": 7.26192786322897e-05,
      "loss": 1.7751,
      "step": 14500
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.4123888909816742,
      "learning_rate": 7.139566139657297e-05,
      "loss": 1.7801,
      "step": 14600
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.4034093916416168,
      "learning_rate": 7.017669105100106e-05,
      "loss": 1.7774,
      "step": 14700
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.3902119994163513,
      "learning_rate": 6.896256562222182e-05,
      "loss": 1.7658,
      "step": 14800
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.4042418897151947,
      "learning_rate": 6.775348234980674e-05,
      "loss": 1.7791,
      "step": 14900
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.4166649878025055,
      "learning_rate": 6.654963765420865e-05,
      "loss": 1.7909,
      "step": 15000
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.4639178514480591,
      "learning_rate": 6.535122710485255e-05,
      "loss": 1.7783,
      "step": 15100
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.4075499475002289,
      "learning_rate": 6.415844538836439e-05,
      "loss": 1.7711,
      "step": 15200
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.4076290726661682,
      "learning_rate": 6.297148627694364e-05,
      "loss": 1.775,
      "step": 15300
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3975986838340759,
      "learning_rate": 6.179054259688393e-05,
      "loss": 1.7869,
      "step": 15400
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.45656347274780273,
      "learning_rate": 6.061580619724796e-05,
      "loss": 1.7797,
      "step": 15500
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.4541800618171692,
      "learning_rate": 5.9447467918700614e-05,
      "loss": 1.7792,
      "step": 15600
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.40748560428619385,
      "learning_rate": 5.828571756250623e-05,
      "loss": 1.7719,
      "step": 15700
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.3993796706199646,
      "learning_rate": 5.713074385969457e-05,
      "loss": 1.7747,
      "step": 15800
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.4346265494823456,
      "learning_rate": 5.598273444040083e-05,
      "loss": 1.7784,
      "step": 15900
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.4042094349861145,
      "learning_rate": 5.484187580338409e-05,
      "loss": 1.7768,
      "step": 16000
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.3995737135410309,
      "learning_rate": 5.370835328573016e-05,
      "loss": 1.772,
      "step": 16100
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.4066271185874939,
      "learning_rate": 5.258235103274265e-05,
      "loss": 1.774,
      "step": 16200
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.42735522985458374,
      "learning_rate": 5.1464051968027816e-05,
      "loss": 1.774,
      "step": 16300
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.42267045378685,
      "learning_rate": 5.035363776377797e-05,
      "loss": 1.7776,
      "step": 16400
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.41261008381843567,
      "learning_rate": 4.9251288811257936e-05,
      "loss": 1.7715,
      "step": 16500
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.39661911129951477,
      "learning_rate": 4.815718419150007e-05,
      "loss": 1.7755,
      "step": 16600
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.4607880413532257,
      "learning_rate": 4.707150164621138e-05,
      "loss": 1.7909,
      "step": 16700
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.4114619493484497,
      "learning_rate": 4.599441754889919e-05,
      "loss": 1.7759,
      "step": 16800
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.4182295799255371,
      "learning_rate": 4.492610687621804e-05,
      "loss": 1.7771,
      "step": 16900
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.4591895341873169,
      "learning_rate": 4.386674317954439e-05,
      "loss": 1.7895,
      "step": 17000
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.4375043213367462,
      "learning_rate": 4.281649855678237e-05,
      "loss": 1.7744,
      "step": 17100
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.401496559381485,
      "learning_rate": 4.1775543624405656e-05,
      "loss": 1.7805,
      "step": 17200
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.4192529022693634,
      "learning_rate": 4.07440474897405e-05,
      "loss": 1.7741,
      "step": 17300
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.4191787838935852,
      "learning_rate": 3.972217772349309e-05,
      "loss": 1.7658,
      "step": 17400
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.4225105941295624,
      "learning_rate": 3.8710100332527375e-05,
      "loss": 1.7783,
      "step": 17500
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.4168402850627899,
      "learning_rate": 3.770797973289644e-05,
      "loss": 1.7737,
      "step": 17600
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.43825483322143555,
      "learning_rate": 3.6715978723132436e-05,
      "loss": 1.7766,
      "step": 17700
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.4127149283885956,
      "learning_rate": 3.5734258457799407e-05,
      "loss": 1.7865,
      "step": 17800
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.423768550157547,
      "learning_rate": 3.476297842131287e-05,
      "loss": 1.7739,
      "step": 17900
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.41613784432411194,
      "learning_rate": 3.380229640203123e-05,
      "loss": 1.7851,
      "step": 18000
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.4288266897201538,
      "learning_rate": 3.285236846662215e-05,
      "loss": 1.769,
      "step": 18100
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.4079141914844513,
      "learning_rate": 3.191334893470907e-05,
      "loss": 1.7729,
      "step": 18200
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.4250068664550781,
      "learning_rate": 3.098539035380128e-05,
      "loss": 1.7691,
      "step": 18300
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.4411340057849884,
      "learning_rate": 3.006864347451195e-05,
      "loss": 1.7794,
      "step": 18400
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.4407234787940979,
      "learning_rate": 2.9163257226068152e-05,
      "loss": 1.7756,
      "step": 18500
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3677651882171631,
      "learning_rate": 2.8269378692116676e-05,
      "loss": 1.7715,
      "step": 18600
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.4166853129863739,
      "learning_rate": 2.738715308682962e-05,
      "loss": 1.7656,
      "step": 18700
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.41335293650627136,
      "learning_rate": 2.6516723731313897e-05,
      "loss": 1.771,
      "step": 18800
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.37924301624298096,
      "learning_rate": 2.5658232030328088e-05,
      "loss": 1.7672,
      "step": 18900
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.38206544518470764,
      "learning_rate": 2.4811817449310614e-05,
      "loss": 1.7689,
      "step": 19000
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.4103902280330658,
      "learning_rate": 2.3977617491723126e-05,
      "loss": 1.7724,
      "step": 19100
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.38415268063545227,
      "learning_rate": 2.3155767676712314e-05,
      "loss": 1.7681,
      "step": 19200
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.38694441318511963,
      "learning_rate": 2.2346401517094606e-05,
      "loss": 1.7746,
      "step": 19300
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.41456225514411926,
      "learning_rate": 2.1549650497666095e-05,
      "loss": 1.7745,
      "step": 19400
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.41493314504623413,
      "learning_rate": 2.076564405384258e-05,
      "loss": 1.7621,
      "step": 19500
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.4268884062767029,
      "learning_rate": 1.9994509550632156e-05,
      "loss": 1.7725,
      "step": 19600
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.4065045118331909,
      "learning_rate": 1.9236372261944168e-05,
      "loss": 1.7636,
      "step": 19700
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.3905247747898102,
      "learning_rate": 1.8491355350238248e-05,
      "loss": 1.7601,
      "step": 19800
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.4295255243778229,
      "learning_rate": 1.7759579846515662e-05,
      "loss": 1.7642,
      "step": 19900
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.4118395745754242,
      "learning_rate": 1.7041164630657758e-05,
      "loss": 1.772,
      "step": 20000
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.41179201006889343,
      "learning_rate": 1.6336226412113075e-05,
      "loss": 1.768,
      "step": 20100
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.40007251501083374,
      "learning_rate": 1.564487971093772e-05,
      "loss": 1.7731,
      "step": 20200
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.39757418632507324,
      "learning_rate": 1.4967236839190935e-05,
      "loss": 1.7737,
      "step": 20300
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.4040454924106598,
      "learning_rate": 1.4303407882689634e-05,
      "loss": 1.7716,
      "step": 20400
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.43343180418014526,
      "learning_rate": 1.3653500683124532e-05,
      "loss": 1.7743,
      "step": 20500
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.4033937454223633,
      "learning_rate": 1.3017620820540722e-05,
      "loss": 1.7661,
      "step": 20600
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.3946479856967926,
      "learning_rate": 1.2395871596185881e-05,
      "loss": 1.7749,
      "step": 20700
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.38762450218200684,
      "learning_rate": 1.1788354015728543e-05,
      "loss": 1.7702,
      "step": 20800
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.40320342779159546,
      "learning_rate": 1.1195166772849296e-05,
      "loss": 1.7708,
      "step": 20900
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.4248204827308655,
      "learning_rate": 1.0616406233207598e-05,
      "loss": 1.7726,
      "step": 21000
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.40912163257598877,
      "learning_rate": 1.0052166418786801e-05,
      "loss": 1.7753,
      "step": 21100
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.39834126830101013,
      "learning_rate": 9.502538992619891e-06,
      "loss": 1.7777,
      "step": 21200
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.42479079961776733,
      "learning_rate": 8.967613243898466e-06,
      "loss": 1.7611,
      "step": 21300
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.4046148657798767,
      "learning_rate": 8.447476073467309e-06,
      "loss": 1.7677,
      "step": 21400
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.4188443720340729,
      "learning_rate": 7.942211979707114e-06,
      "loss": 1.767,
      "step": 21500
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.40504834055900574,
      "learning_rate": 7.4519030448071845e-06,
      "loss": 1.7723,
      "step": 21600
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.40563297271728516,
      "learning_rate": 6.9766289214310725e-06,
      "loss": 1.7777,
      "step": 21700
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.4113779664039612,
      "learning_rate": 6.516466819776501e-06,
      "loss": 1.7704,
      "step": 21800
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.4058232009410858,
      "learning_rate": 6.071491495032344e-06,
      "loss": 1.7786,
      "step": 21900
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.4224437177181244,
      "learning_rate": 5.641775235234381e-06,
      "loss": 1.7636,
      "step": 22000
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.3770928382873535,
      "learning_rate": 5.22738784952167e-06,
      "loss": 1.7691,
      "step": 22100
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.42287614941596985,
      "learning_rate": 4.828396656795964e-06,
      "loss": 1.7725,
      "step": 22200
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.38312840461730957,
      "learning_rate": 4.4448664747853034e-06,
      "loss": 1.774,
      "step": 22300
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.40693390369415283,
      "learning_rate": 4.07685960951425e-06,
      "loss": 1.7689,
      "step": 22400
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.4217306673526764,
      "learning_rate": 3.7244358451819505e-06,
      "loss": 1.7793,
      "step": 22500
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.40621063113212585,
      "learning_rate": 3.3876524344499505e-06,
      "loss": 1.7689,
      "step": 22600
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.41478633880615234,
      "learning_rate": 3.0665640891413216e-06,
      "loss": 1.7668,
      "step": 22700
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.4075249433517456,
      "learning_rate": 2.7612229713524508e-06,
      "loss": 1.766,
      "step": 22800
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.4179040491580963,
      "learning_rate": 2.4716786849791063e-06,
      "loss": 1.7762,
      "step": 22900
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.4166405200958252,
      "learning_rate": 2.197978267658141e-06,
      "loss": 1.7683,
      "step": 23000
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.3933893144130707,
      "learning_rate": 1.9401661831259355e-06,
      "loss": 1.7645,
      "step": 23100
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.3918820023536682,
      "learning_rate": 1.698284313995202e-06,
      "loss": 1.7557,
      "step": 23200
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.4286416471004486,
      "learning_rate": 1.4723719549509018e-06,
      "loss": 1.7703,
      "step": 23300
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.41219744086265564,
      "learning_rate": 1.2624658063666639e-06,
      "loss": 1.7701,
      "step": 23400
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.3942449390888214,
      "learning_rate": 1.0685999683427207e-06,
      "loss": 1.7737,
      "step": 23500
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.40720540285110474,
      "learning_rate": 8.908059351661723e-07,
      "loss": 1.7674,
      "step": 23600
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.41624152660369873,
      "learning_rate": 7.291125901946027e-07,
      "loss": 1.7736,
      "step": 23700
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.39200079441070557,
      "learning_rate": 5.835462011638981e-07,
      "loss": 1.7653,
      "step": 23800
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.391929030418396,
      "learning_rate": 4.541304159208948e-07,
      "loss": 1.7673,
      "step": 23900
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.4252641797065735,
      "learning_rate": 3.408862585817407e-07,
      "loss": 1.7831,
      "step": 24000
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.4050365388393402,
      "learning_rate": 2.438321261164278e-07,
      "loss": 1.7539,
      "step": 24100
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.41519564390182495,
      "learning_rate": 1.6298378536012682e-07,
      "loss": 1.7785,
      "step": 24200
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.39737752079963684,
      "learning_rate": 9.835437045175866e-08,
      "loss": 1.7643,
      "step": 24300
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.3982950448989868,
      "learning_rate": 4.995438070041214e-08,
      "loss": 1.7657,
      "step": 24400
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.4102506935596466,
      "learning_rate": 1.779167887955291e-08,
      "loss": 1.7673,
      "step": 24500
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.4126627445220947,
      "learning_rate": 1.8714899497895844e-09,
      "loss": 1.7688,
      "step": 24600
    }
  ],
  "logging_steps": 100,
  "max_steps": 24648,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 4.1131287008988365e+18,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
