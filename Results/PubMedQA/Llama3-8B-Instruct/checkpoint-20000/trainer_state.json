{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.5795976519584656,
      "learning_rate": 0.0001998,
      "loss": 1.5385,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6523047089576721,
      "learning_rate": 0.0001996,
      "loss": 1.447,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5320574045181274,
      "learning_rate": 0.00019940000000000002,
      "loss": 1.4363,
      "step": 300
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5614504814147949,
      "learning_rate": 0.00019920000000000002,
      "loss": 1.4378,
      "step": 400
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5854209661483765,
      "learning_rate": 0.000199,
      "loss": 1.4355,
      "step": 500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5122101306915283,
      "learning_rate": 0.0001988,
      "loss": 1.4402,
      "step": 600
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47280505299568176,
      "learning_rate": 0.0001986,
      "loss": 1.4549,
      "step": 700
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.45033392310142517,
      "learning_rate": 0.0001984,
      "loss": 1.4348,
      "step": 800
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.490619421005249,
      "learning_rate": 0.00019820000000000002,
      "loss": 1.4476,
      "step": 900
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4776076078414917,
      "learning_rate": 0.00019800000000000002,
      "loss": 1.4432,
      "step": 1000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4714796841144562,
      "learning_rate": 0.0001978,
      "loss": 1.4351,
      "step": 1100
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4705211818218231,
      "learning_rate": 0.0001976,
      "loss": 1.4321,
      "step": 1200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.45685136318206787,
      "learning_rate": 0.0001974,
      "loss": 1.438,
      "step": 1300
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.512165367603302,
      "learning_rate": 0.0001972,
      "loss": 1.444,
      "step": 1400
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5764269828796387,
      "learning_rate": 0.00019700000000000002,
      "loss": 1.4472,
      "step": 1500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5590420961380005,
      "learning_rate": 0.0001968,
      "loss": 1.4455,
      "step": 1600
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7206591963768005,
      "learning_rate": 0.0001966,
      "loss": 1.4457,
      "step": 1700
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.48716622591018677,
      "learning_rate": 0.0001964,
      "loss": 1.4453,
      "step": 1800
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4696999490261078,
      "learning_rate": 0.0001962,
      "loss": 1.4331,
      "step": 1900
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.458239883184433,
      "learning_rate": 0.000196,
      "loss": 1.4474,
      "step": 2000
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6132866740226746,
      "learning_rate": 0.00019580000000000002,
      "loss": 1.427,
      "step": 2100
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5558908581733704,
      "learning_rate": 0.0001956,
      "loss": 1.4431,
      "step": 2200
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5636329054832458,
      "learning_rate": 0.0001954,
      "loss": 1.4337,
      "step": 2300
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5040302276611328,
      "learning_rate": 0.0001952,
      "loss": 1.4563,
      "step": 2400
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.556709349155426,
      "learning_rate": 0.000195,
      "loss": 1.4631,
      "step": 2500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.537499189376831,
      "learning_rate": 0.0001948,
      "loss": 1.4509,
      "step": 2600
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5661356449127197,
      "learning_rate": 0.00019460000000000001,
      "loss": 1.4448,
      "step": 2700
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5884741544723511,
      "learning_rate": 0.0001944,
      "loss": 1.4429,
      "step": 2800
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5691575407981873,
      "learning_rate": 0.0001942,
      "loss": 1.4445,
      "step": 2900
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5601754188537598,
      "learning_rate": 0.000194,
      "loss": 1.457,
      "step": 3000
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.616183876991272,
      "learning_rate": 0.0001938,
      "loss": 1.4653,
      "step": 3100
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5749704837799072,
      "learning_rate": 0.00019360000000000002,
      "loss": 1.4489,
      "step": 3200
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5768247246742249,
      "learning_rate": 0.0001934,
      "loss": 1.4444,
      "step": 3300
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5504340529441833,
      "learning_rate": 0.0001932,
      "loss": 1.4547,
      "step": 3400
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7295146584510803,
      "learning_rate": 0.000193,
      "loss": 1.4579,
      "step": 3500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6152468919754028,
      "learning_rate": 0.0001928,
      "loss": 1.4515,
      "step": 3600
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6167387962341309,
      "learning_rate": 0.0001926,
      "loss": 1.4605,
      "step": 3700
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7252178192138672,
      "learning_rate": 0.00019240000000000001,
      "loss": 1.4543,
      "step": 3800
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5475459098815918,
      "learning_rate": 0.0001922,
      "loss": 1.4632,
      "step": 3900
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6071264147758484,
      "learning_rate": 0.000192,
      "loss": 1.4794,
      "step": 4000
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6953980326652527,
      "learning_rate": 0.0001918,
      "loss": 1.4576,
      "step": 4100
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6187163591384888,
      "learning_rate": 0.0001916,
      "loss": 1.4715,
      "step": 4200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6528695225715637,
      "learning_rate": 0.0001914,
      "loss": 1.4613,
      "step": 4300
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6329741477966309,
      "learning_rate": 0.0001912,
      "loss": 1.4539,
      "step": 4400
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7285433411598206,
      "learning_rate": 0.000191,
      "loss": 1.4555,
      "step": 4500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6598461866378784,
      "learning_rate": 0.0001908,
      "loss": 1.4757,
      "step": 4600
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.734218955039978,
      "learning_rate": 0.0001906,
      "loss": 1.4608,
      "step": 4700
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7120314240455627,
      "learning_rate": 0.0001904,
      "loss": 1.4828,
      "step": 4800
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.985375702381134,
      "learning_rate": 0.0001902,
      "loss": 1.4866,
      "step": 4900
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6979266405105591,
      "learning_rate": 0.00019,
      "loss": 1.4699,
      "step": 5000
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7137866020202637,
      "learning_rate": 0.0001898,
      "loss": 1.4817,
      "step": 5100
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7531825304031372,
      "learning_rate": 0.0001896,
      "loss": 1.4831,
      "step": 5200
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7568873763084412,
      "learning_rate": 0.0001894,
      "loss": 1.4751,
      "step": 5300
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.779904305934906,
      "learning_rate": 0.0001892,
      "loss": 1.497,
      "step": 5400
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.703446090221405,
      "learning_rate": 0.00018899999999999999,
      "loss": 1.4915,
      "step": 5500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7576552033424377,
      "learning_rate": 0.0001888,
      "loss": 1.4776,
      "step": 5600
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7502580285072327,
      "learning_rate": 0.0001886,
      "loss": 1.496,
      "step": 5700
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7827948927879333,
      "learning_rate": 0.0001884,
      "loss": 1.4932,
      "step": 5800
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7918341755867004,
      "learning_rate": 0.0001882,
      "loss": 1.4961,
      "step": 5900
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8051194548606873,
      "learning_rate": 0.000188,
      "loss": 1.4894,
      "step": 6000
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8155494332313538,
      "learning_rate": 0.0001878,
      "loss": 1.4961,
      "step": 6100
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.793769121170044,
      "learning_rate": 0.0001876,
      "loss": 1.4925,
      "step": 6200
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8742356896400452,
      "learning_rate": 0.00018740000000000003,
      "loss": 1.5055,
      "step": 6300
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9114035367965698,
      "learning_rate": 0.00018720000000000002,
      "loss": 1.497,
      "step": 6400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9163503050804138,
      "learning_rate": 0.00018700000000000002,
      "loss": 1.5009,
      "step": 6500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9298529624938965,
      "learning_rate": 0.00018680000000000001,
      "loss": 1.4795,
      "step": 6600
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8346083760261536,
      "learning_rate": 0.0001866,
      "loss": 1.4794,
      "step": 6700
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7602598071098328,
      "learning_rate": 0.00018640000000000003,
      "loss": 1.4917,
      "step": 6800
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7962440252304077,
      "learning_rate": 0.00018620000000000003,
      "loss": 1.5125,
      "step": 6900
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8244149684906006,
      "learning_rate": 0.00018600000000000002,
      "loss": 1.505,
      "step": 7000
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0555694103240967,
      "learning_rate": 0.00018580000000000002,
      "loss": 1.499,
      "step": 7100
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.946490466594696,
      "learning_rate": 0.0001856,
      "loss": 1.4975,
      "step": 7200
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8740202188491821,
      "learning_rate": 0.0001854,
      "loss": 1.5029,
      "step": 7300
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9172614216804504,
      "learning_rate": 0.00018520000000000003,
      "loss": 1.5154,
      "step": 7400
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8559490442276001,
      "learning_rate": 0.00018500000000000002,
      "loss": 1.5091,
      "step": 7500
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8528008460998535,
      "learning_rate": 0.00018480000000000002,
      "loss": 1.4965,
      "step": 7600
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8708293437957764,
      "learning_rate": 0.00018460000000000001,
      "loss": 1.4964,
      "step": 7700
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.905544638633728,
      "learning_rate": 0.0001844,
      "loss": 1.4911,
      "step": 7800
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0157307386398315,
      "learning_rate": 0.0001842,
      "loss": 1.503,
      "step": 7900
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0108447074890137,
      "learning_rate": 0.00018400000000000003,
      "loss": 1.5136,
      "step": 8000
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8894484639167786,
      "learning_rate": 0.00018380000000000002,
      "loss": 1.5042,
      "step": 8100
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9614408016204834,
      "learning_rate": 0.00018360000000000002,
      "loss": 1.5072,
      "step": 8200
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0727269649505615,
      "learning_rate": 0.0001834,
      "loss": 1.5028,
      "step": 8300
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9591959118843079,
      "learning_rate": 0.0001832,
      "loss": 1.4957,
      "step": 8400
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0598781108856201,
      "learning_rate": 0.000183,
      "loss": 1.5019,
      "step": 8500
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9033932089805603,
      "learning_rate": 0.00018280000000000003,
      "loss": 1.5045,
      "step": 8600
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9538824558258057,
      "learning_rate": 0.00018260000000000002,
      "loss": 1.5018,
      "step": 8700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8327365517616272,
      "learning_rate": 0.00018240000000000002,
      "loss": 1.4941,
      "step": 8800
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0031383037567139,
      "learning_rate": 0.0001822,
      "loss": 1.517,
      "step": 8900
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0868054628372192,
      "learning_rate": 0.000182,
      "loss": 1.5065,
      "step": 9000
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.229804277420044,
      "learning_rate": 0.00018180000000000003,
      "loss": 1.5137,
      "step": 9100
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1395270824432373,
      "learning_rate": 0.00018160000000000002,
      "loss": 1.5115,
      "step": 9200
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9700587391853333,
      "learning_rate": 0.00018140000000000002,
      "loss": 1.5207,
      "step": 9300
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9822769165039062,
      "learning_rate": 0.0001812,
      "loss": 1.5123,
      "step": 9400
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.191853404045105,
      "learning_rate": 0.000181,
      "loss": 1.518,
      "step": 9500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9837140440940857,
      "learning_rate": 0.0001808,
      "loss": 1.4943,
      "step": 9600
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0522791147232056,
      "learning_rate": 0.00018060000000000003,
      "loss": 1.5011,
      "step": 9700
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4465161561965942,
      "learning_rate": 0.00018040000000000002,
      "loss": 1.507,
      "step": 9800
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0616698265075684,
      "learning_rate": 0.00018020000000000002,
      "loss": 1.5112,
      "step": 9900
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9367948174476624,
      "learning_rate": 0.00018,
      "loss": 1.5073,
      "step": 10000
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.888264536857605,
      "learning_rate": 0.0001798,
      "loss": 1.5211,
      "step": 10100
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.034954309463501,
      "learning_rate": 0.0001796,
      "loss": 1.4891,
      "step": 10200
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1265555620193481,
      "learning_rate": 0.00017940000000000002,
      "loss": 1.5228,
      "step": 10300
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0830618143081665,
      "learning_rate": 0.00017920000000000002,
      "loss": 1.504,
      "step": 10400
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.0347737073898315,
      "learning_rate": 0.00017900000000000001,
      "loss": 1.5076,
      "step": 10500
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.093111276626587,
      "learning_rate": 0.0001788,
      "loss": 1.5144,
      "step": 10600
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9668505787849426,
      "learning_rate": 0.0001786,
      "loss": 1.4998,
      "step": 10700
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.409142255783081,
      "learning_rate": 0.0001784,
      "loss": 1.5191,
      "step": 10800
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1336275339126587,
      "learning_rate": 0.00017820000000000002,
      "loss": 1.5154,
      "step": 10900
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9161990880966187,
      "learning_rate": 0.00017800000000000002,
      "loss": 1.5081,
      "step": 11000
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.4786573648452759,
      "learning_rate": 0.0001778,
      "loss": 1.5051,
      "step": 11100
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0542840957641602,
      "learning_rate": 0.0001776,
      "loss": 1.5131,
      "step": 11200
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9682841897010803,
      "learning_rate": 0.0001774,
      "loss": 1.5262,
      "step": 11300
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9106001853942871,
      "learning_rate": 0.0001772,
      "loss": 1.512,
      "step": 11400
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.030389666557312,
      "learning_rate": 0.00017700000000000002,
      "loss": 1.5079,
      "step": 11500
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1027462482452393,
      "learning_rate": 0.00017680000000000001,
      "loss": 1.5093,
      "step": 11600
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1342792510986328,
      "learning_rate": 0.0001766,
      "loss": 1.5099,
      "step": 11700
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0963646173477173,
      "learning_rate": 0.0001764,
      "loss": 1.5057,
      "step": 11800
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.031693458557129,
      "learning_rate": 0.0001762,
      "loss": 1.5115,
      "step": 11900
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0479551553726196,
      "learning_rate": 0.00017600000000000002,
      "loss": 1.503,
      "step": 12000
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2570600509643555,
      "learning_rate": 0.00017580000000000002,
      "loss": 1.5159,
      "step": 12100
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9783658981323242,
      "learning_rate": 0.0001756,
      "loss": 1.5227,
      "step": 12200
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0841659307479858,
      "learning_rate": 0.0001754,
      "loss": 1.5221,
      "step": 12300
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0455255508422852,
      "learning_rate": 0.0001752,
      "loss": 1.5144,
      "step": 12400
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1129475831985474,
      "learning_rate": 0.000175,
      "loss": 1.5169,
      "step": 12500
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0359694957733154,
      "learning_rate": 0.00017480000000000002,
      "loss": 1.5026,
      "step": 12600
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2830437421798706,
      "learning_rate": 0.00017460000000000002,
      "loss": 1.5079,
      "step": 12700
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2481677532196045,
      "learning_rate": 0.0001744,
      "loss": 1.496,
      "step": 12800
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.1294925212860107,
      "learning_rate": 0.0001742,
      "loss": 1.4992,
      "step": 12900
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0382399559020996,
      "learning_rate": 0.000174,
      "loss": 1.5117,
      "step": 13000
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0200992822647095,
      "learning_rate": 0.0001738,
      "loss": 1.4948,
      "step": 13100
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9718788862228394,
      "learning_rate": 0.00017360000000000002,
      "loss": 1.5059,
      "step": 13200
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9528949856758118,
      "learning_rate": 0.0001734,
      "loss": 1.5068,
      "step": 13300
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0307101011276245,
      "learning_rate": 0.0001732,
      "loss": 1.5125,
      "step": 13400
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1238369941711426,
      "learning_rate": 0.000173,
      "loss": 1.5039,
      "step": 13500
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1704837083816528,
      "learning_rate": 0.0001728,
      "loss": 1.5094,
      "step": 13600
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.054356336593628,
      "learning_rate": 0.0001726,
      "loss": 1.5208,
      "step": 13700
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.946785032749176,
      "learning_rate": 0.00017240000000000002,
      "loss": 1.5116,
      "step": 13800
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.1898428201675415,
      "learning_rate": 0.0001722,
      "loss": 1.5086,
      "step": 13900
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9601500630378723,
      "learning_rate": 0.000172,
      "loss": 1.51,
      "step": 14000
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1401972770690918,
      "learning_rate": 0.0001718,
      "loss": 1.5192,
      "step": 14100
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.1350221633911133,
      "learning_rate": 0.0001716,
      "loss": 1.5212,
      "step": 14200
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0223209857940674,
      "learning_rate": 0.0001714,
      "loss": 1.5171,
      "step": 14300
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.9648323655128479,
      "learning_rate": 0.00017120000000000001,
      "loss": 1.5094,
      "step": 14400
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1870797872543335,
      "learning_rate": 0.000171,
      "loss": 1.4992,
      "step": 14500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.976919949054718,
      "learning_rate": 0.0001708,
      "loss": 1.5053,
      "step": 14600
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1505072116851807,
      "learning_rate": 0.0001706,
      "loss": 1.506,
      "step": 14700
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.136609673500061,
      "learning_rate": 0.0001704,
      "loss": 1.5206,
      "step": 14800
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.107358455657959,
      "learning_rate": 0.00017020000000000002,
      "loss": 1.5066,
      "step": 14900
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.2036324739456177,
      "learning_rate": 0.00017,
      "loss": 1.523,
      "step": 15000
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0487762689590454,
      "learning_rate": 0.0001698,
      "loss": 1.5129,
      "step": 15100
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0319786071777344,
      "learning_rate": 0.0001696,
      "loss": 1.5014,
      "step": 15200
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9384340047836304,
      "learning_rate": 0.0001694,
      "loss": 1.5116,
      "step": 15300
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0599194765090942,
      "learning_rate": 0.0001692,
      "loss": 1.5212,
      "step": 15400
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.2817397117614746,
      "learning_rate": 0.00016900000000000002,
      "loss": 1.5089,
      "step": 15500
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0333538055419922,
      "learning_rate": 0.0001688,
      "loss": 1.5135,
      "step": 15600
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1369320154190063,
      "learning_rate": 0.0001686,
      "loss": 1.5063,
      "step": 15700
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0414634943008423,
      "learning_rate": 0.0001684,
      "loss": 1.5166,
      "step": 15800
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3775495290756226,
      "learning_rate": 0.0001682,
      "loss": 1.5123,
      "step": 15900
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.181045413017273,
      "learning_rate": 0.000168,
      "loss": 1.5273,
      "step": 16000
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9552167654037476,
      "learning_rate": 0.0001678,
      "loss": 1.515,
      "step": 16100
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.041664719581604,
      "learning_rate": 0.0001676,
      "loss": 1.5074,
      "step": 16200
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.057199478149414,
      "learning_rate": 0.0001674,
      "loss": 1.507,
      "step": 16300
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1160153150558472,
      "learning_rate": 0.0001672,
      "loss": 1.5087,
      "step": 16400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1737405061721802,
      "learning_rate": 0.000167,
      "loss": 1.5099,
      "step": 16500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1436713933944702,
      "learning_rate": 0.0001668,
      "loss": 1.5206,
      "step": 16600
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.350915551185608,
      "learning_rate": 0.0001666,
      "loss": 1.5133,
      "step": 16700
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0201163291931152,
      "learning_rate": 0.0001664,
      "loss": 1.5015,
      "step": 16800
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1733477115631104,
      "learning_rate": 0.0001662,
      "loss": 1.53,
      "step": 16900
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0041898488998413,
      "learning_rate": 0.000166,
      "loss": 1.5131,
      "step": 17000
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.096932053565979,
      "learning_rate": 0.0001658,
      "loss": 1.5041,
      "step": 17100
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.989629328250885,
      "learning_rate": 0.0001656,
      "loss": 1.51,
      "step": 17200
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.1747909784317017,
      "learning_rate": 0.0001654,
      "loss": 1.5088,
      "step": 17300
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.0687429904937744,
      "learning_rate": 0.0001652,
      "loss": 1.5253,
      "step": 17400
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.137613296508789,
      "learning_rate": 0.000165,
      "loss": 1.521,
      "step": 17500
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0524190664291382,
      "learning_rate": 0.0001648,
      "loss": 1.5079,
      "step": 17600
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.3575453758239746,
      "learning_rate": 0.0001646,
      "loss": 1.4983,
      "step": 17700
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0323854684829712,
      "learning_rate": 0.0001644,
      "loss": 1.513,
      "step": 17800
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.176839828491211,
      "learning_rate": 0.0001642,
      "loss": 1.5091,
      "step": 17900
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1502035856246948,
      "learning_rate": 0.000164,
      "loss": 1.4968,
      "step": 18000
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3788235187530518,
      "learning_rate": 0.0001638,
      "loss": 1.4994,
      "step": 18100
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1913195848464966,
      "learning_rate": 0.0001636,
      "loss": 1.5156,
      "step": 18200
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.168130874633789,
      "learning_rate": 0.0001634,
      "loss": 1.5065,
      "step": 18300
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9784571528434753,
      "learning_rate": 0.0001632,
      "loss": 1.5008,
      "step": 18400
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.1455438137054443,
      "learning_rate": 0.000163,
      "loss": 1.5191,
      "step": 18500
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.1628456115722656,
      "learning_rate": 0.0001628,
      "loss": 1.5125,
      "step": 18600
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0510637760162354,
      "learning_rate": 0.0001626,
      "loss": 1.5033,
      "step": 18700
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2143735885620117,
      "learning_rate": 0.00016240000000000002,
      "loss": 1.5093,
      "step": 18800
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1776888370513916,
      "learning_rate": 0.0001622,
      "loss": 1.5028,
      "step": 18900
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1096094846725464,
      "learning_rate": 0.000162,
      "loss": 1.5246,
      "step": 19000
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.0772514343261719,
      "learning_rate": 0.00016180000000000003,
      "loss": 1.519,
      "step": 19100
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1283479928970337,
      "learning_rate": 0.00016160000000000002,
      "loss": 1.5106,
      "step": 19200
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4668017625808716,
      "learning_rate": 0.00016140000000000002,
      "loss": 1.5108,
      "step": 19300
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2656644582748413,
      "learning_rate": 0.00016120000000000002,
      "loss": 1.5079,
      "step": 19400
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1840111017227173,
      "learning_rate": 0.000161,
      "loss": 1.512,
      "step": 19500
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2601531744003296,
      "learning_rate": 0.0001608,
      "loss": 1.5154,
      "step": 19600
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2900052070617676,
      "learning_rate": 0.00016060000000000003,
      "loss": 1.5165,
      "step": 19700
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2400504350662231,
      "learning_rate": 0.00016040000000000002,
      "loss": 1.5084,
      "step": 19800
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.0682796239852905,
      "learning_rate": 0.00016020000000000002,
      "loss": 1.5148,
      "step": 19900
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1683405637741089,
      "learning_rate": 0.00016,
      "loss": 1.5157,
      "step": 20000
    }
  ],
  "logging_steps": 100,
  "max_steps": 100000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 4.0580764157784883e+18,
  "train_batch_size": 10,
  "trial_name": null,
  "trial_params": null
}
