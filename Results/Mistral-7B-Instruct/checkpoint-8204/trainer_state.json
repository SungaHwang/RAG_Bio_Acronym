{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8204,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02437835202340322,
      "grad_norm": 3.181697368621826,
      "learning_rate": 0.00019878108239882984,
      "loss": 1.8242,
      "step": 100
    },
    {
      "epoch": 0.04875670404680644,
      "grad_norm": 2.759354829788208,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.3318,
      "step": 200
    },
    {
      "epoch": 0.07313505607020965,
      "grad_norm": 2.102668523788452,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.2442,
      "step": 300
    },
    {
      "epoch": 0.09751340809361288,
      "grad_norm": 2.1890926361083984,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.2423,
      "step": 400
    },
    {
      "epoch": 0.12189176011701609,
      "grad_norm": 1.646402359008789,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.2358,
      "step": 500
    },
    {
      "epoch": 0.1462701121404193,
      "grad_norm": 2.5659172534942627,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.251,
      "step": 600
    },
    {
      "epoch": 0.17064846416382254,
      "grad_norm": 2.6764018535614014,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.2501,
      "step": 700
    },
    {
      "epoch": 0.19502681618722575,
      "grad_norm": 1.867554783821106,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.201,
      "step": 800
    },
    {
      "epoch": 0.21940516821062897,
      "grad_norm": 3.0721609592437744,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.2522,
      "step": 900
    },
    {
      "epoch": 0.24378352023403219,
      "grad_norm": 2.103956460952759,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.1768,
      "step": 1000
    },
    {
      "epoch": 0.2681618722574354,
      "grad_norm": 1.4910064935684204,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.2027,
      "step": 1100
    },
    {
      "epoch": 0.2925402242808386,
      "grad_norm": 2.205195665359497,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.1893,
      "step": 1200
    },
    {
      "epoch": 0.3169185763042418,
      "grad_norm": 1.3185746669769287,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.1846,
      "step": 1300
    },
    {
      "epoch": 0.3412969283276451,
      "grad_norm": 5.6637701988220215,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.1847,
      "step": 1400
    },
    {
      "epoch": 0.3656752803510483,
      "grad_norm": 1.368777871131897,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.1437,
      "step": 1500
    },
    {
      "epoch": 0.3900536323744515,
      "grad_norm": 1.9249910116195679,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.1687,
      "step": 1600
    },
    {
      "epoch": 0.4144319843978547,
      "grad_norm": 2.5060975551605225,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.1229,
      "step": 1700
    },
    {
      "epoch": 0.43881033642125794,
      "grad_norm": 2.1623916625976562,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.1604,
      "step": 1800
    },
    {
      "epoch": 0.46318868844466116,
      "grad_norm": 1.588279366493225,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.1283,
      "step": 1900
    },
    {
      "epoch": 0.48756704046806437,
      "grad_norm": 1.6029797792434692,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.1129,
      "step": 2000
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 1.5714064836502075,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.1363,
      "step": 2100
    },
    {
      "epoch": 0.5363237445148707,
      "grad_norm": 2.428605079650879,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.1396,
      "step": 2200
    },
    {
      "epoch": 0.560702096538274,
      "grad_norm": 2.228468179702759,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.1323,
      "step": 2300
    },
    {
      "epoch": 0.5850804485616772,
      "grad_norm": 2.082493305206299,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.1015,
      "step": 2400
    },
    {
      "epoch": 0.6094588005850804,
      "grad_norm": 1.4158481359481812,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.0653,
      "step": 2500
    },
    {
      "epoch": 0.6338371526084836,
      "grad_norm": 2.933357000350952,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.0742,
      "step": 2600
    },
    {
      "epoch": 0.6582155046318869,
      "grad_norm": 2.1267127990722656,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.072,
      "step": 2700
    },
    {
      "epoch": 0.6825938566552902,
      "grad_norm": 1.519683837890625,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.1395,
      "step": 2800
    },
    {
      "epoch": 0.7069722086786934,
      "grad_norm": 1.3175886869430542,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.0877,
      "step": 2900
    },
    {
      "epoch": 0.7313505607020966,
      "grad_norm": 1.7274479866027832,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.0608,
      "step": 3000
    },
    {
      "epoch": 0.7557289127254998,
      "grad_norm": 2.4471631050109863,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.1082,
      "step": 3100
    },
    {
      "epoch": 0.780107264748903,
      "grad_norm": 1.1911900043487549,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.0825,
      "step": 3200
    },
    {
      "epoch": 0.8044856167723062,
      "grad_norm": 1.1342140436172485,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.0611,
      "step": 3300
    },
    {
      "epoch": 0.8288639687957094,
      "grad_norm": 1.1086430549621582,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.0242,
      "step": 3400
    },
    {
      "epoch": 0.8532423208191127,
      "grad_norm": 4.0629658699035645,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.03,
      "step": 3500
    },
    {
      "epoch": 0.8776206728425159,
      "grad_norm": 2.212984085083008,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.0628,
      "step": 3600
    },
    {
      "epoch": 0.9019990248659191,
      "grad_norm": 1.686180830001831,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.0604,
      "step": 3700
    },
    {
      "epoch": 0.9263773768893223,
      "grad_norm": 1.1605898141860962,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.0244,
      "step": 3800
    },
    {
      "epoch": 0.9507557289127255,
      "grad_norm": 2.0102248191833496,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.0164,
      "step": 3900
    },
    {
      "epoch": 0.9751340809361287,
      "grad_norm": 2.961073160171509,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.0421,
      "step": 4000
    },
    {
      "epoch": 0.999512432959532,
      "grad_norm": 1.5446171760559082,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.0658,
      "step": 4100
    },
    {
      "epoch": 1.023890784982935,
      "grad_norm": 1.2311944961547852,
      "learning_rate": 0.00014880546075085325,
      "loss": 0.9449,
      "step": 4200
    },
    {
      "epoch": 1.0482691370063384,
      "grad_norm": 1.021507740020752,
      "learning_rate": 0.0001475865431496831,
      "loss": 0.9434,
      "step": 4300
    },
    {
      "epoch": 1.0726474890297415,
      "grad_norm": 0.9666181802749634,
      "learning_rate": 0.00014636762554851292,
      "loss": 0.9455,
      "step": 4400
    },
    {
      "epoch": 1.0970258410531448,
      "grad_norm": 0.9235323667526245,
      "learning_rate": 0.00014514870794734276,
      "loss": 0.9313,
      "step": 4500
    },
    {
      "epoch": 1.121404193076548,
      "grad_norm": 3.3039441108703613,
      "learning_rate": 0.0001439297903461726,
      "loss": 0.9472,
      "step": 4600
    },
    {
      "epoch": 1.1457825450999513,
      "grad_norm": 1.1092803478240967,
      "learning_rate": 0.00014271087274500245,
      "loss": 0.9617,
      "step": 4700
    },
    {
      "epoch": 1.1701608971233544,
      "grad_norm": 1.1237677335739136,
      "learning_rate": 0.0001414919551438323,
      "loss": 0.9568,
      "step": 4800
    },
    {
      "epoch": 1.1945392491467577,
      "grad_norm": 1.1748417615890503,
      "learning_rate": 0.00014027303754266213,
      "loss": 0.9623,
      "step": 4900
    },
    {
      "epoch": 1.218917601170161,
      "grad_norm": 1.0971065759658813,
      "learning_rate": 0.00013905411994149196,
      "loss": 0.9591,
      "step": 5000
    },
    {
      "epoch": 1.2432959531935641,
      "grad_norm": 1.2549774646759033,
      "learning_rate": 0.00013783520234032182,
      "loss": 0.949,
      "step": 5100
    },
    {
      "epoch": 1.2676743052169672,
      "grad_norm": 1.0442975759506226,
      "learning_rate": 0.00013661628473915166,
      "loss": 0.9366,
      "step": 5200
    },
    {
      "epoch": 1.2920526572403706,
      "grad_norm": 0.7975189089775085,
      "learning_rate": 0.00013539736713798147,
      "loss": 0.9445,
      "step": 5300
    },
    {
      "epoch": 1.3164310092637739,
      "grad_norm": 1.1195608377456665,
      "learning_rate": 0.0001341784495368113,
      "loss": 0.9593,
      "step": 5400
    },
    {
      "epoch": 1.340809361287177,
      "grad_norm": 0.8703979253768921,
      "learning_rate": 0.00013295953193564114,
      "loss": 0.9685,
      "step": 5500
    },
    {
      "epoch": 1.36518771331058,
      "grad_norm": 0.8992469906806946,
      "learning_rate": 0.000131740614334471,
      "loss": 0.9565,
      "step": 5600
    },
    {
      "epoch": 1.3895660653339834,
      "grad_norm": 0.9714943170547485,
      "learning_rate": 0.00013052169673330083,
      "loss": 0.96,
      "step": 5700
    },
    {
      "epoch": 1.4139444173573867,
      "grad_norm": 1.4204410314559937,
      "learning_rate": 0.00012930277913213067,
      "loss": 0.9457,
      "step": 5800
    },
    {
      "epoch": 1.4383227693807898,
      "grad_norm": 0.7083669304847717,
      "learning_rate": 0.0001280838615309605,
      "loss": 0.9601,
      "step": 5900
    },
    {
      "epoch": 1.462701121404193,
      "grad_norm": 0.8264449238777161,
      "learning_rate": 0.00012686494392979037,
      "loss": 0.9378,
      "step": 6000
    },
    {
      "epoch": 1.4870794734275963,
      "grad_norm": 1.2466151714324951,
      "learning_rate": 0.0001256460263286202,
      "loss": 0.9655,
      "step": 6100
    },
    {
      "epoch": 1.5114578254509996,
      "grad_norm": 1.348124384880066,
      "learning_rate": 0.00012442710872745004,
      "loss": 0.97,
      "step": 6200
    },
    {
      "epoch": 1.5358361774744027,
      "grad_norm": 0.917264461517334,
      "learning_rate": 0.00012320819112627987,
      "loss": 0.944,
      "step": 6300
    },
    {
      "epoch": 1.5602145294978058,
      "grad_norm": 1.599104642868042,
      "learning_rate": 0.00012198927352510972,
      "loss": 0.9169,
      "step": 6400
    },
    {
      "epoch": 1.5845928815212091,
      "grad_norm": 1.432161808013916,
      "learning_rate": 0.00012077035592393954,
      "loss": 0.9391,
      "step": 6500
    },
    {
      "epoch": 1.6089712335446125,
      "grad_norm": 2.09645938873291,
      "learning_rate": 0.00011955143832276938,
      "loss": 0.9278,
      "step": 6600
    },
    {
      "epoch": 1.6333495855680156,
      "grad_norm": 1.3665556907653809,
      "learning_rate": 0.00011833252072159921,
      "loss": 0.9786,
      "step": 6700
    },
    {
      "epoch": 1.6577279375914187,
      "grad_norm": 1.0606465339660645,
      "learning_rate": 0.00011711360312042908,
      "loss": 0.9282,
      "step": 6800
    },
    {
      "epoch": 1.682106289614822,
      "grad_norm": 0.6949618458747864,
      "learning_rate": 0.00011589468551925891,
      "loss": 0.9579,
      "step": 6900
    },
    {
      "epoch": 1.7064846416382253,
      "grad_norm": 1.3710505962371826,
      "learning_rate": 0.00011467576791808873,
      "loss": 0.9239,
      "step": 7000
    },
    {
      "epoch": 1.7308629936616284,
      "grad_norm": 0.8204217553138733,
      "learning_rate": 0.00011345685031691857,
      "loss": 0.94,
      "step": 7100
    },
    {
      "epoch": 1.7552413456850315,
      "grad_norm": 0.8728550672531128,
      "learning_rate": 0.00011223793271574843,
      "loss": 0.8862,
      "step": 7200
    },
    {
      "epoch": 1.7796196977084349,
      "grad_norm": 0.7841248512268066,
      "learning_rate": 0.00011101901511457827,
      "loss": 0.9485,
      "step": 7300
    },
    {
      "epoch": 1.8039980497318382,
      "grad_norm": 1.231462001800537,
      "learning_rate": 0.0001098000975134081,
      "loss": 0.9462,
      "step": 7400
    },
    {
      "epoch": 1.8283764017552413,
      "grad_norm": 1.5502811670303345,
      "learning_rate": 0.00010858117991223794,
      "loss": 0.9128,
      "step": 7500
    },
    {
      "epoch": 1.8527547537786444,
      "grad_norm": 1.1125996112823486,
      "learning_rate": 0.00010736226231106778,
      "loss": 0.9035,
      "step": 7600
    },
    {
      "epoch": 1.8771331058020477,
      "grad_norm": 1.5942139625549316,
      "learning_rate": 0.00010614334470989762,
      "loss": 0.9247,
      "step": 7700
    },
    {
      "epoch": 1.901511457825451,
      "grad_norm": 1.3378932476043701,
      "learning_rate": 0.00010492442710872745,
      "loss": 0.9477,
      "step": 7800
    },
    {
      "epoch": 1.9258898098488544,
      "grad_norm": 0.855302631855011,
      "learning_rate": 0.00010370550950755729,
      "loss": 0.9144,
      "step": 7900
    },
    {
      "epoch": 1.9502681618722575,
      "grad_norm": 0.6993356347084045,
      "learning_rate": 0.00010248659190638714,
      "loss": 0.9427,
      "step": 8000
    },
    {
      "epoch": 1.9746465138956606,
      "grad_norm": 0.974097728729248,
      "learning_rate": 0.00010126767430521697,
      "loss": 0.9667,
      "step": 8100
    },
    {
      "epoch": 1.999024865919064,
      "grad_norm": 0.7469705939292908,
      "learning_rate": 0.00010004875670404681,
      "loss": 0.9371,
      "step": 8200
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3261705014493184e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
