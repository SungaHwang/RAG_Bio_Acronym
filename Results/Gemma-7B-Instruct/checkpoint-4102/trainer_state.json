{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4102,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02437835202340322,
      "grad_norm": 7.885652542114258,
      "learning_rate": 0.00019878108239882984,
      "loss": 3.8494,
      "step": 100
    },
    {
      "epoch": 0.04875670404680644,
      "grad_norm": 4.9701151847839355,
      "learning_rate": 0.00019756216479765968,
      "loss": 1.9399,
      "step": 200
    },
    {
      "epoch": 0.07313505607020965,
      "grad_norm": 6.60969352722168,
      "learning_rate": 0.00019634324719648954,
      "loss": 1.8187,
      "step": 300
    },
    {
      "epoch": 0.09751340809361288,
      "grad_norm": 3.8199644088745117,
      "learning_rate": 0.00019512432959531938,
      "loss": 1.7245,
      "step": 400
    },
    {
      "epoch": 0.12189176011701609,
      "grad_norm": 4.725223541259766,
      "learning_rate": 0.0001939054119941492,
      "loss": 1.7618,
      "step": 500
    },
    {
      "epoch": 0.1462701121404193,
      "grad_norm": 6.713329315185547,
      "learning_rate": 0.00019268649439297902,
      "loss": 1.7492,
      "step": 600
    },
    {
      "epoch": 0.17064846416382254,
      "grad_norm": 3.8568661212921143,
      "learning_rate": 0.00019146757679180888,
      "loss": 1.734,
      "step": 700
    },
    {
      "epoch": 0.19502681618722575,
      "grad_norm": 7.023652076721191,
      "learning_rate": 0.00019024865919063872,
      "loss": 1.7069,
      "step": 800
    },
    {
      "epoch": 0.21940516821062897,
      "grad_norm": 5.16474723815918,
      "learning_rate": 0.00018902974158946855,
      "loss": 1.733,
      "step": 900
    },
    {
      "epoch": 0.24378352023403219,
      "grad_norm": 5.315758228302002,
      "learning_rate": 0.0001878108239882984,
      "loss": 1.6391,
      "step": 1000
    },
    {
      "epoch": 0.2681618722574354,
      "grad_norm": 5.321823596954346,
      "learning_rate": 0.00018659190638712825,
      "loss": 1.6347,
      "step": 1100
    },
    {
      "epoch": 0.2925402242808386,
      "grad_norm": 9.205940246582031,
      "learning_rate": 0.00018537298878595809,
      "loss": 1.5981,
      "step": 1200
    },
    {
      "epoch": 0.3169185763042418,
      "grad_norm": 4.301296710968018,
      "learning_rate": 0.00018415407118478792,
      "loss": 1.6761,
      "step": 1300
    },
    {
      "epoch": 0.3412969283276451,
      "grad_norm": 6.222165584564209,
      "learning_rate": 0.00018293515358361776,
      "loss": 1.622,
      "step": 1400
    },
    {
      "epoch": 0.3656752803510483,
      "grad_norm": 3.437169075012207,
      "learning_rate": 0.0001817162359824476,
      "loss": 1.5368,
      "step": 1500
    },
    {
      "epoch": 0.3900536323744515,
      "grad_norm": 5.79552698135376,
      "learning_rate": 0.00018049731838127743,
      "loss": 1.6007,
      "step": 1600
    },
    {
      "epoch": 0.4144319843978547,
      "grad_norm": 4.184427738189697,
      "learning_rate": 0.00017927840078010726,
      "loss": 1.5548,
      "step": 1700
    },
    {
      "epoch": 0.43881033642125794,
      "grad_norm": 5.03712272644043,
      "learning_rate": 0.0001780594831789371,
      "loss": 1.5969,
      "step": 1800
    },
    {
      "epoch": 0.46318868844466116,
      "grad_norm": 7.73659610748291,
      "learning_rate": 0.00017684056557776696,
      "loss": 1.5503,
      "step": 1900
    },
    {
      "epoch": 0.48756704046806437,
      "grad_norm": 4.098001480102539,
      "learning_rate": 0.0001756216479765968,
      "loss": 1.5556,
      "step": 2000
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 5.721057415008545,
      "learning_rate": 0.00017440273037542663,
      "loss": 1.5145,
      "step": 2100
    },
    {
      "epoch": 0.5363237445148707,
      "grad_norm": 5.561791896820068,
      "learning_rate": 0.00017318381277425647,
      "loss": 1.5473,
      "step": 2200
    },
    {
      "epoch": 0.560702096538274,
      "grad_norm": 4.6710920333862305,
      "learning_rate": 0.00017196489517308633,
      "loss": 1.5571,
      "step": 2300
    },
    {
      "epoch": 0.5850804485616772,
      "grad_norm": 4.553824424743652,
      "learning_rate": 0.00017074597757191614,
      "loss": 1.4729,
      "step": 2400
    },
    {
      "epoch": 0.6094588005850804,
      "grad_norm": 6.198246479034424,
      "learning_rate": 0.00016952705997074597,
      "loss": 1.4698,
      "step": 2500
    },
    {
      "epoch": 0.6338371526084836,
      "grad_norm": 4.777071952819824,
      "learning_rate": 0.0001683081423695758,
      "loss": 1.4794,
      "step": 2600
    },
    {
      "epoch": 0.6582155046318869,
      "grad_norm": 4.112995624542236,
      "learning_rate": 0.00016708922476840567,
      "loss": 1.4211,
      "step": 2700
    },
    {
      "epoch": 0.6825938566552902,
      "grad_norm": 4.350918769836426,
      "learning_rate": 0.0001658703071672355,
      "loss": 1.539,
      "step": 2800
    },
    {
      "epoch": 0.7069722086786934,
      "grad_norm": 5.047833442687988,
      "learning_rate": 0.00016465138956606534,
      "loss": 1.479,
      "step": 2900
    },
    {
      "epoch": 0.7313505607020966,
      "grad_norm": 4.232733726501465,
      "learning_rate": 0.00016343247196489517,
      "loss": 1.4241,
      "step": 3000
    },
    {
      "epoch": 0.7557289127254998,
      "grad_norm": 4.94191312789917,
      "learning_rate": 0.00016221355436372504,
      "loss": 1.491,
      "step": 3100
    },
    {
      "epoch": 0.780107264748903,
      "grad_norm": 2.995272636413574,
      "learning_rate": 0.00016099463676255487,
      "loss": 1.4512,
      "step": 3200
    },
    {
      "epoch": 0.8044856167723062,
      "grad_norm": 4.9415483474731445,
      "learning_rate": 0.0001597757191613847,
      "loss": 1.4395,
      "step": 3300
    },
    {
      "epoch": 0.8288639687957094,
      "grad_norm": 5.740908145904541,
      "learning_rate": 0.00015855680156021454,
      "loss": 1.3754,
      "step": 3400
    },
    {
      "epoch": 0.8532423208191127,
      "grad_norm": 4.836285591125488,
      "learning_rate": 0.00015733788395904438,
      "loss": 1.4224,
      "step": 3500
    },
    {
      "epoch": 0.8776206728425159,
      "grad_norm": 5.876269817352295,
      "learning_rate": 0.0001561189663578742,
      "loss": 1.4458,
      "step": 3600
    },
    {
      "epoch": 0.9019990248659191,
      "grad_norm": 8.347146034240723,
      "learning_rate": 0.00015490004875670405,
      "loss": 1.4329,
      "step": 3700
    },
    {
      "epoch": 0.9263773768893223,
      "grad_norm": 5.609083652496338,
      "learning_rate": 0.00015368113115553388,
      "loss": 1.3999,
      "step": 3800
    },
    {
      "epoch": 0.9507557289127255,
      "grad_norm": 3.812046527862549,
      "learning_rate": 0.00015246221355436375,
      "loss": 1.3732,
      "step": 3900
    },
    {
      "epoch": 0.9751340809361287,
      "grad_norm": 6.698141098022461,
      "learning_rate": 0.00015124329595319358,
      "loss": 1.4023,
      "step": 4000
    },
    {
      "epoch": 0.999512432959532,
      "grad_norm": 6.031205654144287,
      "learning_rate": 0.00015002437835202342,
      "loss": 1.4265,
      "step": 4100
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0610692489893888e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
