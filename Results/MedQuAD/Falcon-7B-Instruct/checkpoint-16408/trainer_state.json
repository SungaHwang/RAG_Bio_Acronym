{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 16408,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 5.53125,
      "learning_rate": 0.0002,
      "loss": 1.61,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.46875,
      "learning_rate": 0.0002,
      "loss": 1.45,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.203125,
      "learning_rate": 0.0002,
      "loss": 1.34,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.390625,
      "learning_rate": 0.0002,
      "loss": 1.31,
      "step": 400
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.0625,
      "learning_rate": 0.0002,
      "loss": 1.34,
      "step": 500
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.609375,
      "learning_rate": 0.0002,
      "loss": 1.32,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.21875,
      "learning_rate": 0.0002,
      "loss": 1.3,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.828125,
      "learning_rate": 0.0002,
      "loss": 1.29,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.8125,
      "learning_rate": 0.0002,
      "loss": 1.34,
      "step": 900
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.671875,
      "learning_rate": 0.0002,
      "loss": 1.24,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5625,
      "learning_rate": 0.0002,
      "loss": 1.255,
      "step": 1100
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.203125,
      "learning_rate": 0.0002,
      "loss": 1.225,
      "step": 1200
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.046875,
      "learning_rate": 0.0002,
      "loss": 1.27,
      "step": 1300
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.671875,
      "learning_rate": 0.0002,
      "loss": 1.205,
      "step": 1400
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.5625,
      "learning_rate": 0.0002,
      "loss": 1.185,
      "step": 1500
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0625,
      "learning_rate": 0.0002,
      "loss": 1.205,
      "step": 1600
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.078125,
      "learning_rate": 0.0002,
      "loss": 1.15,
      "step": 1700
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.578125,
      "learning_rate": 0.0002,
      "loss": 1.19,
      "step": 1800
    },
    {
      "epoch": 0.46,
      "grad_norm": 6.46875,
      "learning_rate": 0.0002,
      "loss": 1.16,
      "step": 1900
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1875,
      "learning_rate": 0.0002,
      "loss": 1.15,
      "step": 2000
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.25,
      "learning_rate": 0.0002,
      "loss": 1.17,
      "step": 2100
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.078125,
      "learning_rate": 0.0002,
      "loss": 1.115,
      "step": 2200
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.015625,
      "learning_rate": 0.0002,
      "loss": 1.16,
      "step": 2300
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.9375,
      "learning_rate": 0.0002,
      "loss": 1.09,
      "step": 2400
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.4375,
      "learning_rate": 0.0002,
      "loss": 1.095,
      "step": 2500
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.3125,
      "learning_rate": 0.0002,
      "loss": 1.07,
      "step": 2600
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.9375,
      "learning_rate": 0.0002,
      "loss": 1.05,
      "step": 2700
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.90625,
      "learning_rate": 0.0002,
      "loss": 1.12,
      "step": 2800
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.453125,
      "learning_rate": 0.0002,
      "loss": 1.075,
      "step": 2900
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.515625,
      "learning_rate": 0.0002,
      "loss": 1.055,
      "step": 3000
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.140625,
      "learning_rate": 0.0002,
      "loss": 1.08,
      "step": 3100
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.734375,
      "learning_rate": 0.0002,
      "loss": 1.075,
      "step": 3200
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8125,
      "learning_rate": 0.0002,
      "loss": 1.04,
      "step": 3300
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.859375,
      "learning_rate": 0.0002,
      "loss": 0.99,
      "step": 3400
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.359375,
      "learning_rate": 0.0002,
      "loss": 1.02,
      "step": 3500
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.84375,
      "learning_rate": 0.0002,
      "loss": 1.03,
      "step": 3600
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.4375,
      "learning_rate": 0.0002,
      "loss": 1.06,
      "step": 3700
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.921875,
      "learning_rate": 0.0002,
      "loss": 1.02,
      "step": 3800
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.109375,
      "learning_rate": 0.0002,
      "loss": 1.0,
      "step": 3900
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.40625,
      "learning_rate": 0.0002,
      "loss": 1.02,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.453125,
      "learning_rate": 0.0002,
      "loss": 1.045,
      "step": 4100
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.359375,
      "learning_rate": 0.0002,
      "loss": 0.925,
      "step": 4200
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6796875,
      "learning_rate": 0.0002,
      "loss": 0.935,
      "step": 4300
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.1875,
      "learning_rate": 0.0002,
      "loss": 0.925,
      "step": 4400
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.953125,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 4500
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.9609375,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 4600
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.59375,
      "learning_rate": 0.0002,
      "loss": 0.945,
      "step": 4700
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.03125,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 4800
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6953125,
      "learning_rate": 0.0002,
      "loss": 0.925,
      "step": 4900
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.5625,
      "learning_rate": 0.0002,
      "loss": 0.94,
      "step": 5000
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.390625,
      "learning_rate": 0.0002,
      "loss": 0.935,
      "step": 5100
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.25,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 5200
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.78125,
      "learning_rate": 0.0002,
      "loss": 0.94,
      "step": 5300
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.1875,
      "learning_rate": 0.0002,
      "loss": 0.94,
      "step": 5400
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.140625,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 5500
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.609375,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 5600
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.25,
      "learning_rate": 0.0002,
      "loss": 0.925,
      "step": 5700
    },
    {
      "epoch": 1.41,
      "grad_norm": 2.75,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 5800
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.65625,
      "learning_rate": 0.0002,
      "loss": 0.94,
      "step": 5900
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.96875,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 6000
    },
    {
      "epoch": 1.49,
      "grad_norm": 3.3125,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 6100
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.203125,
      "learning_rate": 0.0002,
      "loss": 0.945,
      "step": 6200
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.109375,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 6300
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.8125,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 6400
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.625,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 6500
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.15625,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 6600
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.90625,
      "learning_rate": 0.0002,
      "loss": 0.95,
      "step": 6700
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.9375,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 6800
    },
    {
      "epoch": 1.68,
      "grad_norm": 2.140625,
      "learning_rate": 0.0002,
      "loss": 0.94,
      "step": 6900
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.828125,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 7000
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.84375,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 7100
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.40625,
      "learning_rate": 0.0002,
      "loss": 0.875,
      "step": 7200
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.84375,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 7300
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.6875,
      "learning_rate": 0.0002,
      "loss": 0.925,
      "step": 7400
    },
    {
      "epoch": 1.83,
      "grad_norm": 2.828125,
      "learning_rate": 0.0002,
      "loss": 0.89,
      "step": 7500
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.59375,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 7600
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.1875,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 7700
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.921875,
      "learning_rate": 0.0002,
      "loss": 0.94,
      "step": 7800
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.9765625,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 7900
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.78125,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 8000
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.421875,
      "learning_rate": 0.0002,
      "loss": 0.95,
      "step": 8100
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.40625,
      "learning_rate": 0.0002,
      "loss": 0.945,
      "step": 8200
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.78125,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 8300
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.75,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 8400
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.625,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 8500
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.375,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 8600
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.8515625,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 8700
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.8671875,
      "learning_rate": 0.0002,
      "loss": 0.87,
      "step": 8800
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.078125,
      "learning_rate": 0.0002,
      "loss": 0.885,
      "step": 8900
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.875,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 9000
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.140625,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 9100
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.8125,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 9200
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.8359375,
      "learning_rate": 0.0002,
      "loss": 0.88,
      "step": 9300
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.046875,
      "learning_rate": 0.0002,
      "loss": 0.89,
      "step": 9400
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.921875,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 9500
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.296875,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 9600
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.359375,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 9700
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.21875,
      "learning_rate": 0.0002,
      "loss": 0.89,
      "step": 9800
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.890625,
      "learning_rate": 0.0002,
      "loss": 0.865,
      "step": 9900
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.375,
      "learning_rate": 0.0002,
      "loss": 0.855,
      "step": 10000
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.65625,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 10100
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.96875,
      "learning_rate": 0.0002,
      "loss": 0.94,
      "step": 10200
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.8984375,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 10300
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.09375,
      "learning_rate": 0.0002,
      "loss": 0.89,
      "step": 10400
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.171875,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 10500
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.84375,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 10600
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.09375,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 10700
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.859375,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 10800
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.59375,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 10900
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.6484375,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 11000
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.515625,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 11100
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.96875,
      "learning_rate": 0.0002,
      "loss": 0.885,
      "step": 11200
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.5,
      "learning_rate": 0.0002,
      "loss": 0.935,
      "step": 11300
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.203125,
      "learning_rate": 0.0002,
      "loss": 0.865,
      "step": 11400
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.9375,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 11500
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.015625,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 11600
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.5625,
      "learning_rate": 0.0002,
      "loss": 0.885,
      "step": 11700
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.4375,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 11800
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.25,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 11900
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.21875,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 12000
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.9453125,
      "learning_rate": 0.0002,
      "loss": 0.885,
      "step": 12100
    },
    {
      "epoch": 2.97,
      "grad_norm": 2.390625,
      "learning_rate": 0.0002,
      "loss": 0.865,
      "step": 12200
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.109375,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 12300
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.0625,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 12400
    },
    {
      "epoch": 3.05,
      "grad_norm": 1.671875,
      "learning_rate": 0.0002,
      "loss": 0.88,
      "step": 12500
    },
    {
      "epoch": 3.07,
      "grad_norm": 1.5859375,
      "learning_rate": 0.0002,
      "loss": 0.88,
      "step": 12600
    },
    {
      "epoch": 3.1,
      "grad_norm": 2.03125,
      "learning_rate": 0.0002,
      "loss": 0.875,
      "step": 12700
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.3984375,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 12800
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.1875,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 12900
    },
    {
      "epoch": 3.17,
      "grad_norm": 2.21875,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 13000
    },
    {
      "epoch": 3.19,
      "grad_norm": 1.4296875,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 13100
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.84375,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 13200
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.109375,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 13300
    },
    {
      "epoch": 3.27,
      "grad_norm": 1.4375,
      "learning_rate": 0.0002,
      "loss": 0.875,
      "step": 13400
    },
    {
      "epoch": 3.29,
      "grad_norm": 1.921875,
      "learning_rate": 0.0002,
      "loss": 0.885,
      "step": 13500
    },
    {
      "epoch": 3.32,
      "grad_norm": 2.234375,
      "learning_rate": 0.0002,
      "loss": 0.885,
      "step": 13600
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.40625,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 13700
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.125,
      "learning_rate": 0.0002,
      "loss": 0.89,
      "step": 13800
    },
    {
      "epoch": 3.39,
      "grad_norm": 1.703125,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 13900
    },
    {
      "epoch": 3.41,
      "grad_norm": 2.015625,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 14000
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.046875,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 14100
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.8046875,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 14200
    },
    {
      "epoch": 3.49,
      "grad_norm": 1.828125,
      "learning_rate": 0.0002,
      "loss": 0.935,
      "step": 14300
    },
    {
      "epoch": 3.51,
      "grad_norm": 1.78125,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 14400
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.53125,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 14500
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.3125,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 14600
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.6953125,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 14700
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.8359375,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 14800
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.125,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 14900
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.484375,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 15000
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.9453125,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 15100
    },
    {
      "epoch": 3.71,
      "grad_norm": 1.4375,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 15200
    },
    {
      "epoch": 3.73,
      "grad_norm": 1.3828125,
      "learning_rate": 0.0002,
      "loss": 0.89,
      "step": 15300
    },
    {
      "epoch": 3.75,
      "grad_norm": 1.71875,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 15400
    },
    {
      "epoch": 3.78,
      "grad_norm": 1.625,
      "learning_rate": 0.0002,
      "loss": 0.88,
      "step": 15500
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.3515625,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 15600
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.8984375,
      "learning_rate": 0.0002,
      "loss": 0.915,
      "step": 15700
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.046875,
      "learning_rate": 0.0002,
      "loss": 0.92,
      "step": 15800
    },
    {
      "epoch": 3.88,
      "grad_norm": 1.9609375,
      "learning_rate": 0.0002,
      "loss": 0.91,
      "step": 15900
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.15625,
      "learning_rate": 0.0002,
      "loss": 0.93,
      "step": 16000
    },
    {
      "epoch": 3.92,
      "grad_norm": 1.7734375,
      "learning_rate": 0.0002,
      "loss": 0.895,
      "step": 16100
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.078125,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 16200
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.28125,
      "learning_rate": 0.0002,
      "loss": 0.9,
      "step": 16300
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.390625,
      "learning_rate": 0.0002,
      "loss": 0.905,
      "step": 16400
    }
  ],
  "logging_steps": 100,
  "max_steps": 16408,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 3.604014235987354e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
