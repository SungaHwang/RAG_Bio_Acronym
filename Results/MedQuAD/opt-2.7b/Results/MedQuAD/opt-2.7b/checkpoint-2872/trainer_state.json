{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 2872,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14,
      "grad_norm": 1.5130436420440674,
      "learning_rate": 0.0001994023212852595,
      "loss": 1.6822,
      "step": 100
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.399770975112915,
      "learning_rate": 0.00019761642953795895,
      "loss": 1.4601,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.282995581626892,
      "learning_rate": 0.00019466367254778233,
      "loss": 1.4227,
      "step": 300
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0722500085830688,
      "learning_rate": 0.00019057934631478617,
      "loss": 1.3882,
      "step": 400
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1340806484222412,
      "learning_rate": 0.00018541227313604078,
      "loss": 1.3922,
      "step": 500
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3247060775756836,
      "learning_rate": 0.00017922421800467512,
      "loss": 1.3652,
      "step": 600
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1713792085647583,
      "learning_rate": 0.0001720891502974423,
      "loss": 1.3424,
      "step": 700
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.52152019739151,
      "learning_rate": 0.00016409235957627925,
      "loss": 1.3297,
      "step": 800
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.5345258116722107,
      "learning_rate": 0.00015532943607319142,
      "loss": 1.3119,
      "step": 900
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6160534024238586,
      "learning_rate": 0.0001459051280453127,
      "loss": 1.3293,
      "step": 1000
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6073423624038696,
      "learning_rate": 0.00013593208965883156,
      "loss": 1.3137,
      "step": 1100
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.5698666572570801,
      "learning_rate": 0.00012552953436904577,
      "loss": 1.2914,
      "step": 1200
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5951370596885681,
      "learning_rate": 0.00011482180989346771,
      "loss": 1.2849,
      "step": 1300
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5554934144020081,
      "learning_rate": 0.0001039369118121445,
      "loss": 1.285,
      "step": 1400
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.391956090927124,
      "learning_rate": 9.300495356298269e-05,
      "loss": 1.2264,
      "step": 1500
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.3773936629295349,
      "learning_rate": 8.215661112110143e-05,
      "loss": 1.2703,
      "step": 1600
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.4659210443496704,
      "learning_rate": 7.152156095385527e-05,
      "loss": 1.273,
      "step": 1700
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.4418613612651825,
      "learning_rate": 6.122692992354748e-05,
      "loss": 1.2137,
      "step": 1800
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.4438337981700897,
      "learning_rate": 5.1395775667036425e-05,
      "loss": 1.2627,
      "step": 1900
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.4403987526893616,
      "learning_rate": 4.2145615617131095e-05,
      "loss": 1.2493,
      "step": 2000
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.4080989956855774,
      "learning_rate": 3.3587022249226904e-05,
      "loss": 1.2372,
      "step": 2100
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.9280214905738831,
      "learning_rate": 2.5822301345006194e-05,
      "loss": 1.2699,
      "step": 2200
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.9684000015258789,
      "learning_rate": 1.8944269072676012e-05,
      "loss": 1.2142,
      "step": 2300
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.8483853936195374,
      "learning_rate": 1.3035142502005792e-05,
      "loss": 1.2263,
      "step": 2400
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.8941609263420105,
      "learning_rate": 8.165556816475461e-06,
      "loss": 1.2289,
      "step": 2500
    },
    {
      "epoch": 3.62,
      "grad_norm": 1.0107910633087158,
      "learning_rate": 4.393720970361948e-06,
      "loss": 1.2397,
      "step": 2600
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.0991560220718384,
      "learning_rate": 1.7647218836795875e-06,
      "loss": 1.2433,
      "step": 2700
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.8561480045318604,
      "learning_rate": 3.0998549233205443e-07,
      "loss": 1.2087,
      "step": 2800
    }
  ],
  "logging_steps": 100,
  "max_steps": 2872,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 2.2585189350776832e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
