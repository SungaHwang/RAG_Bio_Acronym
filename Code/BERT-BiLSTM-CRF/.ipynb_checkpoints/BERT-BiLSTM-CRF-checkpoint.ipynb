{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4d52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4564b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/media/lurker18/Local Disk/BioNER-Abbrev/Dataset/NCBI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3f3216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-05 13:33:01,625] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./pretrained_model/pubmedbert/tokenizer_config.json',\n",
       " './pretrained_model/pubmedbert/special_tokens_map.json',\n",
       " './pretrained_model/pubmedbert/vocab.txt',\n",
       " './pretrained_model/pubmedbert/added_tokens.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\"\n",
    "\n",
    "pubmedbert = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = False)\n",
    "pubmedbert.save_pretrained(f\"./pretrained_model/pubmedbert\")\n",
    "tokenizer.save_pretrained(\"./pretrained_model/pubmedbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2505cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Settings\n",
    "device = \"cuda:0\"\n",
    "max_len = 256\n",
    "train_batch_size = 64\n",
    "valid_batch_size = 64\n",
    "epochs = 30\n",
    "num_workers = 8\n",
    "BASE_MODEL_PATH = './pretrained_model/pubmedbert'\n",
    "model_path = \"models/NBCI_pubmedbert\"\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(BASE_MODEL_PATH,\n",
    "                                                       do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f60177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityDataset:\n",
    "    def __init__(self, texts, tags,enc_tag):\n",
    "        self.texts = texts\n",
    "        self.tags = tags\n",
    "        self.enc_tag = enc_tag\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        tags = self.tags[item]\n",
    "\n",
    "        ids = []\n",
    "        target_tag =[]\n",
    "\n",
    "        for i, s in enumerate(text):\n",
    "            inputs = TOKENIZER.encode(\n",
    "                str(s),\n",
    "                add_special_tokens = False\n",
    "            )\n",
    "            input_len = len(inputs)\n",
    "            ids.extend(inputs)\n",
    "            target_tag.extend([tags[i]] * input_len)\n",
    "\n",
    "        ids = ids[:max_len - 2]\n",
    "        target_tag = target_tag[:max_len - 2]\n",
    "\n",
    "        ids = [102] + ids + [103]\n",
    "        o_tag = self.enc_tag.transform([\"O\"])[0]\n",
    "        target_tag = [o_tag] + target_tag + [o_tag]\n",
    "\n",
    "        mask = [1] * len(ids)\n",
    "        token_type_ids = [0] * len(ids)\n",
    "\n",
    "        padding_len = max_len - len(ids)\n",
    "\n",
    "        ids = ids + ([0] * padding_len)\n",
    "        mask = mask + ([0] * padding_len)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
    "        target_tag = target_tag + ([0] * padding_len)\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype = torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype = torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"target_tag\": torch.tensor(target_tag, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acddd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EntityModel(nn.Module):\n",
    "    def __init__(self, num_tag):\n",
    "        super(EntityModel, self).__init__()\n",
    "        self.num_tag = num_tag\n",
    "        self.bert = transformers.BertModel.from_pretrained(BASE_MODEL_PATH, return_dict = False)\n",
    "        self.bilstm =  nn.LSTM(768, 1024 // 2, num_layers = 1, bidirectional = True, batch_first = True)\n",
    "\n",
    "        self.dropout_tag = nn.Dropout(0.3)\n",
    "        \n",
    "        self.hidden2tag_tag = nn.Linear(1024, self.num_tag)\n",
    "\n",
    "        self.crf_tag = CRF(self.num_tag, batch_first = True)\n",
    "    \n",
    "    \n",
    "    # return the loss only, not encode the tag\n",
    "    def forward(self, ids, mask, token_type_ids, target_tag):\n",
    "        x, _ = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
    "        h, _ = self.bilstm(x)\n",
    "\n",
    "        o_tag = self.dropout_tag(h)\n",
    "        tag = self.hidden2tag_tag(o_tag)\n",
    "        mask = torch.where(mask == 1, True, False)\n",
    "\n",
    "        loss_tag = - self.crf_tag(tag, \n",
    "                                  target_tag, \n",
    "                                  mask = mask, \n",
    "                                  reduction = 'token_mean')\n",
    "        loss = loss_tag\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    # encode the tag, dont return loss\n",
    "    def encode(self, ids, mask, token_type_ids, target_tag):\n",
    "        # Bert - BiLSTM\n",
    "        x, _ = self.bert(ids, \n",
    "                         attention_mask = mask, \n",
    "                         token_type_ids = token_type_ids)\n",
    "        h, _ = self.bilstm(x)\n",
    "\n",
    "        # drop out\n",
    "        o_tag = self.dropout_tag(h)\n",
    "        # o_pos = self.dropout_pos(h)\n",
    "\n",
    "        # Hidden2Tag (Linear)\n",
    "        tag = self.hidden2tag_tag(o_tag)\n",
    "        mask = torch.where(mask == 1, True, False)\n",
    "        tag = self.crf_tag.decode(tag, mask = mask)\n",
    "\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2d4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tags = []\n",
    "with open(data_folder + \"/classes.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        total_tags.append(line.strip())\n",
    "        \n",
    "\n",
    "enc_tag = preprocessing.LabelEncoder()\n",
    "enc_tag.fit(list(total_tags))\n",
    "\n",
    "def process_data(data_path):\n",
    "    sentences, tags = [], []\n",
    "    sentence, tag = [], []\n",
    "    \n",
    "    total_tags = set()\n",
    "    i = 0\n",
    "    \n",
    "    for path in data_path:\n",
    "        with open(path, \"r\") as f:\n",
    "            for line in f:\n",
    "                if i % 10000 == 0:\n",
    "                    print(len(sentences))\n",
    "                \n",
    "                i += 1\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"-DOCSTART-\"):\n",
    "                    continue\n",
    "                elif len(line) == 0:\n",
    "                    if sentence == [] and tag == []:\n",
    "                        continue\n",
    "                        \n",
    "                    sentences.append(sentence)\n",
    "                    tags.append(tag)\n",
    "                    sentence, tag = [], []\n",
    "                else:\n",
    "                    s,t = line.split(\"\\t\")\n",
    "                    sentence.append(s)\n",
    "                    tag.append(t)\n",
    "                    \n",
    "    for i in range(len(tags)):\n",
    "        tags[i] = enc_tag.transform(tags[i])\n",
    "        \n",
    "    return sentences, tags, enc_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b9f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation Tagging \n",
    "\n",
    "def split_tag(chunk_tag):\n",
    "    \"\"\"\n",
    "    split chunk tag into IOBES prefix and chunk_type\n",
    "    e.g.\n",
    "    B-PER --> (B, PER)\n",
    "    O --> (0, None)\n",
    "    \"\"\"\n",
    "    if chunk_tag == 'O':\n",
    "        return ('O', None)\n",
    "    return chunk_tag.split(\"-\", maxsplit = 1)\n",
    "\n",
    "def is_chunk_end(prev_tag, tag):\n",
    "    \"\"\"\n",
    "    check if the previous chunk ended between the previous and current word\n",
    "    e.g.\n",
    "    (B-PER, I-PER) --> False\n",
    "    (B-LOC, O) --> True\n",
    "    Note: in case of contradicting tags, e.g. (B-PER, I-LOC)\n",
    "    this is considered as (B-PER, B-LOC)\n",
    "    \"\"\"\n",
    "    \n",
    "    prefix1, chunk_type1 = split_tag(prev_tag)\n",
    "    prefix2, chunk_type2 = split_tag(tag)\n",
    "    \n",
    "    if prefix1 == 'O':\n",
    "        return False\n",
    "    if prefix2 == 'O':\n",
    "        return prefix1 != 'O'\n",
    "    \n",
    "    if chunk_type1 != chunk_type2:\n",
    "        return True\n",
    "    \n",
    "    return prefix2 in [\"B\", \"S\"] or prefix1 in [\"E\", \"S\"]\n",
    "\n",
    "def is_chunk_start(prev_tag, tag):\n",
    "    \"\"\"\n",
    "    check if a new chunk started between the previous and current word\n",
    "    \"\"\"\n",
    "    prefix1, chunk_type1 = split_tag(prev_tag)\n",
    "    prefix2, chunk_type2 = split_tag(tag)\n",
    "    \n",
    "    if prefix2 == \"O\":\n",
    "        return False\n",
    "    if prefix1 == \"O\":\n",
    "        return prefix2 != \"O\"\n",
    "    \n",
    "    if chunk_type1 != chunk_type2:\n",
    "        return True\n",
    "    \n",
    "    return prefix2 in [\"B\", \"S\"] or prefix1 in [\"E\", \"S\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4203c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(tp, p, t, percent = True):\n",
    "    \"\"\"\n",
    "    compute overall precision, recall and F1-Score (default values are 0.0)\n",
    "    if percent is True, return 100 * original decimal value\n",
    "    \"\"\"\n",
    "    precision = tp / p if p else 0\n",
    "    recall = tp / t if t else 0\n",
    "    fb1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
    "    if percent:\n",
    "        return 100 * precision, 100 * recall, 100 * fb1\n",
    "    else:\n",
    "        return precision, recall, fb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cdd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chunks(true_seqs, pred_seqs):\n",
    "    \n",
    "    \"\"\"\n",
    "    true_seqs: a list of true tags\n",
    "    pred_seqs: a list of predicted tags\n",
    "    return: \n",
    "    correct_chunks: a dict (counter), \n",
    "                    key = chunk types, \n",
    "                    value = number of correctly identified chunks per type\n",
    "    true_chunks:    a dict, number of true chunks per type\n",
    "    pred_chunks:    a dict, number of identified chunks per type\n",
    "    correct_counts, true_counts, pred_counts: similar to above, but for tags\n",
    "    \"\"\"\n",
    "    \n",
    "    correct_chunks = defaultdict(int)\n",
    "    true_chunks = defaultdict(int)\n",
    "    pred_chunks = defaultdict(int)\n",
    "\n",
    "    correct_counts = defaultdict(int)\n",
    "    true_counts = defaultdict(int)\n",
    "    pred_counts = defaultdict(int)\n",
    "\n",
    "    prev_true_tag, prev_pred_tag = 'O', 'O'\n",
    "    correct_chunk = None\n",
    "\n",
    "    for true_tag, pred_tag in zip(true_seqs, pred_seqs):\n",
    "        if true_tag == pred_tag:\n",
    "            correct_counts[true_tag] += 1\n",
    "        true_counts[true_tag] += 1\n",
    "        pred_counts[pred_tag] += 1\n",
    "\n",
    "        _, true_type = split_tag(true_tag)\n",
    "        _, pred_type = split_tag(pred_tag)\n",
    "\n",
    "        if correct_chunk is not None:\n",
    "            true_end = is_chunk_end(prev_true_tag, true_tag)\n",
    "            pred_end = is_chunk_end(prev_pred_tag, pred_tag)\n",
    "\n",
    "            if pred_end and true_end:\n",
    "                correct_chunks[correct_chunk] += 1\n",
    "                correct_chunk = None\n",
    "            elif pred_end != true_end or true_type != pred_type:\n",
    "                correct_chunk = None\n",
    "\n",
    "        true_start = is_chunk_start(prev_true_tag, true_tag)\n",
    "        pred_start = is_chunk_start(prev_pred_tag, pred_tag)\n",
    "\n",
    "        if true_start and pred_start and true_type == pred_type:\n",
    "            correct_chunk = true_type\n",
    "        if true_start:\n",
    "            true_chunks[true_type] += 1\n",
    "        if pred_start:\n",
    "            pred_chunks[pred_type] += 1\n",
    "\n",
    "        prev_true_tag, prev_pred_tag = true_tag, pred_tag\n",
    "    if correct_chunk is not None:\n",
    "        correct_chunks[correct_chunk] += 1\n",
    "\n",
    "    return (correct_chunks, true_chunks, pred_chunks, \n",
    "        correct_counts, true_counts, pred_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ca0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "def get_result(correct_chunks, true_chunks, pred_chunks,\n",
    "    correct_counts, true_counts, pred_counts, verbose = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    if verbose, print overall performance, as well as preformance per chunk type;\n",
    "    otherwise, simply return overall prec, rec, f1 scores\n",
    "    \"\"\"\n",
    "    \n",
    "    # sum counts\n",
    "    sum_correct_chunks = sum(correct_chunks.values())\n",
    "    sum_true_chunks = sum(true_chunks.values())\n",
    "    sum_pred_chunks = sum(pred_chunks.values())\n",
    "\n",
    "    sum_correct_counts = sum(correct_counts.values())\n",
    "    sum_true_counts = sum(true_counts.values())\n",
    "\n",
    "    nonO_correct_counts = sum(v for k, v in correct_counts.items() if k != 'O')\n",
    "    nonO_true_counts = sum(v for k, v in true_counts.items() if k != 'O')\n",
    "\n",
    "    chunk_types = sorted(list(set(list(true_chunks) + list(pred_chunks))))\n",
    "\n",
    "    # compute overall precision, recall and F1-Score (default values are 0.0)\n",
    "    prec, rec, f1 = calc_metrics(sum_correct_chunks, sum_pred_chunks, sum_true_chunks)\n",
    "    res = (prec, rec, f1)\n",
    "    if not verbose:\n",
    "        return res\n",
    "\n",
    "    # print overall performance, and performance per chunk type\n",
    "    \n",
    "    print(\"processed %i tokens with %i phrases; \" % (sum_true_counts, sum_true_chunks), end='')\n",
    "    print(\"found: %i phrases; correct: %i.\\n\" % (sum_pred_chunks, sum_correct_chunks), end='')\n",
    "        \n",
    "    print(\"accuracy: %6.2f%%; (non-O)\" % (100 * nonO_correct_counts/nonO_true_counts))\n",
    "    print(\"accuracy: %6.2f%%; \" % (100 * sum_correct_counts/sum_true_counts), end = '')\n",
    "    print(\"precision: %6.2f%%; recall: %6.2f%%; F1-Score: %6.2f\" % (prec, rec, f1))\n",
    "\n",
    "    # for each chunk type, compute precision, recall and FB1 (default values are 0.0)\n",
    "    for t in chunk_types:\n",
    "        prec, rec, f1 = calc_metrics(correct_chunks[t], pred_chunks[t], true_chunks[t])\n",
    "        print(\"%17s: \" %t , end = '')\n",
    "        print(\"precision: %6.2f%%; recall: %6.2f%%; F1-Score: %6.2f\" % (prec, rec, f1), end = '')\n",
    "        print(\"  %d\" % pred_chunks[t])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "518ae685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the datasets\n",
    "def evaluate(true_seqs, pred_seqs, verbose = True):\n",
    "    (correct_chunks, true_chunks, pred_chunks, correct_counts, true_counts, pred_counts) = count_chunks(true_seqs, pred_seqs)\n",
    "    result = get_result(correct_chunks, true_chunks, pred_chunks, correct_counts, true_counts, pred_counts, verbose = verbose)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b60ef38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the train / validation / test set for each loss\n",
    "def train_fn(data_loader, model, optimizer, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    for data in tqdm(data_loader, total = len(data_loader)):\n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(**data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        final_loss += loss.item()\n",
    "    return final_loss / len(data_loader)\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in tqdm(data_loader, total = len(data_loader)):\n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(device)\n",
    "        loss = model(**data)\n",
    "        final_loss += loss.item()\n",
    "    return final_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def test_fn(dataset,model,device,enc_tag):\n",
    "    final_test = []\n",
    "    final_pred = []\n",
    "    O = enc_tag.transform([\"O\"])[0]\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataset):\n",
    "            for k, v in data.items():\n",
    "                data[k] = v.to(device).unsqueeze(0)\n",
    "\n",
    "            tag = model.encode(**data)\n",
    "            padded_pred = tag[0]\n",
    "            test = data[\"target_tag\"].cpu()[0][:len(padded_pred)]\n",
    "            test = enc_tag.inverse_transform(test)\n",
    "            padded_pred = enc_tag.inverse_transform(padded_pred)\n",
    "            final_pred.extend(padded_pred[1:-1])\n",
    "            final_test.extend(test[1:-1])\n",
    "  \n",
    "    print(evaluate(final_test, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c5571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "def load_model(epochs):\n",
    "    path = model_path + f\"_{epochs}.bin\"\n",
    "    device = torch.device(device)\n",
    "    model = EntityModel(num_tag = num_tag)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef385ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "385\n",
      "766\n",
      "1146\n",
      "1532\n",
      "1907\n",
      "2300\n",
      "2690\n",
      "3083\n",
      "3459\n",
      "3839\n",
      "4249\n",
      "4631\n",
      "5007\n",
      "5383\n",
      "5766\n",
      "6126\n",
      "0\n",
      "369\n",
      "734\n"
     ]
    }
   ],
   "source": [
    "# Load the NCBI Disease\n",
    "if __name__ == \"__main__\":\n",
    "    sentences, tag, enc_tag = process_data([data_folder + '/NCBI-disease-IOB/train.tsv',\n",
    "                                            data_folder + '/NCBI-disease-IOB/dev.tsv'])\n",
    "    test_sentences, test_tag, _ = process_data([data_folder + '/NCBI-disease-IOB/test.tsv'])\n",
    "\n",
    "    meta_data = {\n",
    "        \"enc_tag\": enc_tag\n",
    "    }\n",
    "\n",
    "    joblib.dump(meta_data, \"meta.bin\")\n",
    "\n",
    "    num_tag = len(list(enc_tag.classes_))\n",
    "\n",
    "    (\n",
    "        train_sentences,\n",
    "        valid_sentences,\n",
    "        train_tag,\n",
    "        valid_tag\n",
    "    ) = model_selection.train_test_split(sentences, \n",
    "                                         tag, \n",
    "                                         random_state = 42, \n",
    "                                         test_size = 0.1)\n",
    "\n",
    "    train_dataset = EntityDataset(texts = train_sentences, \n",
    "                                  tags = train_tag,\n",
    "                                  enc_tag = enc_tag)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                    batch_size = train_batch_size, \n",
    "                                                    num_workers = num_workers)\n",
    "\n",
    "    valid_dataset = EntityDataset(texts = valid_sentences, \n",
    "                                  tags = valid_tag,\n",
    "                                  enc_tag = enc_tag)\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                                                    batch_size = valid_batch_size, \n",
    "                                                    num_workers = num_workers)\n",
    "\n",
    "    test_dataset = EntityDataset(texts = test_sentences,\n",
    "                                 tags = test_tag, \n",
    "                                 enc_tag = enc_tag)\n",
    "\n",
    "    device = torch.device(device)\n",
    "    model = EntityModel(num_tag = num_tag)\n",
    "    model.to(device)\n",
    "\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=3e-5, weight_decay=0.001)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1babe96a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [01:10<00:00,  1.28it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.31069549719492595\n",
      "Validation loss = 0.15180383026599883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 939/939 [00:14<00:00, 63.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 26587 tokens with 1361 phrases; found: 738 phrases; correct: 290.\n",
      "accuracy:  47.08%; (non-O)\n",
      "accuracy:  94.03%; precision:  39.30%; recall:  21.31%; F1-Score:  27.63\n",
      "          Disease: precision:  39.30%; recall:  21.31%; F1-Score:  27.63  738\n",
      "(39.295392953929536, 21.3078618662748, 27.63220581229157)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27431/1750572902.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation loss = {valid_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"_{epoch}.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory models does not exist."
     ]
    }
   ],
   "source": [
    "# Run the model!\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_fn(train_data_loader, model, optimizer, device)\n",
    "    torch.cuda.empty_cache()\n",
    "    valid_loss = eval_fn(valid_data_loader, model, device)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Train Loss = {train_loss}\")\n",
    "    print(f\"Validation loss = {valid_loss}\")\n",
    "    test_fn(test_dataset, model, device, enc_tag)\n",
    "    torch.save(model.state_dict(), model_path + f\"_{epoch}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26751590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
